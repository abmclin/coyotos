<?xml version="1.0"?>
<!DOCTYPE book PUBLIC "-//EROS Group//DTD OSDoc XML V0.1//EN"
               "http://www.coyotos.org/OSDoc/DTD/osdoc-0.1.dtd" [

<!ENTITY SpecVersion "0.5+ (0.6 in progress)">
]>
  <book id="ukernel-spec" xmlns:xi="http://www.w3.org/2001/XInclude">
  <docinfo>
<!--     ptsz="12" twocolumn="yes" -->
    <title>Coyotos Microkernel Specification</title>
    <subtitle>Version &SpecVersion;</subtitle>
    <authorgroup>
      <author>
	<firstname>Jonathan</firstname>
	<othername>S.</othername>
	<surname>Shapiro</surname>
	<degree>Ph.D.</degree>
      </author>
      <author>
	<firstname>Jonathan</firstname>
	<othername>W.</othername>
	<surname>Adams</surname>
      </author>
      <affiliation>
	<orgname>The EROS Group, LLC</orgname>
      </affiliation>
    </authorgroup>
    <authorgroup>
      <author>
 	<firstname>Eric</firstname>
 	<surname>Northup</surname>
      </author> 
      <author>
	<othername>M.</othername>
 	<firstname>Scott</firstname>
 	<surname>Doerrie</surname>
      </author> 
      <author>
 	<firstname>Swaroop</firstname>
 	<surname>Sridhar</surname>
      </author> 
      <affiliation>
	<orgname>Systems Research Laboratory</orgname>
	<address>Dept. of Computer Science</address>
	<address>Johns Hopkins University</address>
      </affiliation>
    </authorgroup>
    <authorgroup>
      <author>
	<firstname>Neal</firstname>
	<othername>H.</othername>
	<surname>Walfield</surname>
      </author>
      <author>
	<firstname>Marcus</firstname>
	<surname>Brinkmann</surname>
      </author>
      <affiliation>
	<orgname>GNU Hurd Project</orgname>
      </affiliation>
    </authorgroup>
    <pubdate>April 29, 2007</pubdate>
    <copyright>
      <year>2007</year> 
      <holder>The EROS Group, LLC</holder>
      <copyterms>
	Verbatim copies of this document may be duplicated or
	distributed in print or electronic form for non-commercial
	purposes.
      </copyterms>
    </copyright>
    <legalnotice>
      <p>
	THIS SPECIFICATION IS PROVIDED ``AS IS'' WITHOUT ANY
	WARRANTIES, INCLUDING ANY WARRANTY OF MERCHANTABILITY,
	NON-INFRINGEMENT, FITNESS FOR ANY PARTICULAR PURPOSE, OR ANY
	WARRANTY OTHERWISE ARISING OF ANY PROPOSAL, SPECIFICATION OR
	SAMPLE.
      </p>
    </legalnotice>
    <categories>
      <category>dev/coyotos</category>
    </categories>
    <synopsis>
      <p>Provisional specification for the Coyotos microkernel.</p>
    </synopsis>
  </docinfo>
  <nocite ref="Redell:Thesis"/>
  <toc/>
  <preface>
    <title>Acknowledgments</title>
    <p>
      Many people have assisted us in evaluating and advancing this
      design:
    </p>
    <blockquote>
      <p>
	Norm Hardy, Charlie Landau, and Bill Frantz of the KeyKOS
	project. Charlie also runs the CapROS project, another
	successor to the EROS system.
      </p>
      <p>
	The members of the <tt>coyotos-dev</tt> mailing list, notably
	Bas Wijnen and Tom Bachmann, Christopher Nelson, Dominique
	Quatravaux, and Pierre Thierry.
      </p>
      <p>
	The members of the L4 community, notably Hermann H&auml;rtig,
	Espen Skoglund, and Kevin Elphinstone.
      </p>
      <p>
	The external participants in the kernel design review meeting
	of 28-29 March, 2007: Godfrey Vassallo, John Davidsen, Scott
	Doerrie, and Norman Hardy.
      </p>
    </blockquote>
    <p>
      There are surely others that we will come to name as the design
      stabilizes further, and some that we will inadvertently omit. To
      the last, please accept our apologies. As is customary, any flaw
      remaining in this specification is ours.
    </p>
    <p>
      Comments and suggestions concerning this specification are
      welcome. They should be sent to the <tt>coyotos-dev</tt>
      electronic mailing list. In order to send, you must be
      subscribed to the list. The subscription interface may be found
      at:
    </p>
    <blockquote>
      <p>
	<tt>http://www.coyotos.org/mailman/listinfo/coyotos-dev</tt>.
      </p>
    </blockquote>
    <p>
      In order to keep the mail archives readable, we ask that you
      send only ``plain text'' emails.
    </p>
  </preface>
  <preface>
    <title>Preface</title>
    <p>
      Coyotos is a security microkernel. It is a microkernel in the
      sense that it is a minimal protected platform on which a
      complete operating system can be constructed. It is a security
      microkernel in the sense that it is a minimal protected platform
      on which higher level security policies can be constructed.
    </p>
    <sect1>
      <title>The Original Plan</title>
      <p>
	As originally conceived, Coyotos was intended to be a
	relatively minor departure from its predecessor, EROS <cite
	ref="shap2004towards"/>.  EROS <cite
	ref="shap1999fastcapsystem"/> was a small, robust microkernel
	whose central design ideas were pervasive use of capabilities
	<cite ref="dennis1966semantics"/> as the fundamental access
	model, an atomic, blocking capability invocation
	(therefore atomic and blocking IPC) model , and a
	persistent single-level store <cite ref="shap2002store"/>. All
	of these features were inherited with some revision from the
	KeyKOS system. <cite ref="hardy1985keykos"/> Early
	application-level work on EROS, notably the defensible network
	system <cite ref="sinha04network"/> and the secure window
	system <cite ref="shap04ews"/> revealed areas where the EROS
	architecture would clearly benefit from refinement, but did
	not initially suggest fundamental shortcomings in the
	architecture. Coyotos was to have been that minor refinement,
	incorporating a new IPC primitive called ``endpoints'' and a
	revised memory mapping entity called a PATT.  Our main goals were
	cleanup, consistency, and formalization.
      </p>
      <p>
	For algorithmic reasons, the PATT idea did not survive into
	the current specification, and has been replaced by guarded
	page tables <cites> <cite ref="liedtke1995gpt4600"/> <cite
	ref="elphinstone99vm64"/> </cites>. Though they were
	independently invented, guarded page tables may be seen as a
	generalization of the level skipping techniques of the KeyKOS
	translation mechanism or the Motorola MC68851 memory management
	unit <cite ref="mc68851"/>. The variant of guarded page tables
	incorporated here are modified to incorporate the fault
	handler and background space mechanisms of KeyKOS and EROS.
      </p>
      <p>
	In January 2004, a summit meeting of sorts occurred between
	the several research groups working on L4 derivatives and
	Shapiro. The L4 Dresden group, in particular, wanted to get a
	better understanding of capability-based design and kernel
	mechanisms, with the intent that these would be adapted into
	the L4 architecture <cite ref="sag04l4refman"/>. The new
	kernel architecture would come to be known as
	``L4.sec''. There was some discussion of merging the two
	kernels, but no agreement could be reached on the future of
	L4's <tt>map</tt> and <tt>unmap</tt> operation. While the
	failure to merge the architectures was a disappointment, the
	idea that there would be a controlled experiment that would
	allow us to directly evaluate the <tt>map/unmap</tt> approach
	againts the EROS <tt>node</tt> approach was a promising result
	in its own right.
      </p>
    </sect1>
    <sect1>
      <title>Overrun by the Hurd</title>
      <p>
	Events intervened in the form of Neal Walfield and Marcus
	Brinkmann, the current architects of the GNU Hurd system.  The
	Hurd is a protected, object-based operating system that was
	initially constructed on top of the Mach microkernel.  Mach
	has a variety of problems that have been thoroughly documented
	in the research literature. Of particular importance to Hurd
	are a lack of resource accounting mechanisms and poor
	performance. As a result of these issues, the Hurd project had
	provisionally decided to move to L4.
      </p>
      <p>
	Unfortunately, modeling copyable, protected object references
	using L4's <tt>map/grant</tt> operations proved unexpectedly
	challenging. This left the Hurd project temporarily disrupted,
	leading Brinkmann and Walfield to seek more information about
	capability-based design.  An extended discussion between
	Shapiro, Walfield, and Brinkmann at the <doctitle>2005 Libre
	Software Meeting</doctitle> about capability systems in
	general and the plans for Coyotos ensued. As more information
	about the L4.sec design emerged <cite ref="kauer2005thesis"/>,
	it became clear that copyable protected references might be
	problematic on the L4.sec interface as well. Walfield and
	Brinkmann travelled to Baltimore for a month-long set of
	design discussions in January 2006, leading to the current
	design for Coyotos.
      </p>
      <p>
	The January discussions exposed a fundamental problem in the
	originally intended Coyotos interface: <b>kernel threads are
	not cheap.</b> Over the last 15 years, it has become a tenet
	of faith among microkernel designers that blocking and
	unbuffered communication mechanisms are good. Perhaps the most
	persuasive argument supporting this position was offered by
	Liedtke in <doctitle>Improving IPC by Kernel Design</doctitle>
	<cite ref="l3:ipc"/>. The essential argument of this paper is
	that buffering carries additional copying costs, and that
	non-synchronizing IPC carries additional context switch
	overheads, the paper argues that the correct way to eliminate
	these expenses is by eliminating both features in favor of a
	blocking and unbuffered communication model. When an
	application must block on multiple communication channels, it
	should use multiple kernel threads. Our own research results
	<cite ref="EROS:IPC"/> along with those of Ford <em>et
	al.</em> <cite ref="mach4evolving"/> and others seemed to
	confirm the performance argument, and unbuffered blocking IPC
	systems became more or less the accepted design wisdom in the
	microkernel world. Looking back, it now seems likely that none
	of us adequately considered the issue of space or thought hard
	enough about application-level robustness.
      </p>
      <p>
	The space concern is a clear failing in blocking, unbuffered
	designs. Suppose there is a server that wishes to wait
	simultaneously for activity on one of 1024 network
	connections. In a blocking IPC design you need a thread to
	wait on each of these connections. The register state of a
	modern Pentium-family processor occupies nearly four
	kilobytes, and there is additional state needed within the
	operating system. Estimate it at two pages, or 8 kilobytes.
	Ignoring their address space, runtime storage requirements, or
	any other space that may be needed, the mere existence of
	these 1024 threads requires about 8 <em>megabytes</em>. It
	could be argued that this is acceptable on a modern desktop PC
	(though I disagree). It is simply <em>not</em> acceptable on
	smaller embedded systems. The requirement for many threads
	solely for the purpose of demultiplexing presents an intrinsic
	failure of scalability.
      </p>
      <p>
	The robustness problem is more difficult to see, because it
	occurs rarely. The problem is that we need to be able to
	preempt the <em>receiver</em> (as when debugging) without
	thereby preempting the <em>receive</em>. If there is no
	receive and the sender will not block then we will lose
	messages that would normally be delivered. Coyotos resolves
	this by dividing the message into long and short
	components. The long portion of the message is delivered to
	memory as before. The short portion is delivered to a ``short
	message buffer'' if the target process is not actually
	receiving at the moment of transmission. The buffered message
	payload is delivered when the process next enters a receiving
	state. In contrast to most buffered designs, the buffer
	storage is explicitly allocated and bounded.
      </p>
      <p>
	The end result of all this is that Coyotos uses a very
	different IPC model than the EROS model.
      </p>
    </sect1>
    <sect1>
      <title>Scheduler Activations</title>
      <p>
	While redesigning the IPC system, we wanted to address another
	issue. EROS never provided a reasonable solution for
	application-level preemption. This makes emulating things like
	UNIX signals difficult, and it makes it tricky to notify
	running processes that events of possible interest have
	occurred. Because of the ``cannot preempt receive'' issue, it
	was also difficult in EROS to notify <em>waiting</em>
	processes of possible events of interest. The Coyotos process
	model incorporates scheduler activations and soft interrupts
	as a way to provide this. Our mechanism is most directly
	related to the Topaz system <cite ref="thomas90scheduler"/>,
	but interested readers should also look at first-class user
	threads in the Psyche system <cite ref="marsh91firstclass"/>,
	and the Nemesis kernel <cite ref="roscoe1995thesis"/>.
      </p>
      <p>
	Scheduler activations give us clean event loop
	concurrency support and a sensible scheduling strategy for
	user-level threads.
      </p>
    </sect1>
    <sect1>
      <title>Coyotos: Take II</title>
      <p>
	The version of Coyotos described here is an outgrowth of the
	January 2006 discussions between Walfield, Brinkmann, and
	Shapiro. In contrast to the original plan, it is an unbuffered
	<em>asynchronous</em> design. A single kernel-scheduled thread
	may have multiple receives outstanding at the same time, and
	will be reliably notified when each is completed.<footnote>
	  <p>
	    Provided that it correctly implements the activation
	    protocol.
	  </p>
	</footnote> Completion notifications are delivered to an
	application-supplied activation handler, which can elect
	whether to preempt the current user-mode thread of execution,
	enqueue the event for later processing, or simply ignore
	it. The resulting design presents a curious sort of hybrid:
	the kernel mechanisms are both asynchronous and atomic, but
	applications are able to efficiently construct blocking
	semantics on top of these if desired. If we have gotten this
	right, the common-case simplicity and performance of the old
	design has been largely preserved, but the less common (though
	still important) cases of multithreading and polling can now
	be handled sensibly.
      </p>
      <p>
	Coyotos retains the atomicity and pure capability-based design
	of the EROS system, but has moved completely to this new,
	asynchronous communications model. It also introduces a more
	efficient memory mapping mechanism, jointly invented by
	Shapiro, Eric Northup, and Scott Doerrie.  We will need to see
	whether the result works out. There is no substitute for
	measurement.
      </p>
      <p align="right">
	Jonathan S. Shapiro, Ph.D.<br/>
	Department of Computer Science<br/>
	Johns Hopkins University<br/>
	January, 2006
      </p>
    </sect1>
    <!-- <sect1> -->
<!--       <title>A Word on Terminology</title> -->
<!--       <p> -->
<!-- 	Coyotos is based on -->
<!-- 	<term>scheduler activations</term>, a mechanism whose effect -->
<!-- 	is to make user-level threads ``first class.'' Scheduler -->
<!-- 	activations permit a user-level thread scheduler to operate in -->
<!-- 	cooperation with the kernel-level scheduler. This creates a -->
<!-- 	significant confusion when speaking about process dispatch -->
<!-- 	because two levels of dispatch now must occur: the kernel must -->
<!-- 	dispatch the process, and the process's activation handler -->
<!-- 	must dispatch some user-level thread. When a process re-enters -->
<!-- 	the kernel, the kernel must be aware of the current -->
<!-- 	process-level execution mode in order to save the process -->
<!-- 	registers in a way that can later be used by the user-level -->
<!-- 	activation handler. We can no longer speak simply about a -->
<!-- 	process that is running or ready or idle. We must -->
<!-- 	simultaneously speak about whether it is ``activated'' or -->
<!-- 	normal. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	There is also some confusion about the term -->
<!-- 	<term>event</term>. It is common practice in some kernel -->
<!-- 	literature to refer to events in the sense of ``kernel events -->
<!-- 	of interest'' &mdash; things that an application may block -->
<!-- 	for. In a scheduler activation design, the application instead -->
<!-- 	enqueues an ``event wait'' structure (in Coyotos: the SMB) to -->
<!-- 	wait for operation completion and continues execution. There -->
<!-- 	is no process state corresponding to the traditional -->
<!-- 	``blocked'' state. When the operation of interest completes, -->
<!-- 	the enqueued event wait structure is delivered back to the -->
<!-- 	application. -->
<!-- 	in the form of an -->
<!-- 	<term>activation</term>. Activations are preemptive, and cause -->
<!-- 	the receiving application to transition into its activation -->
<!-- 	handler in order to process the event and optionally make a -->
<!-- 	user-level thread switch. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	Scheduler activation designs also use events for something -->
<!-- 	that we normally don't <em>think</em> of as un-blocking: the -->
<!-- 	scheduling mechanism.  In a conventional system, a -->
<!-- 	<em>ready</em> process is actually a <em>blocked</em> process -->
<!-- 	that is waiting for the CPU resource; this is just like any -->
<!-- 	other type of resource blocking. In scheduler activation -->
<!-- 	designs, this insight is made explicit: the transition from -->
<!-- 	<em>ready</em> to <em>running</em> is signalled by an event. -->
<!--       </p> -->
<!--       <p align="right"> -->
<!-- 	Jonathan S. Shapiro, Ph.D.<br/> -->
<!-- 	Department of Computer Science<br/> -->
<!-- 	Johns Hopkins University<br/> -->
<!-- 	January, 2006 -->
<!--       </p> -->
<!--     </sect1> -->
  </preface>
  <chapter>
    <title>Overview</title>
    <p>
      This document describes the abstractions, objects, and interface
      specifications (capability types) implemented by the Coyotos
      microkernel. At some points it includes discussion of the
      intended model of usage by way of motivating or explaining what
      has been incorporated. Such discussions are non-normative.
    </p>
    <p>
      All kernel-implemented objects are named and manipulated by
      means of capabilities, which grant varying degrees of authority
      according to the capability type.  Developers can extend the
      system with new objects by deploying processes that implement
      the associated interfaces. Several such application-implemented
      objects are part of the core Coyotos system.
    </p>
    <sect1>
      <title>Microkernel Objects</title>
      <p>
	The Coyotos kernel provides processes, GPTs (mapping
	structures), schedules, receive queues, pages, and a
	small number of other kernel objects.
      </p>
      <p>
	<leadin>Processes</leadin> Processes are the unit of
	execution, scheduling, and resource binding. A process names
	its address space, its schedule (which governs their execution
	timing) and their fault handler (which receives notice of
	exceptions).
      </p>
      <p>
	<leadin>Schedules</leadin> Schedules are an abstraction of
	computational resources. In order to execute instructions, a
	process must name (via a capability) the schedule under which
	it runs. The schedule, in turn, must convey authority to use
	one or more processors under a defined scheduling contract.
      </p>
      <p>
	<leadin>GPTs</leadin> GPTs are the unit of address mapping
	composition. An address mapping is defined as a mapping from
	addresses to capability slots, and is represented by a
	directed (potentially cyclic) graph of GPTs whose leaf
	capability slots name atomic storage units (pages or
	capability pages). A virtual address is divided into a
	<term>virtual page address</term> and a <term>page
	offset</term>.  Valid virtual page addresses describe paths to
	leaf slots that contain data page or capability page
	capabilities.
      </p>
<!--       <p> -->
<!-- 	<leadin>First-class receive buffers (FCRBs)</leadin> FCRBs -->
<!-- 	capture all of the information necessary for a process to -->
<!-- 	receive an incoming message. The Coyotos messaging aspect -->
<!-- 	bears some resemblance to the first-class messages of HYDRA -->
<!-- 	<cite ref="wulf1974hydra"/>. In certain cases, FCRBs can be -->
<!-- 	used to provide a guaranteed non-blocking, single-delivery -->
<!-- 	notification to the receiving process. This resolves several -->
<!-- 	of the control flow denial of service difficulties that are -->
<!-- 	present in EROS and other systems based on unbuffered, -->
<!-- 	blocking communication systems <cite -->
<!-- 	ref="shap2003vulnerabilities"/>. -->
<!--       </p> -->
      <p>
	<leadin>Endpoints</leadin> An endpoint is a named rendezvous
	point between a message sender and a message receiver. Each
	endpoint carries a receiver-interpreted endpoint
	identifier. In addition, each endpoint provides means for
	ensuring that its capabilities can be used exactly once.
      </p>
      <p>
	<leadin>Receive Queues</leadin> Receive queues provide a means
	for several processes to receive from a single endpoint. The
	receive queue acts as a rendevous point for the receiving
	processes.  When a message is sent via the endpoint, the
	kernel will select a waiting process from the receive queue
	and deliver the message to that receiver. This permits kernel
	demultiplexing of receive processes, which enhances
	performance on multiprocessors.
      </p>
      <p>
	<leadin>Pages</leadin> Pages are the atomic unit of data and
	capability storage allocation. An address space consists of a
	lattice of GPTs whose leaves are pages. Pages are typed: a
	page may contain either data or capabilities, but not
	both. The size of a page is determined by the underlying
	hardware architecture.
      </p>
      <p>
	There are a small number of other kernel-implemented
	capabilities. These primarily provide protected transformation
	operations on capabilities.
      </p>
    </sect1>
    <sect1>
      <title>Entry Capabilities and Extensibility</title>
      <p>
	Endpoint objects have ``entry capabilities''. An entry
	capability does not implement operations on the
	endpoint. Instead, it provides the means by which an
	application introduces new services. Any invocation of an
	entry capability is delivered to the providing object server.
      </p>
    </sect1>
    <sect1 id="persistence">
      <title>Checkpointing and Persistence</title>
      <p>
	Coyotos is a persistent object system. Main memory is treated
	as a <em>cache</em> of a larger backing store. Objects are
	loaded from backing store on demand and are rewritten to the
	backing store as a consequence of age or checkpoint. Following
	a system restart, persistent objects retain their state as of
	the last checkpoint. A checkpoint saves a ``consistent cut''
	of the system. In consequence, processes are recovered in such
	a way that ongoing communications on the local machine may be
	resumed without recovery effort.
      </p>
      <p>
	<leadin>Secure Restart</leadin> On restart, any connection to
	the outside world is <em>severed</em> if continued
	communication on that connection might (conservatively)
	require re-authentication. In particular, network and terminal
	connections are terminated.
      </p>
      <p>
	<leadin>Lost Objects</leadin> One risk in this class of design
	is that objects may be permanently lost as a consequence of
	low-level storage failures (e.g. sector errors). When backing
	store is not already duplexed, the Coyotos object store
	implementation uses software duplexing of critical system
	structures. Applications may also use this mechanism if
	desired.
      </p>
    </sect1>
    <sect1>
      <title>Activations and Process States</title>
      <p>
	From the kernel perspective, a process has five run states:
	<term>blocked</term>, <term>faulted</term>,
	<term>receiving</term>, <term>ready</term>, and
	<term>running</term>.  A blocked process is waiting for a
	kernel resource. A ready process is attempting to execute
	instructions and is waiting for a CPU. A running process is
	currently executing.
      </p>
      <p>
	Orthogonal to these states is the process activation
	status. Coyotos implements a variant of the design proposed by
	March <foreignphrase>et al.</foreignphrase> in <em>First-Class
	User-Level Threads</em> <cite ref="marsh91firstclass"/>, and
	is similar to the <em>Scheduler Activations</em> design of
	Anderson <foreignphrase>et al.</foreignphrase> <cite
	ref="thomas90scheduler"/>.  Coyotos does not initiate all
	activations through the activation handler, but it does use
	the activation mechanism to allow a process to handle its own
	exceptions and to indicate events such as slice timeout that
	are of interest to real-time thread schedulers.
      </p>
      <p>
	The activation mechanism introduces two activation states:
	<term>normal</term> and <term>activated</term>. The activation
	state of a process is largely orthogonal to its run
	state. When the specification speaks of ``transitioning to the
	running state,'' the activation state of the process is
	unchanged unless a change is explicitly mentioned.
      </p>
<!--       <p> -->
<!-- 	At user level, a process has two states in which it may be -->
<!-- 	executing: the <term>normal</term> state and the -->
<!-- 	<term>activated</term> state. Incoming events are always -->
<!-- 	delivered in association with a transition from the normal to -->
<!-- 	the activated state. The activated state has a separate entry -->
<!-- 	point known as the <em>activation handler</em>. The activation -->
<!-- 	handler exists to make dispatching (or deferral) decisions -->
<!-- 	about incoming events. One possibility is that the activation -->
<!-- 	handler may elect to perform a user-level thread switch, and -->
<!-- 	therefore acts as a user-mode scheduling agent (which is how -->
<!-- 	these came to be known as <em>scheduler activations</em>.  The -->
<!-- 	user-level thread switch is kernel supported by placing the -->
<!-- 	register save area for user-mode registers in memory that is -->
<!-- 	shared between the kernel and the application and is readable -->
<!-- 	and writable to both. The kernel supports the activation -->
<!-- 	handler by handling register save in a mode-sensitive way on -->
<!-- 	kernel entry.  A scheduler activation may be thought of as a -->
<!-- 	kernel-implemented trap mechanism that operates entirely at -->
<!-- 	application level.  It is similar in concept to a single-level -->
<!-- 	hardware exception mechanism in a RISC processor. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	Another possible handling mechanism is that the activation -->
<!-- 	handler might simply enqueue the newly received message for -->
<!-- 	later processing and then resume the current user thread of -->
<!-- 	control without modification. In the latter design, the user -->
<!-- 	thread would typically execute in event-driven fashion until -->
<!-- 	all pending events are processed. -->
<!--       </p> -->
      <p>
	Both hardware and software exceptions incurred by a process in
	the <em>normal</em> state are delivered by transition to the
	<em>activated</em> state. Software-defined exceptions are used
	to encapsulate various events of interest, including slice
	expiration, and non-blocking interprocess signalling.
      </p>
    </sect1>
    <sect1>
      <title>Messages</title>
      <p>
<!-- 	Coyotos provides two types of messages: idempotent and -->
<!-- 	stateful.  -->
	From the sender perspective, message transmission is
	(nearly) atomic. From the receiver perspective, message
	transfer occurs asynchronously. Arrival is signalled by a
	message completion event delivered to the receiver's
	activation handler.
      </p>
      <p>
	<leadin>Relaxed Data Atomicity</leadin> Coyotos permits
	relaxed data atomicity for stateful messages. While a stateful
	receive is pending, the data bytes of the receive area are
	considered undefined and may be modified by the kernel to
	arbitrary values. When receipt has completed, the receive area
	is defined up to the kernel-provided length of the received
	message. The relaxed atomicity rule allows the kernel message
	send implementation to avoid a pre-probe pass on the received
	data area, which significantly improves performance. Note that
	the "undefined" rule explicitly does <em>not</em> apply to
	received capabilities. The complete set of capabilities (if
	any) transferred by a message are required to be transferred
	to receiver-controlled storage atomically. This requirement
	ensures that the inductive state transition requirements of
	the formal capability protection model are satisfied.
      </p>
<!--       <p> -->
<!-- 	<leadin>Idempotent Messages</leadin> An idempotent message is -->
<!-- 	one whose content is set by the receiver (in the FCRB). The -->
<!-- 	information conveyed by the arrival of an idempotent message -->
<!-- 	is the fact that it has been transmitted (fired) one or more -->
<!-- 	times by one or more senders since it was last received. If -->
<!-- 	the receiver is currently executing an activation from a -->
<!-- 	previous transmission of the same idempotent message at the -->
<!-- 	time of a subsequent send, the idempotent message will be -->
<!-- 	delivered again. Sends on idempotent message FCRBs do not -->
<!-- 	block. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	<leadin>Stateful messages</leadin> A stateful message is one -->
<!-- 	where the sender defines the message payload and the receiver -->
<!-- 	specifies (via a stateful FCRB) the location(s) in the -->
<!-- 	receiver address space where the payload should be -->
<!-- 	delivered. A stateful receive FCRB may be either -->
<!-- 	<em>pending</em> or <em>delivered</em>. A send operation on a -->
<!-- 	stateful FCRB will not make progress until that FCRB becomes -->
<!-- 	pending. On completion, it causes the FCRB state to transition -->
<!-- 	from pending to delivered. The receiver must explicitly reset -->
<!-- 	the FCRB state before subsequent attempts to send on that FCRB -->
<!-- 	will make progress. This ensures that the received message -->
<!-- 	payload cannot be overwritten by successive senders before -->
<!-- 	processing. -->
<!--       </p> -->
      <p>
	<leadin>Blocking Send</leadin> A blocking send guarantees
	eventual delivery provided the operation completes and the
	receiver is not destroyed before delivery. Page faults at the
	receiver's designated receive location(s) will be delivered to
	the receiver-designated fault handlers as required. When fault
	handling has completed, the sender will retry the send
	operation from the beginning. Senders may implement watchdog
	timeouts on send operations by arranging to send themselves an
	idempotent message after a preset delay.
      </p>
      <p>
	<leadin>Non-blocking Send</leadin> A non-blocking send will be
	silently discarded if any condition arises that would cause a
	blocking send to block.  It will be truncated if a receiver
	page fault occurs during transmission. If truncation occurs,
	the receiver is notified of the partial delivery.
      </p>
    </sect1>
    <sect1>
      <title>Naming and Invocation</title>
      <p>
	Coyotos objects are named by capabilities. A capability is a
	kernel-protected value that names a resource and identifies
	some interface (equivalently: facet or object) of that
	resource. The interface in turn defines methods that the
	invoker can invoke by sending a message specifying the
	corresponding method code point. Thus, every invocation
	consists of a message send to a particular method of a
	particular interface of a particular resource, performed by
	invoking a capability. This is true both for
	server-implemented interfaces and kernel-implemented
	interfaces.
      </p>
      <p>
	The Coyotos invocation mechanism is derived in part from the
	EROS design. The invocation payload has been enriched, but the
	invocation state model has been simplified. An invocation
	consists of a send phase followed by an optional asynchronous
	receive phase. The send phase may specify blocking or
	non-blocking behavior. If a non-blocking send is unable to
	make immediate progress, its message payload is truncated or
	dropped. The receive phase, if present, blocks until an
	incoming message arrives, and can optionally require that the
	incoming message arrive on a particular endpoint identifier.
      </p>
      <p>
	The Coyotos kernel implements only one major system call:
	<progident>InvokeCap</progident>.  A small number of
	additional system calls exist to implement pseudo-instructions
	such as capability load and store.
      </p>
      <p>
	Entry capabilities contain a 32-bit protected payload
	field. The endpoints that they name contain a 64-bit endpoint
	identifier. Both values are delivered to the recipient as part
	of an incoming message. Neither is readable or modifiable by
	the capability's invoker. Servers may use these values to
	distinguish interfaces, object identities, permissions, or
	other desired characteristic.
      </p>
    </sect1>
    <sect1>
      <title>Exception and Interrupt Handling</title>
      <p>
	For reasons of performance, the Coyotos kernel handles
	scheduling-related interrrupts directly. It does not specify
	or implement a policy for other interrupt handling. The kernel
	maintains a capability-named interface for interrupt handler
	registry. With the exception of low-level scheduling
	preemption, all policy and processing associated with
	interrupts is handled by application-level code.
      </p>
      <p>
	The Coyotos kernel also pushes responsibility for exception
	handling policy to application level. When runtime application
	exceptions occur, the kernel delivers the state associated
	with the exception as an activation, either to the offending
	process's activation handler or to an external fault handler
	designated by an endpoint.
      </p>
    </sect1>
    <sect1>
      <title>Protection Model</title>
      <p>
	An essential part of the security microkernel concept is that
	security policy &mdash; including mandatory security policy
	&mdash; should be implemented by application code. The code
	that enforces system-wide policy needs to be protected and
	must not be evaded, but it does not necessarily need to run in
	supervisor mode.
      </p>
      <p>
	In keeping with this philosophy, the Coyotos kernel does not
	implement a security policy. Coyotos provides primitive
	protection support in the form of protected
	capabilities. Applications can invoke services only by
	invoking capabilities. Capabilities are kernel protected, and
	can be obtained only by transfer over capability-authorized
	channels. It has been shown formally that this restriction is
	sufficient to support (overt) confinement of subsystems <cite
	ref="shap00verifying"/>, and that given overt confinement, a
	higher-level security policy can be implemented either by
	construction or by an application-level reference monitor
	<cite ref="KeyKOS:KeySafe"/>.
      </p>
      <p>
	A useful property of capability systems is that they directly
	express the ``relies-on'' relationships between components. If
	an object or subsystem <em>A</em> depends directly on a second
	object or subsystm <em>B</em> for its operation, then
	<em>A</em> necessarily holds a capability to <em>B</em>. In
	the absence of such a capability, <em>A</em> cannot invoke
	<em>B</em> at all (or even know if the existence of
	<em>B</em>). A key point here is that <em>A</em> may rely on
	<em>B</em> only in a qualified way, and (in some cases) may be
	able to take measures to guard against failures or hostility
	from <em>B</em>. This allows applications to take direct
	responsibility for their dependencies, and also to impose
	context-sensitive access restrictions on their providers.
      </p>
      <p>
	For this reason, we try to avoid the term ``trust'' in our
	designs, preferring instead to use ``relies on.''
      </p>
    </sect1>
  </chapter>
  <part>
    <title>Microkernel Abstractions</title>
    <chapter id="Capabilities">
      <title>Capabilities</title>
      <p>
	The Coyotos kernel implements a number of object types, each
	of which has a corresponding capability type:
      </p>
      <table latex.center="yes" id="cap_types" latex.colspec="llp{3.4in}l">
	<thead>
	  <tr>
	    <td><b>Encoding</b></td>
	    <td><b>Type</b></td>
	    <td><b>Description</b></td>
	    <td><b>Restrictions</b></td>
	  </tr>
	</thead>
	<tbody>
	  <tr>
	    <td>0</td>
	    <td>Null</td>
	    <td>
	      <p>
		Universal, invalid capability.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>1</td>
	    <td>Window</td>
	    <td>
	      <p>
		A local mapping window (Chapter&nbsp;<xref
		ref="AddressSpaces"/>).
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>2</td>
	    <td>Background</td>
	    <td>
	      <p>
		A background mapping window (Chapter&nbsp;<xref
		ref="AddressSpaces"/>).
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>3</td>
	    <td>KeyBits</td>
	    <td>
	      <p>
		Discloses the bit representation of
		capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>4</td>
	    <td>Discrim</td>
	    <td>
	      <p>
		Classifies capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>5</td>
	    <td>Range</td>
	    <td>
	      <p>
		Fabricates object capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>6</td>
	    <td>Sleep</td>
	    <td>
	      <p>
		Interface to the kernel interval timer.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>7</td>
	    <td>IRQ Control</td>
	    <td>
	      <p>
		Interrupt request line control interface.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>8</td>
	    <td>Schedule Control</td>
	    <td>
	      <p>
		Interface to the kernel master scheduling
		table.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>9</td>
	    <td>Checkpoint</td>
	    <td>
	      <p>
		Control capability for the kernel
		checkpoint mechanism.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>10</td>
	    <td>ObStore</td>
	    <td>
	      <p>
		Interface between kernel and object store
		manager.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>11</td>
	    <td>Pin Control</td>
	    <td>
	      <p>
		Permission to pin objects in memory.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td><em>13-31</em></td>
	    <td><em>Reserved</em></td>
	    <td>
	      <p>
		<em>Encodings reserved for future use.</em>
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>32</td>
	    <td>Endpoint</td>
	    <td>
	      <p>
		Control capability for an endpoint.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>33</td>
	    <td>Receive Queue</td>
	    <td>
	      <p>
		Control capability for a receive queue.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>34</td>
	    <td>Page</td>
	    <td>
	      <p>
		Data page. The size of a page is determined by the
		underlying hardware page size.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>35</td>
	    <td>CapPage</td>
	    <td>
	      <p>
		Capability page. The size of a capability page is
		determined by the page size of the underlying
		hardware page size.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>36</td>
	    <td>GPT</td>
	    <td>
	      <p>
		Guarded Page Table. Used to compose
		larger address spaces from pages.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK,OP
	    </td>
	  </tr>
	  <tr>
	    <td>38</td>
	    <td>Process</td>
	    <td>
	      <p>
		Capability that manipulates the kernel process
		abstraction.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>39</td>
	    <td>AppNotice</td>
	    <td>
	      <p>
		Capability that permits posting of non-blocking,
		application-defined software notices.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td><em>40-62</em></td>
	    <td><em>Reserved</em></td>
	    <td>
	      <p>
		<em>Encodings reserved for future use.</em>
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>63</td>
	    <td>Entry</td>
	    <td>
	      <p>
		Authority to send to the process designated by an Endpoint.
	      </p>
	    </td>
	  </tr>
	</tbody>
      </table>
      <p>
	The <term>RO</term>, <term>NX</term>, <term>WK</term>, and 
	<term>OP</term> restrictions respectively indicate, read-only,
	non-executable, weak, and opaque permission restrictions. These
	are described in detail in the chapter on address spaces.
      </p>
      <sect1 id="caprep">
	<title>Representation</title>
	<p>
	  A capability is 16 bytes, and uses the same representation
	  on both 32-bit and 64-bit platforms.  The capability
	  structure is a ``tagged union'' whose details depend on the
	  capability type field. The kernel is entitled to use
	  optimized representations internally. The representation
	  given below is the representation disclosed by KeyBits,
	  which is the representation typically used on disk.
	</p>
	<p>
	  Except where otherwise indicated, reserved fields must be
	  zero-filled. The <term>P</term> (prepared) bit and the
	  <term>hz</term> (hazard) bit are kernel internal, and are
	  always zeroed by <progident>keybits</progident> when the
	  capability representation is returned.
	</p>
	<sect2 id="memcaps">
	  <title>Capabilities to Memory Objects</title>
	  <p>
	    Memory capabilities include page, cappage, GPT, local
	    window capabilities, and background window
	    capabilities. All of these are used to describe portions
	    of the address space.  The format of page, cappage, and
	    GPT capabilities is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-mem" width="75" srctype="sbox"/>
	    <caption>Memory object capability</caption>
	  </figure>
	  <p>
	    The format of a window capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-window" width="75" srctype="sbox"/>
	    <caption>Mapping window capability</caption>
	  </figure>
	  <p indent="no">
	    The <em>rootSlot</em> field of the window capability is used
	    only for local window capabilities, this field is reserved
	    in background window capabilities.
	  </p>
	  <p indent="no">
	    <leadin>Invariant:</leadin>
	    <progident>l2g&nbsp;&le;&nbsp;64</progident><br/>
	    <leadin>Invariant:</leadin>
	    <progident>(l2g&nbsp;==&nbsp;64)&nbsp;&rArr;&nbsp;(guard&nbsp;==&nbsp;0)</progident><footnote>
	      <p>This invariant
		ensures that no bounds check is required before
		performing C shift operations whose size equals the
		machine word size. On most architectures such shift
		operations truncate the shift amount, but if the value
		being shifted is zero any shift (including none at all)
		will produce the right answer during address space
		traversal.</p>
	    </footnote><br/> 
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(C&nbsp;==&nbsp;1)&nbsp;&rArr;&nbsp;(l2g&nbsp;-&nbsp;l2v)&nbsp;&les;&nbsp;3</progident><br/> -->
	    <leadin>Invariant:</leadin>
	    <progident>((guard&nbsp;&lt;&lt;&nbsp;l2g)&nbsp;&gt;&gt;&nbsp;l2g)&nbsp;==&nbsp;guard</progident><footnote>
	      <p>This invariant ensures that any bits of the guard
		value that would appear (after the normalizing shift)
	    above the highest valid bit position in an address must be
	    zero.</p>
	    </footnote><br/>
	    <leadin>Invariant:</leadin>
	    <progident>l2g&nbsp;&ge;&nbsp;log2(<em>page&nbsp;size</em>)</progident><br/>
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>l2g&nbsp;&ge;&nbsp;l2v</progident><br/> -->
	    <leadin>Invariant:</leadin>
	    <progident>(offset&nbsp;mod&nbsp;2<sup>l2g</sup>)&nbsp;==&nbsp;0</progident><br/>
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(l2g&nbsp;-&nbsp;l2v)&nbsp;&les;&nbsp;4</progident><br/> -->
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(type&nbsp;==&nbsp;Page)&nbsp;&rArr;&nbsp;(l2g&nbsp;==&nbsp;l2v)</progident><br/> -->
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(type&nbsp;==&nbsp;CapPage)&nbsp;&rArr;&nbsp;(l2g&nbsp;==&nbsp;l2v)</progident> -->
	  </p>
	  <p indent="no">
	    These invariants are ensured by the operations that
	    fabricate the respective capabilities. The balance of the
	    system is entitled to assume that they hold.
	  </p>
	  <p>
	    When traversing a memory capability, the virtual address
	    <progident>va</progident> is defined as the bitwise
	    concatenation of three fields
	    <progident>g+u+v</progident>, where
	    <progident>g</progident> is a variable length,
	    possibly empty bit string that will be used as a guard
	    value,
	    <progident>u</progident> is a variable length, possibly
	    empty bit string that will be
	    used to index into the slots of the named GPT (if any),
	    and <progident>v</progident> is the virtual address that
	    will remain to be translated at the next step (if any).
	    The length <progident>|v|</progident> is determined by the
	    <progident>l2v</progident> field of the named Page,
	    CapPage, or GPT.
	    The capability field
	    <progident>l2g</progident> contains length of the bit string
	    <progident>|u+v|</progident>. The value of the
	    effective guard is a multiple of
	    <progident>2<sup>l2g</sup></progident>.
	    For page and capability page capabilities, the value
	    <progident>l2g</progident> also specifies the target page
	    size. This is possible because neither
	    pages nor capability pages have slots to be indexed.
	  </p>
	</sect2>
	<sect2 id="msgcaps">
	  <title>Message-Related Capabilities</title>
	  <p>
	    Endpoint capabilities currently do not carry permission
	    bits, but are otherwise similar in layout to memory
	    capabilities. The protected payload field is reserved in
	    the respective control capabilities, and should be zero.
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-message" width="75" srctype="sbox"/>
	    <caption>Endpoint capability</caption>
	  </figure>
	  <p>
	    Invocations of an endpoint capability ignore the protected
	    payload and provide access to the kernel-implemented
	    object. Invocations of an Entry capability are delivered
	    to an implementing process designated by the endpoint. The
	    protected payload field of the endpoint capability is
	    provided as an additional output of the invocation.
	  </p>
	</sect2>
	<sect2 id="processcaps">
	  <title>Capabilities to Processes</title>
	  <p>
	    The format of a process capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-process" width="75" srctype="sbox"/>
	    <caption>Process capability</caption>
	  </figure>
	</sect2>
	<sect2 id="misccaps">
	  <title>Miscellaneous Capabilities</title>
	  <p>
	    The format of a miscellaneous capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-misc" width="75" srctype="sbox"/>
	    <caption>Miscellaneous capability</caption>
	  </figure>
	</sect2>
      </sect1>
      <sect1 id="cap_validity">
	<title>Valid Capabilities</title>
	<p>
	  Wherever this specification refers to a capability of a
	  specific type, it should be taken to mean a <em>valid</em>
	  capability of the stated type.  The meaning of an invocation
	  of a valid capability is determined by its implementation
	  provider (kernel or server).
	</p>
	<p>
	  A non-object capability is any capability whose external
	  representation does not include an allocation count.  A
	  non-object capability is always valid. Non-object
	  capabilities are not revocable.
	</p>
	<p>
	  All other capabilities are object capabilities. An object
	  capability is valid if and only if all of the following
	  conditions are met:
	</p>
	<ul>
	  <li>
	    <p>
	      There exists some object with a matching object
	      identifier (OID) whose type is compatible with the type
	      of the capability.<footnote>
		<p>
		  This specification intentionally does not take a
		  position on whether OIDs are globally unique or only
		  unique with respect to objects of compatible
		  representation type. This choice is left to the
		  implementation.
		</p>
	      </footnote>
	    </p>
	    <p>
	      This condition may be violated if backing store is lost
	      or corrupted, or through a bug in the object manager.
	    </p>
	  </li>
	  <li>
	    <p>
	      The allocation count in the capability matches the
	      allocation count in the object.
	    </p>
	    <p>
	      This condition ceases to be true when an object is
	      revoked (see <link
	      href="#coyotos.range.rescind"><progident>coyotos.range.rescind</progident></link>).
	    </p>
	  </li>
	  <li>
	    <p>
	      In the case of an endpoint capability whose
	      <progident>PM</progident> bit is set, the protected
	      payload field of the endpoint capability matches the
	      protected payload field of the endpoint object that it
	      names.
	    </p>
	  </li>
	</ul>
	<p>
	  All other object capabilities are invalid.  An invalid
	  capability behaves in all observable respects as if it were
	  the <link href="#coyotos.null">Null capability</link>. This
	  applies both to invocation of an invalid capability and to
	  operations that act on invalid capabilities (notably <link
	  href="#coyotos.keybits">KeyBits</link>, which has
	  implications for debugging invalid capabilities). The kernel
	  is free to overwrite any capability location with a Null
	  capability when it determines that the capability contained
	  in that location is invalid.
	</p>
      </sect1>
      <sect1 id="capability_prepare">
	<title>Capability Prepare</title>
	<p>
	  Coyotos is an object paging system. Both object load and
	  object unload are driven by the use of
	  capabilities. Ignoring latency, this paging behavior is
	  normally invisible to applications. The exception is that
	  object page-in may reveal low-level storage failures that
	  make an object unrecoverable.
	</p>
	<p>
	  Whenever a capability is used, the kernel internally
	  performs a <em>prepare</em> operation on the
	  capability. Conceptually, this prepare step is being done by
	  the process that is performing the current system call. The
	  prepare operation may have several outcomes:
	</p>
	<ul>
	  <li>
	    <p>
	      If the capability is a non-object capability, the
	      prepare operation succeeds (by definition).
	    </p>
	  </li>
	  <li>
	    <p>
	      If the capability names an object, but its
	      <progident>allocCount</progident> does not match the
	      <progident>allocCount</progident> of the corresponding
	      object, the capability is re-written (in place) to the
	      Null capability.
	    </p>
	    <p>
	      The containing object is not marked modified. If
	      other operations cause the containing object to be
	      modified, the Null capability will be written to
	      disk. Otherwise, subsequent reloads of the object
	      will re-obtain the stale capability and this check
	      will be performed again with the same result.
	    </p>
	    <p>
	      Several optimizations and mechanisms are used to ensure
	      that the disk allocation count does not overflow.
	    </p>
	  </li>
	  <li>
	    <p>
	      If the object named by the capability is not in memory,
	      steps are taken to load it. The preparing process is
	      enqueued to wait for the completion of this request, and
	      re-starts its operation when the object has been loaded.
	      In rare cases, this step may result in an
	      <progident>ObjectContentLost</progident> exception if
	      the backing store has experienced an unrecoverable
	      storage error.
	    </p>
	  </li>
	  <li>
	    <p>
	      If the object named by the capability is in memory, it
	      is locked for the duration of the current system call
	      unless they are unlocked explicitly.
	    </p>
	  </li>
	</ul>
	<p>
	  A capability is ``used'' if:
	</p>
	<ul>
	  <li>
	    <p>
	      The capability is invoked by the current system call.
	    </p>
	  </li>
	  <li>
	    <p>
	      The capability designates the invokee of the current
	      system call.
	    </p>
	  </li>
	  <li>
	    <p>
	      Fetching a capability argument or storing a capability
	      result requires memory traversal, in which case all
	      capabilities in the traversed slots are used.
	    </p>
	  </li>
	  <li>
	    <p>
	      The operation requested by the current system call
	      accesses or mutates the target object of the capability.
	    </p>
	  </li>
	</ul>
	<p>
	  Coyotos implementations are required to be atomic. This
	  implies that all resource acquisitions (and therefore all
	  capability prepares) must be acquired before any observable
	  side-effect of a system call occurs.
	</p>
      </sect1>
      <sect1>
	<title>Extensibility</title>
	<p>
	  Coyotos is an extensible object system in the sense of Hydra
	  <cite ref="wulf1974hydra"/>.  New objects may be introduced
	  by designing a process that implements the desired
	  object. Capabilities to these objects are implemented as
	  Entry capabilities. The kernel checks these capabilities
	  for validity, and optionally for a protected payload match
	  (see Chapter&nbsp;<xref ref="invocation"/>), but does not
	  otherwise define semantics for these capabilities.
	</p>
	<p>
	  Because the kernel does not know the semantics of these
	  extensions, entry capabilities are not considered ``safe''
	  by the <link
	  href="#coyotos.discrim.classify"><progident>coyotos.discrim.classify</progident></link>
	  operation.
	</p>
      </sect1>
    </chapter>
    <chapter id="processes">
      <title>Processes</title>
      <p>
	A Coyotos process provides an abstraction of the user-mode
	execution engine presented by the underlying
	microprocessor. From the kernel perspective, a process is the
	unit that is dispatched by the kernel for execution.
      </p>
      <p>
	Coyotos does not distinguish between processes and threads. A
	process encapsulates a single kernel thread of
	execution. Coyotos address spaces are first-class objects. Two
	(or more) processes may be constructed that designate the same
	address space. This achieves concurrent
	execution of multiple kernel threads of control within a
	common addressing environment and resource pool.
      </p>
      <p>
	Coyotos implements the system calls described in
	Chapter&nbsp;<xref ref="syscalls"/>. Most of these should be
	viewed as software-defined instructions. The exception is the
	<progident>InvokeCap</progident> system call, which performs
	capability invocation (see Chapter&nbsp;<xref
	ref="invocation"/>). The majority of the kernel's function is
	provided in the form of kernel-implemented objects
	(equivalently: services) that are named by capabilities. These
	services are invoked in the usual way by invoking their
	capabilities.
      </p>
      <sect1 id="proc_state">
	<title>State of a Process</title>
	<p>
	  The state of a process may be divided conceptually into
	  kernel (privileged or sensitive) state and user
	  (non-privileged) state. <term>User state</term> is that
	  state which a process may modify directly without kernel
	  intervention. This includes architecture-defined
	  non-privileged register state. It also includes additional
	  ``pseudo registers'' defined by Coyotos that support the
	  activation handling mechanism and the capability invocation
	  system call.
	</p>
	<p>
	  <term>Kernel state</term> is that state which records or
	  discloses protection information, or for which the kernel
	  must guarantee invariants for reasons of security,
	  robustness, or operational consistency. The representation
	  of capabilities, for example, is kernel state. The Coyotos
	  process structure contains space to save both the kernel
	  state and the user state of a process.
	</p>
	<p>
	  On some hardware architectures, the separation between
	  kernel state and user state is not cleanly accomplished by
	  the architecture. The most common examples of this involve
	  design failures in the architected processor status word.
	  The IA-32 <smallcaps>eflags</smallcaps> register, for
	  example, includes state such as the supervisor mode bit and
	  the current ``IO privilege level.'' Such fields present a
	  problem because the balance of the
	  <smallcaps>eflags</smallcaps> register must be modifiable by
	  untrusted code. When an unprivileged application runs normal
	  instructions, the hardware generally protects these bits
	  from modification. On such architectures, Coyotos must
	  ensure that any registers modified by get/set registers and
	  similar operations properly protect these fields. The
	  architecture-specific annex for each architecture identifies
	  any such registers and their update constraints.
	</p>
	<sect2 id="proc_kernel_state">
	  <title>Per-process State</title>
	  <figure id="fig:kpcb" latex.position="htb">
	    <img source="process" width="75" srctype="sbox"/>
	    <caption>Per-Process kernel state</caption>
	  </figure>
	  <p>
	    Each process has the following state:
	  </p>
	  <ul>
	    <li>
	      <p>
		The process flags word. This word contains the process
		run state and several bits that control fault-related
		and debugging-related behavior.
	      </p>
	    </li>
	    <li>
	      <p>
		A software-defined interrupt bitfield,
		<term>softInts</term>, indicating (by bit position)
		the software-defined interrupts that are pending for
		this process.
	      </p>
	    </li>
	    <li>
	      <p>
		32 capability ``registers'' that are implemented in
		software by the Coyotos kernel.
	      </p>
	    </li>
	    <li>
	      <p>
		Capability slots that support process recognition and
		identification: <term>brand</term> and the
		<term>cohort</term>.
	      </p>
	    </li>
	    <li>
	      <p>
		Capability slots that identify resources on which the
		process depends: the address space, the schedule, and
		the external fault handler.
	      </p>
	      <p>
		Coyotos address spaces are
		``first class''. An address space may exist without
		having any associated process. Multiple processes may
		name the same address space by placing the same
		address space capability in their respective address
		space slots. Schedules are similarly ``first class.''
	      </p>
	    </li>
	    <li>
	      <p>
		Slots related to exception handling.
	      </p>
	      <p>
		The <term>faultCode</term>
		and <term>faultInfo</term> are conceptually
		similar to the underlying hardware processor's
		exception registers. A process-incurred exception
		causes these registers to be updated with the
		information necessary for error diagnosis and possible
		resolution. The exception fault code space unifies
		both hardware-defined and kernel-defined exceptions
		into a single code point space.
	      </p>
	      <p>
		The <term>handler</term> capability slot contains an
		entry capability to the external fault handler (if
		any). This is an external process that should be
		notified whenever this process incurs a fault.
	      </p>
	    </li>
	    <li>
	      <p>
		Storage for the architecture-defined non-privileged
		register set. Access to these registers is by means of
		invocations on the architecture-specific process
		capability.
	      </p>
	    </li>
	    <li>
	      <p>
		Slots related to capability invocation and IPC, which
		are discussed in Chapter&nbsp;<xref
		ref="invocation"/>: the message scratchpad and receive
		parameter location registers
		(<term>rcvParam[]</term>). The values of these slots
		are typically updated by the
		<progident>InvokeCap</progident> system call. They can
		also be copied or updated through get and set
		operations supplied by the process capability.
	      </p>
	    </li>
	  </ul>
	  <p>
	    The per-process capability state, fault code, and
	    fault information can be accessed and manipulated only
	    through invocations of the process capability. 
	  </p>
	  <p>
	    The process flags word is shown in Figure&nbsp;<xref
	    ref="fig:proc-flags"/>.  The fields of the flags word have
	    the following meanings:
	  </p>
	  <figure id="fig:proc-flags" latex.position="h">
	    <img source="proc-flags" width="65" srctype="sbox"/>
	    <caption>Process flags word</caption>
	  </figure>
	  <table latex.long="yes" latex.center="yes" latex.colspec="lp{5.5in}">
	    <thead>
	      <tr>
		<td><b>Field</b></td>
		<td><b>Meaning</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td><term>XM</term></td>
		<td>
		  <p>
		    <leadin>Execution Model</leadin> indicates whether
		    this process uses a 32-bit (0) or 64-bit (1)
		    execution model.  This bit is significant mainly
		    on architectures having multiple execution models,
		    such as <progident>amd64</progident>.  It controls
		    certain aspects of cross-model invocations.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>SX</term></td>
		<td>
		  <p>
		    <leadin>Slice Expired</leadin> This bit is set by
		    the kernel when the process's real-time slice has
		    expired. The slice expired event is considered an
		    application-defined interrupt. Use and delivery of
		    the <term>sx</term> notification is discussed in
		    Chapter&nbsp;<xref ref="scheduling"/>.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>SN</term></td>
		<td>
		  <p>
		    <leadin>Soft Notice</leadin>
		    This bit is set by the kernel whenever a
		    new bit is set in the pending
		    application-defined notices field.  It
		    signals that the handler should be
		    dispatched in the activated state with an
		    <progident>AppNotice</progident> exception if
		    no exceptions are pending when it is next
		    dispatched.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>TC</term></td>
		<td>
		  <p>
		    <leadin>Trap On Call</leadin> indicates that the
		    process should incur a ``trap on syscall exception
		    when it attempts to perform a system call. This
		    trap will occur <em>after</em> registers have been
		    saved to the process structure, but
		    <em>before</em> arguments have been examined by
		    the kernel. In particular, the system call number
		    will not yet have been examined by the kernel.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>TR</term></td>
		<td>
		  <p>
		    <leadin>Trap On Return</leadin> indicates that the
		    process should incur a ``trap on system call
		    return exception when it exits or bypasses the
		    receive state following a successful
		    invocation. This trap occurs just <em>after</em>
		    the parameter words (if any) have been copied out
		    to the application.  In consequence, it occurs
		    after any associated exceptions are processed by
		    the recipient.  Control has not been returned to
		    the receiver.
		  </p>
		  <p>
		    If this bit is set at process system call return,
		    a <progident>process.FC_SysCallReturn</progident>
		    fault will be set in the process state just prior
		    to returning.  The
		    <progident>process.resume()</progident> does not
		    cause the invokee to resume in the system call
		    exit path, so this exception will not re-occur on
		    resumption.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>CS</term></td>
		<td>
		  <p>
		    <leadin>Call Step</leadin> if set (1), indicate
		    thats the <term>tc</term> bit should be ignored at
		    the next point where it would normally take
		    effect.
		  </p>
		  <p>
		    This bit is set as a side effect of the
		    <progident>process.resume()</progident> operation
		    if the currently pending fault code is
		    <progident>process.FC_SysCallEntry</progident>.
		    It is cleared whenever the process proceeds
		    successfully to the commit point of the current
		    system call.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>PC</term></td>
		<td>
		  <p>
		    <leadin>Parameter Copyout</leadin> This bit is set
		    by the kernel whenever a parameter copyout from
		    the parameter scratchpad area is required before
		    resuming user-mode execution of the current
		    process.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>runState</term></td>
		<td>
		  <p>
		    The process run state. Indicates whether the
		    process is running (0), receiving (1), or stopped
		    (2).
		  </p>
		</td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
	<sect2 id="proc_act_state">
	  <title>Activation Save Area</title>
	  <p>
	    The <term>actSaveArea</term> field of the kernel Process
	    structure is a pointer value that is set by the
	    application. It defines the user-mode address where
	    certain registers should be saved when transitioning
	    control to the in-process fault handler when an exception
	    is incurred. If this field is NULL (0), no transition to
	    an in-process handler will be attempted.
	  </p>
	  <p>
	    If the field is non-null, the kernel will
	    <em>reference</em> the structure at this address to
	    determine how exception information should be delivered.
	    The address indicated by <term>actSaveArea</term> should
	    point to the structure show in Figure&nbsp;<xref
	    ref="fig:actstate"/>. The architecture-specific annex may
	    define additional registers to be saved. The save area
	    structure must be word aligned.  If, during activation
	    state copyout, a page fault is incurred, the kernel will
	    attempt to deliver a page fault exception to the
	    <em>external</em> fault handler if one is defined.
	  </p>
	  <p>
	    The use and interpretation of the activation save area
	    fields is described in Section&nbsp;<xref
	    ref="ExceptionDelivery"/>.
	  </p>
	  <figure id="fig:actstate" latex.position="thb">
	    <img source="proc-actstate" width="75" srctype="sbox"/>
	    <caption>Activation process state</caption>
	  </figure>
	</sect2>
      </sect1>
      <sect1 id="proc_exec_model">
	<title>Execution Model</title>
	<p>
	  The instruction set available to a Coyotos process consists
	  of the user mode (non-privileged) instruction set of the
	  underlying processor architecture, the kernel-implemented
	  <progident>InvokeCap</progident> instruction (which
	  is the subject of Chapter&nbsp;<xref ref="invocation"/>).
	</p>
	<p>
	  From the perspective of the kernel, a process exists in one
	  of the following run states:
	</p>
	<deflist>
	  <defli>
	    <label><term>blocked</term></label>
	    <li>
	      <p>
		Process is attempting to send, but is blocked
		availability of a kernel resource. Process has no
		current or pending software interrupts. On release,
		process will resume in the <em>ready</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>receiving</term></label>
	    <li>
	      <p>
		Process is waiting for an incoming message from an
		endpoint, and has no current or pending software
		interrupts. On receipt, process will resume in the
		<em>ready</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>ready</term></label>
	    <li>
	      <p>
		Process is attempting to execute instructions. Process
		may have current or pending software
		interrupts. Pending exceptions will be delivered when
		the process transitions to the <em>running</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>faulted</term></label>
	    <li>
	      <p>
		Process has incurred an exception that has been
		reported to the external fault handler designated by
		the process's <progident>handler</progident>
		capability. Process will not executing instructions.
	      </p>
	    </li>
	  </defli>
	</deflist>
	<p>
	  Orthogonal to these states, a process may be in the
	  <em>activated</em> or <em>normal</em> activation state.  The
	  state transition diagram is shown in Figure&nbsp;<xref
	  ref="fig.transition"/>.
	</p>
	<figure id="fig.transition" latex.placement="bth">
	  <img source="transitions" width="65" srctype="gif"/>
	  <caption>Process state transitions</caption>
	</figure>
	<p>
	  The <em>blocked</em> state is not externally observable. A
	  blocked process has an externally reported
	  <progident>runState</progident> of ``running''. Such a
	  process is deemed to be running without making progress or
	  consuming CPU cycles.  The <em>faulted</em> state is
	  externally reported as a <progident>runState</progident> of
	  ``stopped'' with a non-zero fault code.
	</p>
	<p>
	  A process that is in the <em>running</em> state will
	  initiate instructions as long as its process
	  <progident>faultCode</progident> field is set to
	  <progident>FC_NoFault</progident> (0). Execution behavior
	  when any other value is stored in the
	  <progident>faultCode</progident> field is discussed in
	  Section&nbsp;<xref ref="ExceptionHandling"/>.
	</p>
      </sect1>
      <sect1 id="ExceptionHandling">
	<title>Exception Handling</title>
	<p>
	  An exception occurs as the result of an instruction executed
	  by the process.  Every exception has an associated fault
	  code. Specific exceptions may define an additional pointer
	  value to be delivered as additional fault information. The
	  fault code and fault information are delivered to the
	  process by storing them in the
	  <progident>faultCode</progident> and
	  <progident>faultInfo</progident> fields of the KPCB and
	  causing the process to resume execution.
	</p>
	<sect2 id="ExceptionDelivery">
	  <title>Exception Delivery</title>
	  <p>
	    When a process attempts to initiate instructions with a
	    <progident>faultCode</progident> other than
	    <progident>FC_NoFault</progident>, the behavior depends on
	    the value of the <progident>actSaveArea</progident> field:
	  </p>
	  <ul>
	    <li>
	      <p>
		If <progident>actSaveArea</progident> is non-null, and
		the <progident>actSaveArea-&gt;flags.a</progident> bit
		is clear (0), then:
	      </p>
	      <ol>
		<li>
		  <p>
		    The current program counter, stack pointer, flags
		    register (processor status word),
		    <progident>faultCode</progident>, and
		    <progident>faultInfo</progident>, and
		    <progident>softInts</progident> fields are copied
		    to the activation save area. The
		    <progident>SN</progident> and
		    <progident>SX</progident> bit values are copied
		    from the process flags to the activation save area
		    flags. The <progident>a</progident> bit of the
		    activation save area is set.
		  </p>
		</li>
		<li>
		  <p>
		    The values of <progident>aEntryPC</progident>,
		    <progident>aEntrySP</progident>, and
		    <progident>aEntryFlags</progident> in the
		    activation save area are copied to the program
		    counter, stack pointer, and flags fields the
		    in-kernel process structure (respectively).
		  </p>
		</li>
		<li>
		  <p>
		    The <progident>softInts</progident>,
		    <progident>SN</progident>,
		    <progident>SX</progident>,
		    <progident>faultCode</progident>, and
		    <progident>faultInfo</progident>, fields of the
		    in-kernel process structure are cleared.
		  </p>
		</li>
		<li>
		  <p>
		    The process is now dispatched normally.
		  </p>
		</li>
	      </ol>
	      <p>
		The copyin step is performed in such a way that
		exceptions are recoverable without losing the process
		state. If a page fault occurs during the copyout or
		copyin steps, an <progident>ActivationFail</progident>
		exception is reported to the external handler
		providing the page fault address as its fault
		information (this is, in effect, a type of ``double
		fault'').  In this case the
		<progident>faultCode</progident> and
		<progident>faultInfo</progident> fields of the kernel
		process structure retain their original fault
		information. Debuggers resuming a process after an
		<progident>ActivationFail</progident> fault should
		take care <em>not</em> to clear the fault code if
		delivery of the original fault to the activation
		handler is still desired.
	      </p>
	    </li>
	    <li>
	      <p>
		Otherwise, the following actions are taken in
		sequence:
	      </p>
	      <ol>
		<li>
		  <p>
		    If an Entry capability is stored in the
		    process's <progident>handler</progident> slot, the
		    kernel synthesizes a message to this endpoint on
		    behalf of the faulting process. The message will
		    provide the <progident>faultCode</progident> and
		    <progident>faultInfo</progident> values and a
		    process capability to the faulted
		    process. Disposition of the faulted process is now
		    at the discretion of the fault handler.
		  </p>
		  <p>
		    If the handler process is blocked, handler message
		    delivery will be re-attempted when the external
		    handler process becomes unblocked.
		  </p>
		</li>
		<li>
		  <p>
		    The process enters the <em>faulted</em> state
		    (runState = stopped) and ceases to execute
		    instructions.
		  </p>
		</li>
	      </ol>
	      <p>
		In the absence of a specified external handler, a
		process attempting to deliver a fault notification to its
		external handler will effectively cease to execute
		instructions without notice to anyone. It is the
		reponsibility of the programmer to ensure that an
		external handler capability is defined if noticing
		this condition is required.
	      </p>
	    </li>
	  </ul>
	  <p>
	    Note that the state of <progident>actSaveArea</progident>,
	    <progident>actSaveArea-&gt;flags.a</progident>, and
	    <progident>handler</progident> are checked on each
	    delivery attempt. If a process blocks attempting to
	    deliver its fault information to an external fault
	    handler, and the <progident>actSaveArea</progident> and/or
	    field is modified before the external handler becomes
	    unblocked, the fault may end up being delivered to the
	    in-process fault handler depending on the value of
	    <progident>actSaveArea-&gt;flags.a</progident>.
	  </p>
<!-- 	  <note> -->
<!-- 	    <title>Open Issue</title> -->
<!-- 	    <p> -->
<!-- 	      There is an open issue here regarding debugging. Certain -->
<!-- 	      messaging-related faults are deferred if -->
<!-- 	      <progident>upcb.a</progident> is set, because they are -->
<!-- 	      really notifications. This means that a debugger cannot -->
<!-- 	      trace events simply by setting -->
<!-- 	      <progident>upcb.a=1</progident>. -->
<!-- 	    </p> -->
<!-- 	    <p> -->
<!-- 	      If a debugger wishes to learn of notifications, there -->
<!-- 	      appear to be three (mutually exclusive) posssible -->
<!-- 	      strategies: -->
<!-- 	    </p> -->
<!-- 	    <ol> -->
<!-- 	      <li> -->
<!-- 		<p> -->
<!-- 		  Add a bit <progident>nh</progident> (<b>n</b>otify -->
<!-- 		  <b>h</b>andler) indicating that notifications should -->
<!-- 		  be delivered when in the <em>SelfHandling</em> state -->
<!-- 		  (and thereby be delivered to the debugger). -->
<!-- 		</p> -->
<!-- 	      </li> -->
<!-- 	      <li> -->
<!-- 		<p> -->
<!-- 		  Add a bit <progident>xh</progident> (e<b>x</b>ternal -->
<!-- 		  <b>h</b>andler) indicating that all faults and -->
<!-- 		  notifications should be delivered to the external -->
<!-- 		  handler. -->
<!-- 		</p> -->
<!-- 	      </li> -->
<!-- 	      <li> -->
<!-- 		<p> -->
<!-- 		 Debugger injects its own handler entry point, taking -->
<!-- 		 over the handler logic. -->
<!-- 		</p> -->
<!-- 	      </li> -->
<!-- 	    </ol> -->
<!-- 	    <p> -->
<!-- 	      We have not yet adopted a choice among these options. -->
<!-- 	    </p> -->
<!-- 	  </note> -->
	</sect2>
	<sect2>
	  <title>Return From In-Process Handler</title>
	  <p>
	    Several things need to happen simultaneously to return
	    from an in-process fault handler:
	  </p>
	  <ul>
	    <li>
	      <p>
		The <progident>upcb.a</progident> field must be
		cleared (set to 0).
	      </p>
	    </li>
	    <li>
	      <p>
		The <progident>PC</progident> must be updated.
	      </p>
	    </li>
	    <li>
	      <p>
		The <progident>SP</progident> must be updated.
	      </p>
	    </li>
	    <li>
	      <p>
		The <progident>flags</progident> must be updated.
	      </p>
	    </li>
	    <li>
	      <p>
		A check must be performed to confirm that
		<progident>upcb.ai</progident> is clear (0).
	      </p>
	    </li>
	  </ul>
	  <p>
	    These operations must be performed in user mode while
	    running within a critical section, which is not possible
	    on any architecture we know about. The alternative is to
	    perform the sequence in a way that the kernel can
	    recognize in the event that preemption occurs. This is the
	    approach adopted by Coyotos. The kernel implements a
	    dedicated code page at an architecture-specific virtual
	    address. In most implementations, the kernel reserves a
	    location in the thread-local storage area for the return
	    program counter.
	  </p>
	  <note>
	    <title>Non-Normative Illustration</title>
	    <p>
	      The following code sequences are not normative. Consult
	      the architecture-specific annex for normative code
	      sequences on your architecture.
	    </p>
	  </note>
	  <p>
	    The return sequence is implemented by:
	  </p>
	  <literallayout>
actSaveArea.savedPC    &lt;-  <em>return PC</em>
actSaveArea.savedSP    &lt;-  <em>return SP</em>
actSaveArea.savedFlags &lt;-  <em>return flags value</em>;
jmp <em>kernel_supplied_return_stub</em></literallayout>
	  <p indent="no">
	    The kernel-supplied stub in turn performs something like
	    the following sequence:
	  </p>
	  <literallayout>
tls.savedPC     &lt;- actSaveArea.savedPC
actSaveArea.a   &lt;- 0
FLAGS           &lt;- actSaveArea.savedFLAGS
SP              &lt;- actSaveArea.savedSP
j *tls.savedPC
</literallayout>
	  <p>
	    If preemption occurs within the kernel-supplied page, the
	    update is completed by the kernel on behalf of the
	    de-activating process. This is done by copying the values
	    of <progident>actSaveArea.savedPC</progident>,
	    <progident>actSaveArea.savedSP</progident>, and
	    <progident>actSaveArea.savedFlags</progident> from the
	    activation save area into the corresponding in-process
	    locations and clearing
	    <progident>actSaveArea.flags.a</progident>.
	  </p>
	</sect2>
	<sect2>
	  <title>Return From Out-of-Process Handler</title>
	  <p>
	    If an exception has been delivered to an out-of-process
	    handler, the fault was incurred in the activation
	    handler. The out-of-process handler must take action to
	    clear the fault, and then invokes the process capability
	    to return the process to the running state.
	  </p>
	</sect2>
      </sect1>
      <sect1>
	<title>Application-Defined Notifications</title>
	<p>
	  Coyotos supports application-defined non-blocking
	  notifications via the <link
	  href="#coyotos.AppNotice"><progident>AppNotice</progident></link>
	  capability type. A notification is posted by invoking the
	  <progident>AppNotice</progident> capability with 32-bit mask
	  indicating the notifications (in the range 0..31) to be
	  posted.  The set of authorized notifications is determined
	  at the time the <progident>AppNotice</progident> capability
	  is fabricated. The effect of posting a set of
	  application-defined notices is to set the corresponding bits
	  of the target process <progident>softNotices</progident>
	  word, and to set the <progident>sn</progident> bit of the
	  target process flags if the value of
	  <progident>appNotices</progident> has changed as a
	  consequence of this posting (i.e. if the interrupt was not
	  already pending). Of the set of notices posted, only the
	  authorized subset is delivered.
	</p>
	<p>
	  Application-defined notifications have lower delivery
	  priority than hardware exceptions. Delivery is suppressed
	  during a closed wait, and also when the application is
	  running in the <em>activated</em> state. If the
	  <progident>upcb.ai</progident> bit is set, no other
	  exception is pending, and the application is running in the
	  <em>normal</em> state or is in an open <em>receive</em>
	  state, the kernel will deliver the
	  <progident>SoftNotice</progident> fault code to the
	  activation handler.
	</p>
      </sect1>
    </chapter>
    <chapter id="AddressSpaces">
      <title>Address Spaces</title>
      <p>
	The Coyotos architecture defines 64-bit address spaces for
	both 32-bit and 64-bit machines. On 32-bit machines, the
	leading 2<sup>32</sup> byte positions are addressable by
	hardware load and store instructions.  That is, the
	hardware-accessible map is a <em>window</em> onto the leading
	subrange of the software-defined space.
      </p>
      <p>
	On some architectures, a portion of the hardware-addressable
	space may be reserved for use by the kernel. On such machines,
	the hardware-accessible address space is overlaid by the
	kernel-defined region.
      </p>
      <sect1 id="memobs">
	<title>Memory Objects and Address Interpretation</title>
	<p>
	  Three objects are used to define Coyotos address spaces:
	  pages, cappages, and GPTs. Capabilities to these objects may
	  be invoked in the usual way. The interface definitions for
	  these objects are provided in Part II.
	</p>
	<p>
	  The meaning of a data (capability) address reference is
	  determined by starting at the data (capability) address
	  space capability of the referencing process and traversing
	  memory objects until the address has been successfully
	  translated or an exception has occurred. The traversal
	  process is similar to the traversal of hardware-based
	  hierarchical translation tables, but there are several
	  differences:
	</p>
	<ul>
	  <li>
	    <p>
	      The Coyotos mapping structures provide support for
	      per-region fault handlers. Any region of size
	      2<sup><em>k</em></sup> pages may have an associated
	      fault handler. When a memory fault is reported to the
	      in-process fault handler, the in-process handler may
	      optionally forward memory fault messages to the
	      per-region handler in order to request region-specific
	      fault handling.
	    </p>
	  </li>
	  <li>
	    <p>
	      The ``levels'' of the mapping hierarchy are dynamically
	      determined. Smaller subspaces may appear where a larger
	      space is expected, with the effect that the ``missing''
	      regions are considered invalid addresses. Larger
	      subspaces may appear where a smaller space would
	      naturally appear, with the effect that only the leading
	      subrange of the larger subspace is addressable through
	      this mapping.
	    </p>
	  </li>
	  <li>
	    <p>
	      A mechanism is provided for mapping ``windows'' onto
	      other address spaces by reference. This enables one
	      address space to map (portions of) another even when the
	      second space is opaque.
	    </p>
	  </li>
	  <li>
	    <p>
	      In order to support certain essential types of
	      addressing flexibility &mdash; notably windows &mdash;
	      it is necessary to allow some unusual arrangements of
	      the hierarchical structures. An unfortunate consequence
	      of this is that it is possible for a hostile or
	      erroneous program to create statically cyclic address
	      spaces. Such spaces are <term>malformed</term>, and
	      attempts to reference a cyclically defined address
	      generate a <progident>MalformedSpace</progident>
	      exception.
	    </p>
	  </li>
	</ul>
	<sect2>
	  <title>Permissions</title>
	  <p>
	    All memory object capabilities carry a four-bit field, "restr",
	    which specify restrictions on which types of access may legally be
	    performed:
	  </p>
	  <deflist>
	    <defli>
	      <label><term>RO</term></label>
	      <li>
		<p>
		  <leadin>Read Only (0x1)</leadin> Attempts to perform write
		  references  along any address translation path that
		  traverses this capability are prohibited.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>NX</term></label>
	      <li>
		<p>
		  <leadin>No Execute (0x2)</leadin> Instruction fetch
		  references along any address translation path that
		  traverses this capability are prohibited. Attempts to
		  perform instruction fetches at such addresses generate
		  an <progident>NoExecute</progident> exception.
		</p>
		<note>
		  <title>Issue</title>
		  <p>
		    I have not yet examined the exception handling
		    policy for machines that implement <term>NX</term>
		    to confirm that a differentiated access violation
		    type is generated at the hardware level.
		  </p>
		</note>
		<p>
		  On hardware that does not support the
		  <term>NX</term> restriction, the <term>NX</term> bit
		  is ignored.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>WK</term></label>
	      <li>
		<p>
		  <leadin>Weak (0x4)</leadin> A capability read reference
		  along an address translation path that traverses a
		  capability with this bit set conservatively
		  downgrades the returned capability, if required, in
		  a way that ensures <em>transitively</em> read-only
		  authority.
		</p>
		<p>
		  Capability and data stores that traverse a weak
		  capability in the translation path generate an
		  access violation exception.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>OP</term></label>
	      <li>
		<p>
		  <leadin>Opaque (0x8)</leadin> The address space
		  structure may not be accessed or modified through
		  any GPT capability with the Opaque bit set.
		</p>
	      </li>
	    </defli>
	  </deflist>
	  <p>
	    The result of translation of the form
	    <progident>translate(space,addr,access-type)</progident>
	    is either an exception or a valid translation of the form
	    <progident>(page,offset)</progident>. If an exception is
	    reported, the type of the exception and the originally
	    referenced address are provided to the referencing
	    process's activation handler, the faulting instruction (if
	    any) has no effect), and the program counter is not
	    advanced. The defined reference types are:
	  </p>
	  <deflist latex.colspec="ll">
	    <defli>
	      <label><b>Fetch</b></label>
	      <li>
		<p>Instruction load from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Load Data</b></label>
	      <li>
		<p>Read data from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Load Capability</b></label>
	      <li>
		<p>Read capability from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Store Data</b></label>
	      <li>
		<p>Write data to address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Store Capability</b></label>
	      <li>
		<p>Write capability to address space.</p>
	      </li>
	    </defli>
	  </deflist>
	</sect2>
	<sect2>
	  <title>References and Access Violations</title>
	  <p>
	    The rules for address translation are given below in the
	    discussions of individual memory objects. As traversal of
	    the memory objects proceeds, the <em>effective
	    restrictions</em> associated with the address are computed
	    by beginning with no initial restrictions and performing a
	    cumulating logical <em>or</em> with the restriction bits in
	    each traversed capability as translation progresses.
	  </p>
	  <p>
	    If a capability is traversed during translation that
	    cannot legally appear within an address space, a
	    <progident>Malformedpace</progident> exception is
	    generated according to the reference type.
	  </p>
	  <p>
	    If the traversed path is well-formed, but the address
	    cannot be completely translated, an
	    <progident>InvalidAddress</progident> exception is
	    generated according to the reference type. Untranslatable
	    fetch references generate the
	    <progident>InvalidAddress</progident> exception.
	  </p>
	  <p>
	    If an address is completely translatable, the resulting
	    permission restrictions may not permit the reference
	    type. In this case an exception will be generated
	    according to the following rules:
	  </p>
	  <table latex.center="yes" latex.colspec="lll">
	    <thead>
	      <tr>
		<td><b>Ref Type</b></td>
		<td><b>Permissions</b></td>
		<td><b>Result</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>Fetch</td>
		<td>NX</td>
		<td>Exception: 
		  <progident>NoExecute</progident></td>
	      </tr>
	      <tr>
		<td>Capability Store, Data Store</td>
		<td>RO <em>or</em> WK</td>
		<td>Exception: 
		  <progident>AccessViolation</progident></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    If the permissions are sufficient to allow the operation,
	    a final check is made to ensure that the type of the load
	    or store operation (data or capability) matches the type
	    of the page mapped at that address (Page, CapPage). If a
	    type mismatch occurs, a
	    <progident>DataAccessTypeError</progident> or
	    <progident>CapAccessTypeError</progident> exception is
	    raised.
	  </p>
	  <p>
	    A capability load that traverses a path having
	    <progident>WK</progident> restrictions will succeed, but
	    will return a downgraded result as follows:
	  </p>
	  <table latex.center="yes" latex.colspec="ll">
	    <thead>
	      <tr>
		<td><b>Capability At Address</b></td>
		<td><b>Result</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>Page, CapPage, GPT, Window, Endpoint</td>
		<td>Copy with RO, WK bits set.</td>
	      </tr>
	      <tr>
		<td>Discrim</td>
		<td>Return value is unchanged.</td>
	      </tr>
	      <tr>
		<td><em>other</em></td>
		<td>Null capability is returned.</td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
      </sect1>
      <sect1 id="pages">
	<title>Pages and Capability Pages</title>
	<p>
	  The smallest mappable unit, and therefore the smallest
	  address space, is the page or the cappage. A page is the
	  atomic unit of data storage whose size is
	  implementation-defined. A capability page is a page-sized
	  unit that holds capabilities rather than data. Capabilities
	  are byte-addressed opaque 16-byte quantities that are
	  aligned at 16 byte boundaries.
	</p>
	<p>
	  Coyotos implements a single page size whose size matches
	  some hardware page size implemented by the underlying
	  hardware. On processors that implement multiple page sizes,
	  the selected page size need not be the smallest size
	  supported by the underlying hardware.  It is
	  implementation-dependent whether the kernel will attempt to
	  exploit larger hardware page sizes if available. If such
	  exploitation is attempted, it is accomplished by
	  re-synthesizing larger pages by physical arrangement of
	  standard-sized pages. The atomic unit of mapping and
	  permissions remains the Coyotos page size.
	</p>
	<p>
	  A page capability may be inserted into the
	  address space slot of a process, with the
	  effect of defining an address space having valid offsets
	  between [<em>guard</em>,<em>guard+pgsize</em>-1]. Attempts
	  to reference offsets outside this range result in an invalid
	  address exception.
	</p>
	<p>
	  Capability pages are byte-addressable units. However,
	  capabilities must be stored and referenced at naturally
	  aligned (16 byte) boundaries.
	</p>
	<p>
	  Address translation of an address <em>addr</em> with respect
	  to a page or cappage capability is defined as follows:
	</p>
	<ol>
	  <li>
	    <p>
	      If the value of <em>addr</em> exceeds the page size, an
	      <progident>InvalidAddress</progident> exception is
	      generated.
	    </p>
	  </li>
	  <li>
	    <p>
	      Otherwise: the <em>addr</em> is a valid offset, and the
	      overall address reference is valid.
	    </p>
	  </li>
	</ol>
      </sect1>
      <sect1 id="as_compose">
	<title>Address Space Composition</title>
	<p>
	  Address spaces are composed by means of the GPT object.  A
	  GPT is simply a fixed-length vector of capabilities
	  (currently 16), each of which is paired with a
	  <term>guard</term>. In Coyotos, the guard has been
	  incorporated into the capability format itself.
	  The state of a GPT is shown below.
	</p>
	<figure latex.placement="h">
	  <img source="gpt" width="75" srctype="sbox"/>
	  <caption>GPT State</caption>
	</figure>
	<p>
	  <leadin>Invariant:</leadin>
	  <progident>l2v&nbsp;&ge;&nbsp;log2(<em>page&nbsp;size</em>)</progident><br/>
	</p>
	<p>
	  The meanings of the GPT fields are:
	</p>
	<deflist>

	  <defli>
	    <label><term>l2v</term></label>
	    <li>
	      <p>
		<leadin>Subspace size</leadin> Each slot of the GPT
		names a subspace of size
		<progident>2<sup>l2v</sup></progident> bytes.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>ha</term></label>
	    <li>
	      <p>
		<leadin>fault handler</leadin> Slot 15 of the GPT
		contains an Entry capability to the fault handler.
	      </p>
	      <p>
		Care should be taken to set the
		<progident>l2v</progident> value appropriately when
		the <progident>ha</progident> bit is set. If the
		translation algorithm traverses an Entry capability in
		the normal course of translation, a malformed space
		exception will be generated.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>bg</term></label>
	    <li>
	      <p>
		<leadin>background space</leadin> Slot 14 of the GPT contains a
		memory capability to a background space (see window
		capabilities).
	      </p>
	      <p>
		Care should be taken to set the
		<progident>l2v</progident> value appropriately when
		the <progident>bg</progident> bit is set. If the
		translation algorithm traverses a background
		capability during the normal course of translation,
		the translation result will appear as if a larger
		space was entered.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>cap[0..15]</term></label>
	    <li>
	      <p>
		Capabilities to subspaces.
	      </p>
	    </li>
	  </defli>
	</deflist>
	<p indent="no">
	  When the <progident>ha</progident> or
	  <progident>bg</progident> bits are set, it is the
	  responsibility of the process managing the GPT to ensure
	  that the <progident>l2v</progident> value prevents
	  collision. 
	</p>
	<sect2 id="xlate_algorithm">
	  <title>Translation Algorithm</title>
	  <p>
	    <leadin>Note: </leadin>
	    In the discussion that follows, it may be useful to
	    refer to the capability representation for window and
	    memory object capabilities (see Chapter 2), with
	    particular reference to the <progident>l2v</progident>
	    and <progident>l2g</progident> fields.
	  </p>
	  <p>
	    Address translation is performed by translating an
	    unsigned virtual address <progident>va</progident> with
	    respect to some memory capability <progident>C</progident>
	    (a GPT, page, capability page, or window capability).
	    Translation begins at the address space capability of the
	    process structure with a 64-bit virtual address.  In the
	    normal case, the progress of translation causes bits to be
	    ``consumed'' from the left, leading to virtual addresses
	    of progressively smaller magnitudes.  Window capabilities,
	    however, may cause the remaining virtual address to grow
	    as translation proceeds.
	  </p>
	  <p>
	    The virtual address <progident>va</progident> that is
	    currently being translated is conceptually divided into
	    three fields <em>g</em>, <em>u</em>, and
	    <em>v</em>. 
	    The
	    <progident>g</progident> field (which may be zero width)
	    contains the <term>guard</term> value. 
	    The <em>u</em> field contains the index value
	    that will be used to index into the next GPT. 
	    The
	    <progident>v</progident> field contains either the
	    address bits that will remain to be translated when the
	    current step has completed (GPT or window capability) or
	    the page offset bits (page or capability page capability).
	  </p>
	  <figure latex.placement="h">
	    <img source="gpt-va" width="75" srctype="sbox"/>
	    <caption>Virtual address structure</caption>
	  </figure>
	  <p>
	    In reading the following section, recall the invariants
	    described in Section&nbsp;<xref ref="memcaps"/>. These are
	    checked at capability fabrication time, and are assumed to
	    hold by the following algorithm statements.
	  </p>
	  <p>
	    The values of <em>g</em>, <em>u</em>, and <em>v</em> are
	    computed from the capability <progident>C</progident> and
	    the address <progident>va</progident> as follows:
	  </p>
	  <literallayout>
g = va &gt;&gt; C.l2g;
guard = C.guard &lt;&lt; C.l2g;
u = (va - guard) &gt;&gt; C.l2v;
v = va &amp; ((1u &lt;&lt; C.l2v) - 1);</literallayout>
	  <p>
	    At the start of translation, the background space
	    capability <progident>C<sub>background</sub></progident>
	    is the Null capability, the virtual address is as provided
	    by the hardware (or possibly the IPC logic) and the
	    effective access restrictions <progident>AR</progident> is
	    the empty set.  Translation proceeds by iteration, with
	    each iteration performing the following steps in sequence:
	  </p>
	  <ol>
	    <li>
	      <p>
		The <progident>g</progident> value is compared to the
		 zero-extended guard value stored in the
		 capability. If they do not match, the address is
		 invalid and an <progident>InvalidAddress</progident>
		 exception is generated.
	      </p>
	    </li>
	    <li>
	      <p>
		If the <progident>u</progident> value exceeds the
		number of slots in the GPT, the address is invalid and
		an <progident>InvalidAddress</progident> exception is
		generated.
	      </p>
	    </li>
	    <li>
	      <p>
		The effective access restrictions are updated from the
		capability <progident>C</progident> by:
	      </p>
	      <literallayout>
AR:=AR+C.restr</literallayout>
	      <p indent="no">
		If the resulting effective access restrictions are
		insufficient for the requested access type, an
		<progident>AccessViolation</progident> exception is
		generated.
	      </p>
	    </li>
	    <li>
	      <p>
		Processing now proceeds according to the capability
		type:
	      </p>
	      <ul>
		<li>
		  <p>
		    If the capability type
		    <progident>C.type</progident> is
		    <progident>Page</progident> or
		    <progident>CapPage</progident>, translation has
		    completed successfully.
		  </p>
		</li>
		<li>
		  <p>
		    If a local or background window capability appears
		    in the address space slot of a process, all
		    addresses are deemed invalid.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability is a local window capability
		    appearing within some GPT, translation proceeds
		    from the capability contained in the
		    <em>rootSlot</em> slot of the GPT containing the
		    local window capability at the offset named by the
		    capability.
		  </p>
		  <literallayout>
va := v + C.offset
C := containingGPT[C.rootSlot]</literallayout>
		  <p>
		    Note that the invariants of Section&nbsp;<xref
		    ref="memcaps"/> guarantee that there is no bitwise
		    overlap between <progident>v</progident> and
		    <progident>C.offset</progident>. That is: the
		    addition can be correctly implemented as a bitwise
		    ``or'' operation.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability is a background window
		    capability, translation proceeds from the
		    capability to the background space with
		  </p>
		  <literallayout>
va := v + C.offset
C := C<sub>background</sub></literallayout>
		  <p>
		    Note that the invariants of Section&nbsp;<xref
		    ref="memcaps"/> guarantee that there is no bitwise
		    overlap between <progident>v</progident> and
		    <progident>C.offset</progident>. That is: the
		    addition can be correctly implemented as a bitwise
		    ``or'' operation.
		  </p>
		  <p>
		    Recall that
		    <progident>C<sub>background</sub></progident> is
		    initialized to Null at the start of
		    translation. If no other background capability has
		    been defined at the point where the background
		    window capability is encountered, all addresses
		    that fall within the background window are
		    invalid.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability type is
		    <progident>GPT</progident>, translation proceeds
		    with
		  </p>
		  <literallayout>
gpt := target-of(C);
if (gpt-&gt;bg)
  C<sub>background</sub> = gpt-&gt;cap[14];
if (gpt-&gt;ha)
  C<sub>handler</sub> = gpt-&gt;cap[15];
va := v
C := gpt-&gt;cap[<em>u</em>]</literallayout>
		</li>
		<li>
		  <p>
		    If the capability is a <progident>Null</progident>
		    capability, an
		    <progident>InvalidAddress</progident>
		    exception is generated.
		  </p>
		</li>
		<li>
		  <p>
		    Otherwise, a
		    <progident>MalformedSpace</progident>
		    exception is generated.
		  </p>
		</li>
	      </ul>
	    </li>
	  </ol>
	</sect2>
	<sect2>
	  <title>Exception Handling</title>
	  <p>
	    If an exception is generated by the translation mechanism,
	    the exception is
	    reported by storing the exception type and address in the
	    process's
	    <progident>faultCode</progident> and
	    <progident>faultInfo</progident> slots, respectively. The
	    exception is then delivered as described in
	    Section&nbsp;<xref ref="ExceptionDelivery"/>.
	  </p>
	</sect2>
	<sect2>
	  <title>Cycle Detection</title>
	  <p>
	    It is possible for an erroneous or hostile program to
	    arrange GPT objects in such a way as to create a static
	    cycle. Such an address space is <em>malformed</em>, and
	    attempts to traverse such a cycle during address
	    translation result in an
	    <progident>MalformedSpace</progident> exception.
	  </p>
	  <p>
	    No final selection has been made for a method of cycle
	    detection. Three rules have been proposed:
	  </p>
	  <ol>
	    <li>
	      <p>
		A bound on the total number of GPT structures that
		will be visited before generating a
		<progident>MalformedSpace</progident> exception.
	      </p>
	      <p>
		This method has been rejected. It has the unfortunate
		property that existing, valid addressing structures
		can be rendered invalid by ``splitting'' an existing
		GPT. We want to preserve the ability to split without
		semantic alteration in order to be able to map
		subspaces.
	      </p>
	    </li>
	    <li>
	      <p>
		A bound on the total number of capabilities
		<em>that do not translate new bits</em> that will be
		visited before generating a
		<progident>MalformedSpace</progident> exception.
	      </p>
	      <p>
		This method keeps track of
		<progident>|v<sub>least</sub>|</progident>, the shortest
		virtual address that has been obtained by translation
		to the current point. If
		<progident>C.l2v&ge;|v<sub>least</sub>|</progident>,
		then the current capability does not translate new bits.
	      </p>
	      <p>
		This method has been rejected. It has the unfortunate
		property that existing, valid addressing structures
		can be rendered invalid by ``splitting'' an existing
		GPT. We want to preserve the ability to split without
		semantic alteration in order to be able to map
		subspaces.
	      </p>
	    </li>
	    <li>
	      <p>
		A bound on the total number of <em>bits</em> visited
		for translation, defined as the cumulative sum of
		<progident>(|va|-|v|)</progident> for all
		capabilities visited during a translation attempt.
	      </p>
	      <p>
		This approach preserves the possibility of a
		correctness-preserving split operation.
	      </p>
	    </li>
	  </ol>
	  <p>
	    All methods of cycle detection introduce a complication
	    for implementors: the validity of addresses within a
	    subspace is contextually dependent on the number of
	    bound-countable events in the prefix path leading to that
	    subtree. This means that two process address spaces may
	    both have some subspace mapped at otherwise valid
	    subspaces addresses, and selected subranges of the mapped
	    subspace may nonetheless be valid in one space but not in
	    the other.
	  </p>
	  <p>
	    Because of this problem, care must be taken when
	    implementing page table sharing to ensure that page tables
	    are shared only when all possible references through that
	    hardware table are equally valid in all referencing
	    contexts. If this is not done, one process would be able
	    to produce valid mappings in the hardware mapping table
	    that would be usable by the second, even though the second
	    lacks the ability to produce those hardware mappings for
	    itself.
	  </p>
	</sect2>
<!-- 	<sect2> -->
<!-- 	  <title>Region-Specific Fault Handling</title> -->
<!-- 	  <note> -->
<!-- 	    <title>Pending Edit</title> -->
<!-- 	    <p> -->
<!-- 	      This needs to be fleshed out. The idea is that this is -->
<!-- 	      an invocation that is sent to the per-region fault -->
<!-- 	      handler, but the traversal is done with kernel support -->
<!-- 	      and the kernel ensures that the message is ``valid.'' -->
<!-- 	    </p> -->
<!-- 	  </note> -->
<!-- 	  <p> -->
<!-- 	    An address space fault can be propagated to the memory -->
<!-- 	    fault handler by means of the <progident>probe</progident> -->
<!-- 	    operation on the GPT capability. -->
<!-- 	  </p> -->
<!-- 	  <p> -->
<!-- 	    The rule for processing address probe operations and -->
<!-- 	    background spaces is to use the ``nearest enclosing -->
<!-- 	    context''. A probe message is delivered by logically -->
<!-- 	    traversing the address space mapping structures until a -->
<!-- 	    fault would occur for the given address and access type, -->
<!-- 	    and the fault message is delivered to the fault handler -->
<!-- 	    named by <progident>C<sub>handler</sub></progident> at the -->
<!-- 	    time the fault is observed. Similarly, window capabilities -->
<!-- 	    cause translation to proceed through the prevailing -->
<!-- 	    <progident>C<sub>background</sub></progident> capability -->
<!-- 	    at the time the window capability is encountered. -->
<!-- 	  </p> -->
<!-- 	</sect2> -->
      </sect1>
      <sect1 id="split">
	<title>Address Space Splitting</title>
	<note>
	  <title>Experimental</title>
	  <p>
	    The feature described in this section is experimental. It
	    is not presently implemented, and may be removed in future
	    versions of Coyotos.
	  </p>
	</note>
	<p>
	  In order to support the subspace transfer item described in
	  the capability invocation chapter, Coyotos introduces a new
	  type of exception that may occur in an address space:
	  the <progident>SplitFault</progident>.
	</p>
	<p>
	  Split faults allow an invoker to send a single capability to
	  an arbitrary 2<sup><em>k</em></sup> page region of an
	  address space, provided that the region is naturally aligned
	  and the invoker has sufficient access rights to extract the
	  dominating capability. Similarly, they permit a receiver to
	  generate appropriate ``holes'' into which such a capability
	  must be received.
	</p>
	<p>
	  The problem solved by split faults is that there may not be
	  any naturally dominating GPT for the subspace. 

	  For example, in a system having 4 kilobyte (2<sup>12</sup>
	  byte) pages, the invoker may wish to transmit a
	  2<sup>11</sup> page (2<sup>23</sup> byte) subspace, but the
	  subspace may currently be dominated by a GPT having
	  <progident>l2v=21</progident>. That is: there is no single
	  slot in the GPT that directly holds a capability of the
	  desired span.  Before a single dominating capability can be
	  sent, this GPT must be ``split'' into an arrangement where
	  the target subtree has a single dominating GPT with
	  <progident>l2v=23</progident>.  When such a send is
	  attempted, the invoker will receive a
	  <progident>SplitFault</progident> exception. This is an
	  advisory that the GPT must be split in order to bring a
	  dominating GPT into existence.
	</p>
	<p>
	  Similarly, if a receiver specifies a ``hole'' of some size
	  <tt>2<sup>hlsz</sup></tt> pages, there must exist some GPT
	  in the receiver tree that could receive (with an appropriate
	  guard value) a capability dominating a tree of the requested
	  size.
	</p>
	<p>
	  The reason this feature is considered experimental is that
	  the correct strategy for splitting GPTs is not obvious.
	</p>
<!-- 	<ul> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      <progident>r<sub>patt</sub> &le; hlsz &le; -->
<!-- 	      h<sub>patt</sub></progident> -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      The receiving PATT either has some slot free or some -->
<!-- 	      pattern that exactly matches the target address. -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      The receiver has write permissions on the appropriate -->
<!-- 	      PATT slot. This requires both that the permissions check -->
<!-- 	      described above are satisfied and that no PATT -->
<!-- 	      capability on the path from the address space root to -->
<!-- 	      the modified PATT is opaque. -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	</ul> -->
	<p>
	  The address space splitting idea is not yet fully
	  developed. There are certainly holes, including necessary
	  but undefined exception types, that need to be resolved in
	  the definition above.
	</p>
      </sect1>
    </chapter>
    <chapter id="invocation">
      <title>Capability Invocation (including IPC)</title>
      <p>
	Coyotos is an object-based system. A process wishing to
	perform an operation (equivalently: invoke a service) does so
	by invoking some capability that it holds. The capability has
	a defined interface that specifies some set of invokable
	methods, including their argument and return types.  The
	provider of these methods may be either the kernel or an
	application; the invocation mechanism is the same in either
	case.  That is: Coyotos is an extensible object system <cite
	ref="wulf1974hydra"/>.  The primary system call in Coyotos is
	the ``invoke capability'' system call (Section&nbsp;<xref
	ref="syscall_invcap"/>). Other system calls defined by the
	Coyotos specification may all be viewed as convenience
	wrappers for capability method invocations.
      </p>
      <p>
	Because kernel-provided and application-provided services
	share a common invocation mechanism, it is necessary to
	specify both the low-level binding of capability interfaces
	and the externally observable semantics of capability
	invocation. While the specific binding is
	architecture-dependent, this chapter includes recommendations
	on bindings that suffice for most platforms.
      </p>
      <p>
	The invoke capability system call implements a variant of
	the <em>SendAndWait</em> primitive proposed by Liedtke <cite
	  ref="l3:ipc"/> or the <smallcaps>call</smallcaps> and
	<smallcaps>return</smallcaps> primitives of EROS <cite
	  ref="shap1999fastcapsystem"/>. The send phase of the
	invocation can be blocking or non-blocking. If a
	non-blocking send is performed, some or all of the message
	may be truncated.  The receive phase may wait for an
	arbitrary endpoint (an ``open wait'') or a specific endpoint
	(a ``closed wait''). The receive phase is optional.
      </p>
      <sect1 id="msg_payload">
	<title>Invocation Payload</title>
	<p>
	  An invocation passes a message that consists of:
	</p>
	<ul>
	  <li>
	    <p>
	      Either 16 or 32 <term>untyped parameter words</term>,
	      depending on the natural register size of the executing
	      process. On a 32-bit platform there are 32 untyped
	      parameter words, each 32-bits wide.  On a 64-bit
	      platform there are 16 untyped parameter words, each
	      64-bits wide. These words may be carried in registers or
	      memory, as specified by the architecture-specific annex
	      for the target platform.
	    </p>
	    <p>
	      Up to 16 <em>typed parameters</em>, which are described
	      by <em>typed parameter items</em>.
	    </p>
	    <p>
	      Input parameter word 0 of the invoke capability
	      operation contains control information describing the
	      rest of the message payload:
	    </p>
	    <figure latex.placement="h">
	      <img source="syscall-invcap-ipw0" width="70"
		srctype="sbox"/>
	      <caption>Invocation control word (input)</caption>
	    </figure>
	    <p>
	      Provided the invokee is valid and well-formed, a message
	      consisting solely of untyped parameter words is
	      guaranteed to proceed without exceptions on all
	      architectures.
	    </p>
	  </li>
	  <li>
	    <p>
	      Up to four capabilities. If
	      <progident>IPW0.SC=1</progident>, capabilities are
	      transmitted, and <progident>IPW0.c</progident> gives the
	      index of the last capability transmitted. If
	      capabilities are transmitted, IPW0.RC=1, and the first
	      capability transmitted is an Endpoint capability, the
	      first capability received will be an Entry capability to
	      that endpoint.  See the specification of the ``invoke
	      capability'' system call in Section&nbsp;<xref
	      ref="syscall_invcap"/> for an explanation of the
	      <progident>SC</progident> and <progident>RC</progident>
	      bits.
	    </p>
	  </li>
	  <li>
	    <p>
	      Up to 6 <term>indirect strings</term>, specified by the
	      typed item parameter words.
	      The corresponding receive regions are named by the
	      <progident>rcvBuf[]</progident> fields of the process
	      structure.
	    </p>
	    <p>
	      Note that parameter words are used to express both typed
	      and untyped items. The <progident>IPW0.u</progident>
	      field gives the index of the last untyped item
	      transmitted. The <progident>IPW0.t</progident> field
	      gives the <em>count</em> of typed item words that are to
	      be processed. If <progident>IPW0.t</progident> is zero,
	      no typed item words are present and no strings are
	      transmitted. The sum
	      <progident>IPW0.t+IPW0.u</progident> may not exceed the
	      total number of parameter words.
	    </p>
	  </li>
	</ul>
	<p>
	  In addition to the payload of the invocation, the invoker
	  specifies:
	</p>
	<ul>
	  <li>
	    <p>
	      The capability to be invoked.
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether they are willing to block in order for the
	      message to be delivered (<progident>IPW0.NB</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether to fabricate a reply capability
	      (<progident>IPW0.RC</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether the receive phase should be performed
	      (<progident>IPW0.RP</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether the receive phase should accept messages only
	      from a particular endpoint
	      (<progident>IPW0.CW</progident>,
	      <progident>upcb.rcvEpID</progident>).
	    </p>
	  </li>
	</ul>
	<p>
	  If a receive phase is executed, the receiver receives the
	  following information in addition to the invocation payload:
	</p>
	<ul>
	  <li>
	    <p>
	      The endpoint identifier of the Endpoint on which the
	      invocation was received.
	    </p>
	  </li>
	  <li>
	    <p>
	      The ``protected payload'' of the capability that was
	      invoked.
	    </p>
	  </li>
	  <li>
	    <p>
	      The number of typed items corresponding to strings that
	      were actually received (as opposed to the bound that the
	      receiver was <em>willing</em> to receive).
	    </p>
	  </li>
	  <li>
	    <p>
	      A modified copy of the invoker's invocation control
	      word, which indicates various information about the
	      incoming message:
	    </p>
	    <figure latex.placement="h">
	      <img source="syscall-invcap-opw0" width="70"
		srctype="sbox"/>
	      <caption>Invocation control word (output)</caption>
	    </figure>
	    <p>
	      In this returned word, the <progident>u</progident>,
	      <progident>RC</progident>, and
	      <progident>SC</progident>, fields are copied from the
	      sender's <em>input</em> invocation control word. The
	      <progident>t</progident> field indicates the number of
	      sent typed item words that were received. A typed item
	      parameter word is received only if the corresponding
	      string was fully received. <progident>OPW1.t</progident>
	      indicates the number of typed item words received. If
	      <progident>OPW1.SC</progident> is set (1),
	      <progident>OPW1.c</progident> indicates either the index
	      of the last capability received or the index of the
	      capability argument that was truncated if
	      <progident>OPW1.T</progident> is set.
	    </p>
	    <p>
	      The <progident>TS</progident> bit indicates whether any
	      incoming parameter string was truncated. If
	      <progident>TS</progident> is clear (0), all transmitted
	      strings were received. If <progident>TS</progident> is
	      set, truncation occurred at an unspecified location
	      following the last received parameter word.
	      A transmitted string will be truncated only if the
	      sender uses a non-blocking send and the
	      receiver-specified buffer is not valid and writable. In
	      this case, the received value
	    </p>
	    <p>
	      Similarly, the <progident>TC</progident> bit indicates
	      whether any transmitted capability parameters were
	      dropped. This can occur if a receiver-specified
	      capability address is invalid or non-writable and the
	      sender has specified a non-blocking transmission.  A
	      transmitted capability that is received into a
	      capability register will never be dropped. If all
	      capabilities are received into capability registers,
	      <progident>OPW1.T</progident> will never be set (1).
	    </p>
	  </li>
	</ul>
	<p>
	  The protected payload and the endpoint ID can be used to
	  determine the receiver-defined context in which the received
	  message should be interpreted. One common use of these
	  fields is for the endpoint ID to identify the object invoked
	  and the protected payload to identify the permissions on
	  that object.
	</p>
      </sect1>
      <sect1 id="inv_exceptions">
	<title>Invocation-Related Exceptions</title>
	<p>
	  Exceptions may occur during invocation on either the sender
	  or the receiver side of the transmission. All such
	  exceptions logically occur <em>before</em> the
	  invocation. In practice, exceptions are generated as a
	  consequence of payload transfer. If an exception occurs, the
	  implementation is free to resume the transfer at the point
	  of interruption if it is able to do so. However, the
	  receiver of an interrupted transmission logically reverts to
	  the beginning of its receive phase when an exception
	  occurs. In the event that a second sender is attempting to
	  send when a messaging exception is incurred, the second
	  sender's message may prevail.
	</p>
	<p>
	  If the sender specifies non-blocking transmission, the
	  transfer of indirect strings and capabilities is ``best
	  effort.'' If the receiver incurs a page fault during the
	  receipt of an indirect string or a capability argument, that
	  argument will be truncated. In this case the receiver will
	  be notified of truncation, but no receiver-side exception
	  will be generated.
	</p>
	<p>
	  The meaning of a non-blocking send is that the sender is
	  unwilling to be blocked for any cause whose handling is
	  controlled by the receiver. The use-case for this option is
	  a server returning a reply to an untrusted client. For
	  purposes of understanding truncation, a hardware page fault
	  that is successfully resolved by the object paging subsystem
	  is not considered to be an architecturally observable
	  fault. Similarly, an exception that can be satisfied by
	  reconstructing a hardware mapping entry from an already
	  defined GPT hierarchy is not considered an architecturally
	  observable fault.
	</p>
      </sect1>
      <sect1 id="endpoints">
	<title>Endpoints</title>
	<p>
	  A process that wishes to accept capability invocations does
	  so by means of one or more endpoints (Figure&nbsp;<xref
	  ref="endpoint_struct"/>). Endpoints have two capability
	  types: the Endpoint capability, which implements the control
	  interface for the endpoint object, and the Entry capability,
	  which provides the means for extending the object
	  system. When an Entry capability is invoked, the invocation
	  parameters are delivered as a message to the process named
	  by the <progident>recipient</progident> field of the
	  Endpoint.
	</p>
	<figure id="endpoint_struct" latex.placement="h">
	  <img source="endpoint" width="75" srctype="sbox"/>
	  <caption>Endpoint structure</caption>
	</figure>
	<p>
	  The meanings of the endpoint fields are:
	</p>
	<table latex.colspec="lp{5.5in}" latex.long="yes">
	  <thead>
	    <tr>
	      <td><b>Field</b></td>
	      <td><b>Meaning</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td><term>PM</term></td>
	      <td>
		<p>
		  <leadin>Payload Match</leadin> Indicates that the
		  protected payload of the endpoint should be compared
		  to the protected payload of the Entry
		  capability. If they are not equal, the invocation
		  behaves as if the Null capability had been invoked.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>CM</term></td>
	      <td>
		<p>
		  <leadin>Cached Message</leadin> A small message has
		  been cached in the endpoint for delivery. The endpoint
		  has been chained onto the target process via the
		  <progident>chain</progident> slot.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>protPayload</term></td>
	      <td>
		<p>
		  <leadin>Protected Payload</leadin> This value will be
		  conditionally used as a matching value if
		  <progident>PM</progident> is set (1).
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>endpointID</term></td>
	      <td>
		<p>
		  A 60-bit field having meaning only to the
		  recipient. The value of this field will be delivered
		  to the recipient during message receive.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>recipient</term></td>
	      <td>
		<p>
		  A process capability to the receiving process.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>ipw0..ipw2</term></td>
	      <td>
		<p>
		  Cached locations for the
		  <progident>ipw0</progident>..<progident>ipw2</progident>
		  values of a short message.
		</p>
	      </td>
	    </tr>
	  </tbody>
	</table>
	<p>
	  A message consisting of exactly two parameter words may be
	  cached in the endpoint if the endpoint does not already
	  contain a cached message. If this is done, the
	  <progident>IPW0</progident> and <progident>IPW1</progident>
	  values of the message will be copied to the endpoint and the
	  endpoint will be added to a chain of endpoints that are
	  attempting to deliver messages to the target process. The
	  <progident>CM</progident> bit will be set to indicate that a
	  message is cached in this endpoint.
	</p>
	<note>
	  <title>Open Issue</title>
	  <p>
	    There is a design issue in how to chain endpoints having
	    cached messages. I originally contemplated a
	    <progident>chain</progident> field threaded through a
	    pending endpoint list, but this does not handle the
	    endpoint destroy operation well. What should happen to
	    later entries in the chain?
	  </p>
	  <p>
	    I am presently thinking that it is best to have the
	    chaining be a kernel-internal matter, and handle the
	    dangling endpoint issue by decongestion. If we cannot come
	    up with a clean way to do that, we will simply drop
	    endpoint caching.
	  </p>
	</note>
	<note>
	  <title>Non-Normative Illustration</title>
	  <p>
	    When a server implements a single logical object, it will
	    typically operate with two endpoints. The first is the one
	    used to invoke the service (the ``receive endpoint''). The
	    endpoint ID of this endpoint is not used. The protected
	    payload of the corresponding Entry capability may be used
	    to express distinct permissions or restrictions on the
	    permitted operations. The second endpoint is used to
	    accept replies (the ``reply endpoint''). The endpoint ID
	    of this endpoint is used as a matching value to implement
	    a closed wait so that unrelated messages are not received
	    where a reply is expected. The endpoint's protected
	    payload is used to ensure that no more than one reply will
	    be received (by means of the
	    <progident>IPW0.RC</progident> bit of the invoke
	    capability system call).
	  </p>
	  <p>
	    When a server implements multiple objects, a distinct
	    receive endpoint is typically allocated for each object
	    implemented by the server. In this case, the endpoint ID
	    is used to identify which object or service is being
	    invoked, and the protected payload field of the
	    corresponding Entry capability is used to express distinct
	    permissions or restrictions on the permitted operations on
	    that object.
	  </p>
	</note>
	<note>
	  <title>Non-Normative Note on Reply Endpoints</title>
	  <p>
	    If the <progident>IPW0.RC</progident> bit is set in the
	    invocation control word parameter, the protected payload
	    of the endpoint is pre-incremented before the Entry
	    capability is fabricated. The purpose of the RC bit is to allow
	    a caller to ensure that a call/return sequence receives at
	    most one reply in the normal case. This is accomplished by
	    ensuring that stale reply capabilities are invalidated (by
	    protected payload mismatch) before the next receive on the
	    reply endpoint is performed.
	  </p>
	  <p>
	    Whenever an Entry capability is invoked, the invokee
	    receives the protected payload value of the invoked Entry
	    capability. In the case of a reply endpoint, the PM bit is
	    set, so the received protected payload value matches the
	    value stored in the endpoint.
	  </p>
	  <p>
	    It is the responsibility of the application to notice when
	    the incoming protected payload value approaches
	    UINT32_MAX. In this situation, the pre-increment will
	    overflow the protected payload counter when it is next
	    used. The recommended solution for this is to obtain a new
	    reply endpoint from a space bank when the protected
	    payload reaches UINT32_MAX-1.
	  </p>
	</note>
      </sect1>
      <sect1 id="cap_kernel_sem">
	<title>Semantics of Kernel Capability Invocation</title>
	<p>
	  To ensure consistent invocation behavior, it is necessary to
	  specify the externally observable behavior when a
	  kernel-implemented method is invoked. In particular, the
	  observable effect on process state and the sequencing of
	  operations and events during a kernel invocation must be
	  defined.
	</p>
	<p>
	  When a kernel capability is invoked, the externally
	  observable behavior should be as if the invoker had invoked
	  an endpoint to some application providing the
	  service. Because no kernel operation accepts an indirect
	  string, the invocation of a kernel capability behaves as if
	  this hypothetical provider had performed a receive phase
	  with <progident>IPW0.AS=0</progident> (no strings will be
	  accepted).  This hypothetical provider arrives at the
	  specified answer and accomplishes any effects of the
	  invocation by unspecified means. It then replies as if it
	  had invoked the <progident>InvCap</progident> system call
	  with the control bits of the first input parameter word set
	  as follows: <progident>NB=1</progident> (non-blocking),
	  <progident>RC=0</progident> (no reply capability is
	  generated), <progident>CW=0</progident> (the kernel
	  conceptually enters an open wait state), and
	  <progident>RP=1</progident> (the kernel waits for the next
	  invocation).  In addition, the <progident>SC</progident>
	  (send capabilities) control bit will be set (clear) if
	  capabilities are (are not) returned by the method.  Note
	  that because the kernel reply is non-blocking, and the
	  kernel is deemed to be in the <em>running</em> state until
	  it has replied, the reply from a kernel-implemented
	  capability cannot cause a second kernel-implemented
	  capability to be invoked.
	</p>
	<p>
	  This statement of behavior has (at least) the following
	  implications:
	</p>
	<ul>
	  <li>
	    <p>
	      The effects of a kernel capability invocation occur
	      whether or not the invocation returns successfully,
	      provided any preconditions specified for the method are
	      satisfied.
	    </p>
	  </li>
	  <li>
	    <p>
	      There exist several kernel operations that alter the
	      state of a process. When the process altered is also the
	      process receiving the kernel reply (the ``invokee''),
	      the kernel behavior must be well-defined. There are two
	      such cases:
	    </p>
	    <ol>
	      <li>
		<p>
		  The invokee process is destroyed as an effect of the
		  invoked method. In this case, the reply proceeds as
		  if via an endpoint that contains a Null capability,
		  and is discarded.
		</p>
	      </li>
<!-- 	      <li> -->
<!-- 		<p> -->
<!-- 		  The UPCB of the invokee process is destroyed as an -->
<!-- 		  effect of the invoked method, or the UPCB slot of -->
<!-- 		  the invokee is overwritten with a new capability by -->
<!-- 		  the invoked method. -->
<!-- 		</p> -->
<!-- 		<p> -->
<!-- 		  If, following the effect of the operation, the -->
<!-- 		  process KPCB contains a valid page capability in the -->
<!-- 		  <progident>upcb</progident> slot, the return values -->
<!-- 		  are delivered to the new UPCB page, according to the -->
<!-- 		  receive parameters and buffer registers of the -->
<!-- 		  <em>new</em> UPCB page. Note that both of these -->
<!-- 		  operations, when successful, return only a single -->
<!-- 		  reply status word. In consequence, the modification -->
<!-- 		  of the UPCB does not actually require that the -->
<!-- 		  receive buffers be re-examined in order to correctly -->
<!-- 		  deliver the reply. -->
<!-- 		</p> -->
<!-- 		<p> -->
<!-- 		  Otherwise, the invokee is considered -->
<!-- 		  <term>malformed</term>, and reply delivery proceeds -->
<!-- 		  as if an endpoint naming a malformed process were -->
<!-- 		  being invoked. Any reply payload that would have -->
<!-- 		  been stored in the UPCB, or whose destination -->
<!-- 		  location would have been determined by consulting -->
<!-- 		  the UPCB, is dropped. A -->
<!-- 		  <progident>MalformedProcess</progident> fault code -->
<!-- 		  is set in the invokee's -->
<!-- 		  <progident>faultCode</progident> slot, and the -->
<!-- 		  invokee transitions to the running state. -->
<!-- 		</p> -->
<!-- 	      </li> -->
	    </ol>
	  </li>
	</ul>
	<p>
	  By intention, kernel-implemented operations satisfy two
	  invariants that simplify or eliminate other potentially
	  obscure corner cases:
	</p>
	<ul>
	  <li>
	    <p>
	      No kernel-implemented interface accepts or returns an
	      indirect string.
	    </p>
	  </li>
	  <li>
	    <p>
	      Kernel methods that modify address space mappings or
	      revoke objects return only scalar return values (and
	      therefore behave as if
	      <progident>SC=0</progident>). This ensures that changes
	      in the meaning of the receive capability
	      <progident>capitem_t</progident> values cannot impact
	      the return of these operations.
	    </p>
	  </li>
	</ul>
	<p>
	  <leadin>Undefined Locations</leadin> The content of receive
	  buffers, receive parameters, and receive capability
	  locations is undefined between the start of the IPC receive
	  phase and the completion of the IPC receive phase.  For
	  performance reasons, the kernel is entitled to arbitrarily
	  modify state whose content is undefined during
	  invocation. In particular, the kernel is entitled to modify
	  the receive parameters or the receive string buffers of a
	  waiting process without releasing that process from its wait
	  state. This allows the kernel to more efficiently implement
	  indirect string moves that may induce invoker or invokee
	  page faults during the transfer. This means that
	  <em>all</em> of the receive string buffers of a recipient
	  may be modified during receive, even if the final message
	  received sends only a single indirect byte.  Similarly, any
	  valid receive capability locations may be overwritten even
	  if a smaller number of capabilities was transferred.
	</p>
	<p>
	  <leadin>State Transitions</leadin> The overwhelming majority
	  of kernel capability invocations return to the invoker
	  without generating any exception. In these cases, the kernel
	  may behave as if the operation occurred instantaneously,
	  with the consequence that the invoker may never be observed
	  to leave the <em>running</em> state.
	</p>
	<p>
	  <leadin>Elided Reply Capability</leadin> When a kernel
	  capability is invoked and replies to the invoker without an
	  exception, the kernel implementation is free to elide the
	  fabrication of the reply capability. Elided reply
	  capabilities are observable because the protected payload
	  value of the reply endpoint will not be incremented.
	</p>
      </sect1>
    </chapter>
    <chapter id="syscalls">
      <title>System Calls</title>
      <p>
	Coyotos currently defines four system calls:
      </p>
      <table latex.center="yes" latex.colspec="llp{4.5in}">
	<thead>
	  <tr>
	    <td>Number</td>
	    <td>Name</td>
	    <td>Description</td>
	  </tr>
	</thead>
	<tbody>
	  <tr>
	    <td>0</td>
	    <td><progident>InvokeCap</progident></td>
	    <td>
	      <p>
		Invokes a capability and (optionally) waits for a
		reply on an endpoint.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>1</td>
	    <td><em>reserved</em></td>
	    <td>
	      <p>
		Reserved for future use.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>2</td>
	    <td><progident>CopyCap</progident></td>
	    <td>
	      <p>
		Copy a capability from one location to another.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>3</td>
	    <td><progident>Yield</progident></td>
	    <td>
	      <p>
		Yield the processor, moving the current process to the
		back of its scheduling class.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>4..15</td>
	    <td><em>reserved</em></td>
	    <td>
	      <p>
		Reserved for future use.
	      </p>
	    </td>
	  </tr>
	</tbody>
      </table>
      <sect1 id="param_words">
	<title>Parameters and Parameter Words</title>
	<p>
	  At the system call trap interface, arguments and return
	  values are conveyed by means of <em>parameter
	  words</em>. The size of a parameter word is determined by
	  the native machine word size. The number of the parameter
	  words is system-call dependent.  Parameter words may be
	  transmitted across the user/supervisor boundary in memory
	  (via the stack) or in registers. The specification of which
	  parameter words are carried in registers at system call
	  entry and exit is defined by the architecture-specific
	  annex. No annex defines fewer than five registers to be
	  available at this interface.
	</p>
	<p>
	  The Coyotos system call specification ensures that all
	  arguments and return values of system calls <em>other
	  than</em> <progident>InvokeCap</progident> can be marshalled
	  in registers. In addition, the majority of
	  kernel-implemented capabilities, including all capabilities
	  likely to be invoked in performance-critical application
	  paths, can be invoked solely through register-marshalled
	  arguments and return values <em>except</em> where indirect
	  strings are used.
	</p>
<!-- 	<p> -->
<!-- 	  On 32-bit platforms, there are 64 parameter -->
<!-- 	  words. On 64-bit platforms, there are 32 parameter words. -->
<!-- 	</p> -->
<!-- 	<p> -->
<!-- 	  All integral scalar types used in the kernel interface, -->
<!-- 	  including those specified as parameters of capability -->
<!-- 	  interfaces and system calls, are naturally aligned -->
<!-- 	  regardless of target platform word size. In particular, 64 -->
<!-- 	  bit integer arguments and fields are aligned at 64 bit -->
<!-- 	  offsets, and structures containing these values (if any) are -->
<!-- 	  required to be aligned at 64 bit boundaries wherever they -->
<!-- 	  are presented at the kernel interface.  Note that on 32-bit -->
<!-- 	  targets this imposes a <em>general</em> alignment constraint -->
<!-- 	  only for <em>nested</em> structures. When an outermost -->
<!-- 	  structure is presented as OUT parameter on a 32-bit -->
<!-- 	  platform, the structure pointer given may be 32-bit aligned. -->
<!-- 	  However, if the same structure is copied to parameter words -->
<!-- 	  during marshalling or demarshalling, the marshalled from -->
<!-- 	  will be naturally aligned within the parameter words. -->
<!-- 	</p> -->
	<p>
	  In the system call specifications that follow, the notations
	  IPW<em>n</em> and OPW<em>n</em> indicate input and output
	  parameter words, respectively. Other fields appearing in
	  input and output descriptions have locations determined by
	  the architecture-specific annex, typically in the UPCB or in
	  registers.  Parameter words above the last parameter word
	  returned by a system call hold the same value that they held
	  at kernel entry.
	</p>
      </sect1>
      <sect1 id="syscall_exceptions">
	<title>Exceptions</title>
	<p>
	  The following exceptions may be incurred by the caller
	  during system call execution.
	</p>
	<table latex.center="yes" latex.colspec="lp{4in}">
	  <thead>
	    <tr>
	      <td><b>Exception</b></td>
	      <td><b>Cause</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td><progident>MalformedSyscall</progident></td>
	      <td>
		<p>
		  The operand was malformed. This includes field
		  value range errors or reserved type codes.
		</p>
		<p>
		  The <progident>faultInfo</progident> field is
		  zero.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>MisalignedReference</progident></td>
	      <td>
		<p>
		  The operand specified a capability address, but
		  the address described is not aligned to a 16-byte
		  boundary.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>InvalidAddress</progident></td>
	      <td>
		<p>
		  The operand specified an address that is
		  not defined.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>AccessViolation</progident></td>
	      <td>
		<p>
		  A store operation was attempted, but the operand
		  specified an address that does not permit write
		  access.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>DataAccessTypeError</progident></td>
	      <td>
		<p>
		  The address specified by a data load/store operand
		  does not reference a data page.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>CapAccessTypeError</progident></td>
	      <td>
		<p>
		  The address specified by a capability load/store
		  system call does not reference a capability page.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>MalformedSpace</progident></td>
	      <td>
		<p>
		  The address specified by the operand violated the
		  well-formed address space constraints.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	  </tbody>
	</table>
	<p>
	  Any system call may generate the
	  <progident>MalformedSyscall</progident> exception if bits
	  marked ``reserved'' are non-zero or specified field value
	  bounds are exceeded.  Individual system call descriptions
	  below specify which of the other exceptions may be incurred
	  by that system call.
	</p>
      </sect1>
      <sect1>
	<title>Capability Parameter Types</title>
	<p>
	  The system call specifications that follow reference the
	  types shown in Figure&nbsp;<xref ref="param_types"/>.
	</p>
	<figure id="param_types" latex.placement="h">
	  <table>
	    <tbody>
	      <tr>
		<td><progident>capreg_t</progident></td>
		<td><img source="capreg_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td><progident>caploc_t</progident></td>
		<td><img source="caploc_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <caption>Parameter type layouts</caption>
	</figure>
	<sect2 id="capregs">
	  <title>Meaning of <progident>capreg_t</progident></title>
	  <p>
	    A <progident>capreg_t</progident> parameter
	    (Figure&nbsp;<xref ref="param_types"/>) is an 8-bit value
	    that describes a capability register.  Capability register
	    zero is defined by the architecture to hold a Null
	    capability. The least <progident>ty</progident> field of a
	    <progident>capreg_t</progident> is required to be
	    zero. This provides for assignability between
	    <progident>capreg_t</progident> and
	    <progident>caploc_t</progident>.
	  </p>
	  <p>
	    A register <progident>capreg_t</progident> appearing as a
	    source operand indicates that the contents of the
	    capability register indexed by the
	    <progident>location</progident> field should be used as
	    the source parameter.
	  </p>
	  <p>
	    A register <progident>capreg_t</progident> appearing as a
	    destination operand indicates that the capability register
	    indexed by the <progident>location</progident> should be
	    used as the destination of the operation. Assignments to
	    capability register zero are silently discarded.
	  </p>
	</sect2>
	<sect2 id="caplocs">
	  <title>Meaning of <progident>caploc_t</progident></title>
	  <p>
	    A <progident>caploc_t</progident> parameter
	    (Figure&nbsp;<xref ref="param_types"/>) describes a
	    generalized capability location that is either a
	    capability register (ty=0) or a memory
	    address (ty=1).
	  </p>
	  <p>
	    The encoding of register <progident>caploc_t</progident>
	    values is identical to the encoding used for
	    <progident>capreg_t</progident> values, modulo the wider
	    <progident>location</progident> field. When the
	    <progident>caploc_t</progident> describes a memory
	    address, the <progident>location</progident> field holds
	    the most significant bits of the address. Capability
	    addresses are required to be 16 byte aligned. In
	    consequence, the expression of valid capability addresses
	    is not restricted by the re-use of the least significant
	    bit for this purpose.
	  </p>
	  <p>
	    The size of a <progident>caploc_t</progident> matches the
	    architecture-defined word size.
	  </p>
	</sect2>
      </sect1>
      <sect1>
	<title>Typed Item Parameters</title>
	<p>
	  <em>Section now stale; update coming.</em>
	</p>
	<p>
	  The <progident>InvokeCap</progident> system call
	  (Section&nbsp;<xref ref="syscall_invcap"/>) defines some of
	  its parameter words as a sequence of <em>untyped parameter
	  words</em> followed by a sequence of <em>typed
	  items</em>. Each typed item is described by one or more more
	  <em>typed item words</em>. The defined typed items are shown
	  in Figure&nbsp;<xref ref="param_types"/>.
	</p>
	<figure id="item_types" latex.placement="h">
	  <table>
	    <tbody>
	      <tr>
		<td><progident>stringitem_t</progident></td>
		<td><img source="stringitem_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td><progident>bufitem_t</progident></td>
		<td><img source="bufitem_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td><progident>epiditem_t</progident></td>
		<td><img source="epiditem_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td><progident>capitem_t</progident></td>
		<td><img source="capitem_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td><progident>rcvcapitem_t</progident></td>
		<td><img source="rcvcapitem_t" width="65"
		    srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <caption>Parameter type layouts</caption>
	</figure>
	<sect2 id="endpointiditems">
	  <title>Meaning of Endpoint ID Items
	    (<progident>epiditem_t</progident>)</title>
	  <p>
	    If CW is set, an endpoint ID item indicates the endpoint
	    ID on which the application wishes to wait. Otherwise,
	    this field should be supplied on input an arbitrarily
	    selected endpoint ID. The corresponding output parameter
	    will contain the endpoint ID of the invoked endpoint, if
	    any.
	  </p>
	</sect2>
	<sect2 id="stringitems">
	  <title>Meaning of String Items
	    (<progident>stringitem_t</progident>)</title>
	  <p>
	    A logical string consists of one or more logically
	    concatenated (gathered) substrings. Each
	    <progident>stringitem_t</progident> describes a single
	    substring. If the continuation bit <em>c</em> of a
	    <progident>stringitem_t</progident> is set (1), this
	    indicates that the <em>next</em>
	    <progident>stringitem_t</progident> describes a
	    continuation of the same logical string.  The last
	    substring in the string is indicated by a
	    <progident>stringitem_t</progident> whose continuation bit
	    <em>c</em> is clear (0).  Each substring in turn is made
	    up of <em>j</em>&nbsp;&ge;&nbsp;1 cords having identical
	    length. The <em>string length</em> field is
	    <u>inclusive</u>. A string of length zero is encoded using
	    a <em>j</em> value of zero.
	  </p>
	  <p>
	    <leadin>Example</leadin> A contiguous, 27 byte string at
	    address <em>s</em> is encoded by the string item:
	  </p>
	  <figure id="stringitem_ex_simple" latex.placement="h">
	    <img source="stringitem_ex_simple" width="65" srctype="sbox"/>
	  </figure>
	  <p>
	    <leadin>Example</leadin> A gathered string consisting of
	    an initial 33 byte fragement at address <em>a</em>
	    followed by two 4096 byte fragments at addresses
	    <em>b</em> and <em>c</em> is encoded by the sequence of
	    string items:
	  </p>
	  <figure id="stringitem_ex_complex" latex.placement="h">
	    <img source="stringitem_ex_complex" width="65" srctype="sbox"/>
	  </figure>
	  <p>
	    The string item structure is adapted from the L4
	    specification <cite ref="sag04l4refman"/>, but not all of
	    the features expressible in L4 are currently supported by
	    Coyotos. In particular, the <em>hh</em> bits are reserved
	    for architecture-dependent cacheability hints, and are
	    required to be zero by the current implementation.
	  </p>
	  <p>
	    When a string item is passed as a parameter to an
	    invocation, the words of the string item are passed as
	    successive parameter words.
	  </p>
	</sect2>
	<sect2 id="bufitems">
	  <title>Meaning of Buffer Items
	    (<progident>bufitem_t</progident>)</title>
	  <p>
	    Buffer items are the dual of string items. They describe
	    how an incoming string should be distributed (scattered)
	    in the receiving address space.
	  </p>
	  <p>
	    In contrast to string items, which induce the invocation
	    path to perform string copies, a
	    <progident>bufitem_t</progident> is interpreted by the
	    invocation path as overwriting successive receive buffer
	    registers. That is: the <em>k</em>th
	    <progident>bufitem_t</progident> overwrites
	    <progident>rcvBuf</progident> register <em>k</em>.
	  </p>
	</sect2>
	<sect2 id="capitems">
	  <title>Meaning of Capability Items
	    (<progident>capitem_t</progident>)</title>
	  <p>
	    Capability items describe the locations of capabilities
	    that are to be transmitted by the current invocation. The
	    interpretation of the <progident>location</progident> and
	    <progident>ty</progident> fields are interpreted the same
	    way as for <progident>caploc_t</progident> parameters,
	    except that the the <progident>location</progident> field
	    holds the most significant bits of the address (the 4
	    least significant bits are not required due to alignment
	    requirements).
	  </p>
	</sect2>
	<sect2 id="rcvcapitems">
	  <title>Meaning of Receive Capability Items
	    (<progident>rcvcapitem_t</progident>)</title>
	  <p>
	    Receive capability items are the dual of capability
	    items. They describe how an incoming capability should be
	    stored in the receiving context.
	  </p>
	  <p>
	    In contrast to capability items, which induce the
	    invocation path to perform capability copies, a
	    <progident>rcvcaptem_t</progident> is interpreted by the
	    invocation path as overwriting successive receive
	    capability location registers. That is: the <em>k</em>th
	    <progident>rcvcapitem_t</progident> overwrites
	    <progident>rcvCap</progident> register <em>k</em>.
	  </p>
	</sect2>
	<sect2>
	  <title>Order of Appearance</title>
	  <p>
	    When typed items are passed to the
	    <progident>InvokeCap</progident> system call, those that
	    are present must be ordered by type. Endpoint ID items
	    (<progident>epiditem_t</progident>) must appear first,
	    followed by string items
	    (<progident>stringitem_t</progident>) must appear first,
	    followed by capability items
	    (<progident>capitem_t</progident>) followed by buffer
	    items, (<progident>bufitem_t</progident>) followed by
	    receive capability items
	    (<progident>bufitem_t</progident>). If this ordering is
	    not maintained, a <progident>MalformedSyscall</progident>
	    exception is generated.
	  </p>
	</sect2>
      </sect1>
      <sect1 id="pseudo_instrs">
	<title>Pseudo-Instructions</title>
	<p>
	  The <progident>Yield</progident> and
	  <progident>CopyCap</progident> system calls are best
	  thought of as pseudo-instructions.
	</p>
	<sect2 id="syscall_Yield">
	  <title>Yield [syscall]</title>
	  <p>
	    The <progident>Yield</progident> system call relinquishes
	    the processor. If the <progident>I</progident> bit is clear
	    (0), the yielding process is placed at the end of the
	    appropriate ready queue.
	  </p>
	  <table latex.center="yes">
	    <thead>
	      <tr>
		<td>Parameter</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPW0</td>
		<td><img source="syscall-yield-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The <progident>Yield</progident> system call does not return
	    any output parameters.
	  </p>
	  <note>
	    <title>Open Issue</title>
	    <p>
	      Should there be a directed yield operation? If so, the
	      yield system call needs to take a second parameter.
	    </p>
	  </note>
	</sect2>
	<sect2 id="syscall_copycap">
	  <title>CopyCap [syscall]</title>
	  <table latex.center="yes">
	    <thead>
	      <tr>
		<td>Parameter</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPW0</td>
		<td><img source="syscall-copycap-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPW1</td>
		<td><img source="syscall-copycap-ipw1" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPW2</td>
		<td><img source="syscall-copycap-ipw2" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The <progident>CopyCap</progident> system call copies a
	    capability from a source location (register or memory address)
	    to a target location (register or memory address).
	    The <progident>CopyCap</progident> system
	    call does not return any output parameters. Exceptions may
	    be generated by the references to the <em>source</em> and 
	    <em>dest</em> parameters.
	  </p>
	  <p>
	    Any of the exceptions listed in Section&nbsp;<xref
	    ref="syscall_exceptions"/> other than
	    <progident>DataAccessTypeError</progident> may be
	    generated by this system call.
	  </p>
	</sect2>
      </sect1>
      <sect1 id="syscall_invcap">
	<title>InvokeCap [syscall]</title>
	<p>
	  The <progident>InvokeCap</progident> system call invokes a
	  capability, passing the supplied parameters to the
	  implementing server. It is both the most complex and the
	  most commonly used system call in the interface. It invokes
	  one capability and optionally blocks for an incoming message
	  on an Endpoint. <progident>InvokeCap</progident> takes a
	  variable number of parameters determined by the invocation
	  control word provided in IPW0.
	</p>
	<p>
	  Any of the exceptions listed in Section&nbsp;<xref
	    ref="syscall_exceptions"/> may be generated by this system
	  call.
	</p>
	<sect2 id="invcap_args">
	  <title>Arguments</title>
	  <p>
	    <progident>InvokeCap</progident> accepts a variable number
	    of arguments specified by the invoker. The argument
	    parameters to <progident>InvokeCap</progident> are:
	  </p>
	  <table latex.center="yes" latex.colspec="llp{5in}">
	    <thead>
	      <tr>
		<td>Argument</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPW0</td>
		<td><img source="syscall-invcap-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPW1</td>
		<td><img source="syscall-invcap-ipw1" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPW2..IPW<em>u</em></td>
		<td><img source="syscall-invcap-word" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPW<em>u+1</em>..IPW<em>u+t+1</em></td>
		<td><img source="syscall-invcap-titem" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The first parameter word (IPW0) is the invocation control
	    word. The fields of this word have the following meanings:
	  </p>
	  <table latex.colspec="llp{5in}" latex.long="yes">
	    <thead>
	      <tr>
		<td><b>Bit</b></td>
		<td><b>Name</b></td>
		<td><b>Meaning</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>NB</td>
		<td>Non-Blocking</td>
		<td>
		  <p>
		    If set (1), send is non-blocking. Any action that
		    would require the sender to be enqueued in such a
		    fashion that re-awakening is controlled by the
		    receiver will result in a dropped message. Any
		    action that would cause a receiver-controlled
		    exception handler to be executed will result in a
		    truncated message.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>RC</td>
		<td>Reply Capability</td>
		<td>
		  <p>
		    If set (1), and <progident>sndCap0</progident>
		    names an endpoint capability,
		    <progident>sndCap0</progident> will be replaced
		    with the corresponding Entry capability. The
		    protected payload of the Entry capability will be
		    set to the current protected payload value stored
		    in the endpoint.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>CW</td>
		<td>Closed Wait</td>
		<td>
		  <p>
		    If set (1), indicates that the receive phase is
		    performing a closed wait, and only messages from
		    endpoints whose endpoint ID matches
		    <progident>recv_id</progident> will be
		    accepted.
		  </p>
		  <p>
		    If clear (0), no restrictions are imposed on
		    receipt and the <progident>recv_id</progident>
		    field is ignored.
		  </p>
		</td>
	      </tr>	   
	      <tr>
		<td>RP</td>
		<td>Receive Phase</td>
		<td>
		  <p>
		    If set (1), the receive phase will be executed.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>AS</td>
		<td>Accept Strings</td>
		<td>
		  <p>
		    If clear (0), any string items recieved will be
		    dropped.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>AC</td>
		<td>Accept Capabilities</td>
		<td>
		  <p>
		    If clear (0), any capabilities received will be
		    dropped.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>u</td>
		<td>Untyped Words</td>
		<td>
		  <p>
		    The index of the last untyped word parameter,
		    including IPW0.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>t</td>
		<td>Typed Words</td>
		<td>
		  <p>
		    The index of the last typed word parameter. Note
		    that the interface requires at least an endpoint
		    ID parameter word to be present in all
		    invocations.
		  </p>
		</td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The parameters of the <progident>InvokeCap</progident>
	    system call are unusual, in that IPW0 determines how the
	    remaining input parameter words are interpreted. Further,
	    some of the bits in the IPW0 word determine how the output
	    parameteres are processed and delivered.
	    <progident>InvokeCap</progident> is <em>also</em> unusual
	    because control flow may not return immediately to the
	    invoker. Finally, it is unusual because an
	    <progident>InvokeCap</progident> system call may cause
	    exceptions to be incurred by the receiver <em>during</em>
	    the system call rather than before it.
	  </p>
	  <sect3>
	    <title>Conventions</title>
	    <p>
	      <progident>InvokeCap</progident> is a reflective system
	      call.  Because the kernel-implemented capabilities use
	      the same request marshalling and demarshalling
	      conventions as application-implemented capabilities,
	      these conventions are effectively mandated.
	    </p>
	    <p>
	      <leadin>Requests</leadin> IPW2 contains the request code
	      (a method code that is typically assigned by
	      CapIDL). The implementing process uses this request
	      code, in combination with the received endpoint ID and
	      protected payload, to determine what interface has been
	      invoked, what method has been requested, and what
	      permissions the invoker has. By convention, no method
	      should be assigned the method code zero (0).
	    </p>
	    <p>
	      <leadin>Replies</leadin> IPW2 of a reply either contains
	      zero (0), indicating a normal result, or non-zero,
	      indicating an exceptional result. If IPW2 of the reply
	      is zero, the remaining parameters are the result of the
	      method as specified by the appropriate IDL
	      specification. If IPW2 of the reply is non-zero, the
	      remaining parameters are determined by the exception
	      specification. In effect, all replies are a tagged union
	      descriminated by their first untyped word value.
	    </p>
	  </sect3>
	  <sect3>
	    <title>Kernel Invocation Conventions</title>
	    <p>
	      The following behavioral specification describes the
	      semantics of the <progident>InvokeCap</progident>
	      instruction as if the capability invoked were an Entry
	      capability. If the capability invoked is a
	      kernel-implemented capability, the invocation behaves as
	      if the kernel were a receiving process that had just
	      performed a SendAndWait with IPW0 and IPW1 fields set as
	      follows:
	    </p>
	    <table latex.center="yes" latex.colspec="lp{2in}lp{2in}">
	      <thead>
		<tr>
		  <td><b>Field</b></td>
		  <td><b>Meaning</b></td>
		  <td><b>Field</b></td>
		  <td><b>Meaning</b></td>
		</tr>
	      </thead>
	      <tbody>
		<tr>
		  <td>IPW0.CW=0</td>
		  <td>Perform an open wait.</td>
		  <td>IPW0.NB=0</td>
		  <td>Reply will be non-blocking.</td>
		</tr>
		<tr>
		  <td>IPW0.AS=1</td>
		  <td>Accept string arguments.</td>
		  <td>IPW0.AC=1</td> <td>Accept capability
		  arguments.</td>
		</tr>
		<tr>
		  <td>IPW1</td>
		  <td>(ignored <progident>capitem_t</progident>).</td>
		  <td>IPW0.RP=1</td>
		  <td>Perform a receive operation.</td>
		</tr>
		<tr>
		  <td>IPW0.RC=0</td> 
		  <td>No reply capability.</td> 
		  <td>IPW0.{u,t}</td>
		  <td>Set according to last operation.</td>
		</tr>
	      </tbody>
	    </table>
	  </sect3>
	</sect2>
	<sect2>
	  <title>Return Values</title>
	  <p>
	    The return values of <progident>InvokeCap</progident> are
	    copies of the sender's argument values with minor
	    alterations:
	  </p>
	  <ul>
	    <li>
	      <p>
		The protected payload of the invoked endpoint
		capability is supplied in place of the invoked
		capability <progident>caploc_t</progident>.
	      </p>
	    </li>
	    <li>
	      <p>
		The sender control bits are replaced by
		<progident>T</progident>, a bit indicating that one or
		more incoming typed items were truncated.
	      </p>
	    </li>
	    <li>
	      <p>
		All addresses supplied in the input typed items are
		zeroed in the output typed items.
	      </p>
	    </li>
	    <li>
	      <p>
		On output, the kernel injects an
		<progident>epiditem_t</progident> as the first output
		typed item.
	      </p>
	    </li>
	  </ul>
	  <table latex.center="yes" latex.colspec="llp{5in}">
	    <thead>
	      <tr>
		<td>Result</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>OPW0</td>
		<td><img source="syscall-invcap-opw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPW1</td>
		<td><img source="syscall-invcap-rcvPP" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPW2..OPW<em>u</em></td>
		<td><img source="syscall-invcap-word" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPW<em>u+1</em>..OPW<em>u+t+1</em></td>
		<td><img source="syscall-invcap-titem" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
<!-- 	<sect2> -->
<!-- 	  <title>Send Phase</title> -->
<!-- 	  <p> -->
<!-- 	    Because of the many exceptions that are possible, the -->
<!-- 	    steps performed by the <progident>InvokeCap</progident> -->
<!-- 	    instruction must be specified in detail. -->
<!-- 	  </p> -->
<!-- 	  <note> -->
<!-- 	    <title>Incomplete Algorithm</title> -->
<!-- 	    <p> -->
<!-- 	      The algorithm description given below does not consider -->
<!-- 	      short messages that may be cached in endpoints. That is, -->
<!-- 	      it assumes that the endpoint <progident>CM</progident> -->
<!-- 	      bit is clear (0) at the time of invocation. The -->
<!-- 	      algorithm specification will be revised when endpoint -->
<!-- 	      message caching is implemented. -->
<!-- 	    </p> -->
<!-- 	  </note> -->
<!-- 	  <p> -->
<!-- 	    The send phase conveys three types of information: -->
<!-- 	  </p> -->
<!-- 	  <ol> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The object to be invoked (via -->
<!-- 		<progident>IPW1</progident>), if any. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The payload parameters to be transferred to the -->
<!-- 		invokee, if any. These include the untyped parameter -->
<!-- 		words and typed item parameter words -->
<!-- 		<em>excluding</em> typed items of types -->
<!-- 		<progident>bufitem_t</progident>, -->
<!-- 		<progident>epiditem_t</progident> or -->
<!-- 		<progident>rcvcap_t</progident>. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		Pseudo-parameters that update the internal receive -->
<!-- 		register state of the invoker. These are the typed -->
<!-- 		item parameters of types -->
<!-- 		<progident>bufitem_t</progident>, -->
<!-- 		<progident>epiditem_t</progident> or -->
<!-- 		<progident>rcvcap_t</progident>. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	  </ol> -->
<!-- 	  <p indent="no"> -->
<!-- 	    Note that if the <progident>IPW0.u</progident> field is -->
<!-- 	    zero, the send phase is entirely skipped. If the send -->
<!-- 	    phase is skipped, input typed item words will not be -->
<!-- 	    processed. Notably, this means that typed item parameters -->
<!-- 	    which update the receive buffers will not be processed. -->
<!-- 	    The kernel implementation exploits the fact that -->
<!-- 	    <progident>IPW0.u</progident> is always registerized to -->
<!-- 	    allow it to zero the <progident>IPW0.u</progident> field -->
<!-- 	    at the end of the send. This update prevents -->
<!-- 	    re-transmission of messages in the face of -->
<!-- 	    checkpoint/restart. -->
<!-- 	  </p> -->
<!-- 	  <ol> -->
<!-- 	    <li id="ipc_start"> -->
<!-- 	      <p> -->
<!-- 		<leadin>Validity Check</leadin> If the reserved bits -->
<!-- 		of <progident>IPW0</progident> are non-zero, a -->
<!-- 		<progident>MalformedSyscall</progident> exception is -->
<!-- 		delivered to the invoker. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If the <progident>IPW0.u</progident> field contains -->
<!-- 		zero, the send phase terminates immediately, -->
<!-- 		processing proceeds immediately to the receive phase -->
<!-- 		of the system call. The remainder of the send phase -->
<!-- 		processing is skipped. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		<progident>IPW1</progident> is interpreted as a -->
<!-- 		<progident>capitem_t</progident> to determine the -->
<!-- 		capability invoked, and the invoked capability is -->
<!-- 		fetched. If the capability is fetched from the address -->
<!-- 		space, the address space is traversed, which has the -->
<!-- 		effect of preparing the capabilities along the -->
<!-- 		traversed path. If insufficient permissions are -->
<!-- 		provided by the referenced path, a memory reference -->
<!-- 		exception is delivered to the invoker. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		The invoked capability becomes the <em>invokee</em> -->
<!-- 		capability until otherwise proven. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The invoked capability named by -->
<!-- 		<progident>IPW1</progident> is prepared -->
<!-- 		(Section&nbsp;<xref ref="capability_prepare"/>). -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		A pass is made over the typed item words to process -->
<!-- 		items of types <progident>epiditem_t</progident>, -->
<!-- 		<progident>capitem_t</progident>,  -->
<!-- 		<progident>bufitem_t</progident>, -->
<!-- 		and -->
<!-- 		<progident>rcvcapitem_t</progident>. If a -->
<!-- 		<progident>epiditem_t</progident> is found, the -->
<!-- 		invoker's <progident>process.rcvEpID</progident> field -->
<!-- 		is updated. Typed items of type -->
<!-- 		<progident>bufitem_t</progident>, and -->
<!-- 		<progident>rcvcapitem_t</progident> are copied to the -->
<!-- 		invoker's <progident>rcvParam[]</progident> vector. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		During this pass, if the invoked capability is not of -->
<!-- 		type Entry, the first <progident>capitem_t</progident> -->
<!-- 		becomes the <em>invokee</em> capability. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The invokee capability is prepared. If (after prepare) -->
<!-- 		this capability is not of type Entry, or if a -->
<!-- 		protected payload match is required and fails, there is no -->
<!-- 		invokee. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The process capability contained in the invokee entry -->
<!-- 		point is prepared. If (after prepare), this capability -->
<!-- 		is not a process capability, there is no invokee. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If the invokee process is not now in the -->
<!-- 		<em>receiving</em> state, the invoker is enqueued -->
<!-- 		until the invokee enters the receiving start. On -->
<!-- 		wakeup, invocation will re-start at step&nbsp;<xref -->
<!-- 		ref="ipc_start"/>. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		If the invokee process and the current process are the -->
<!-- 		same, and the IPW0.RP field is set (1), the invokee -->
<!-- 		is deemed to be in the <em>receiving</em> state. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If an invokee exists, the invokee is locked. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If an invokee exists, and their -->
<!-- 		<progident>IPW0.AC</progident> bit is set (1), the -->
<!-- 		invokee <progident>rcvParam[]</progident> vector is -->
<!-- 		traversed to find and lock all capability pages that -->
<!-- 		will contain output capability parameters. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If an invokee exists, and their -->
<!-- 		<progident>IPW0.AS</progident> bit is set (1), the -->
<!-- 		invokee <progident>rcvParam[]</progident> vector is -->
<!-- 		traversed to find and lock all capability pages that -->
<!-- 		will contain output capability parameters. -->
<!-- 	      </p> -->
<!-- 	    </li> -->

<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		The invoked capability named by -->
<!-- 		<progident>IPW1</progident> is examined, and several -->
<!-- 		mutually exclusive sanity conditions are checked: -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		<em>Some of these are not right</em> -->
<!-- 	      </p> -->
<!-- 	      <ul> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    <leadin>Kernel-Implemented</leadin> If the invoked -->
<!-- 		    capability is a non-entry capability, send-phase -->
<!-- 		    processing continues at step&nbsp;<xref -->
<!-- 		      ref="cap_args"/>. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    <leadin>Invalid Endpoint</leadin> If the invoked -->
<!-- 		    capability is an Entry capability whose endpoint -->
<!-- 		    contains a Null capability in its recipient slot, -->
<!-- 		    the send phase terminates successfully and -->
<!-- 		    processing proceeds to the receive phase of the -->
<!-- 		    system call. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    <leadin>Invokee Receiving</leadin> If the -->
<!-- 		    invokee is receiving on the invoked endpoint, send -->
<!-- 		    phase processing continues at step <xref -->
<!-- 		    ref="ipc_block_move"/>. -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    An invokee is deemed to be receiving on an -->
<!-- 		    endpoint if the invokee is in the <em>receiving</em> -->
<!-- 		    state, and either: -->
<!-- 		  </p> -->
<!-- 		  <ul> -->
<!-- 		    <li> -->
<!-- 		      <p> -->
<!-- 			The invokee's <progident>IPW0.cw</progident> -->
<!-- 			bit is clear (0), <em>or</em> -->
<!-- 		      </p> -->
<!-- 		    </li> -->
<!-- 		    <li> -->
<!-- 		      <p> -->
<!-- 			The invokee's <progident>rcvEpID</progident> -->
<!-- 			value matches the endpoint ID value stored in -->
<!-- 			the invoked endpoint object. -->
<!-- 		      </p> -->
<!-- 		    </li> -->
<!-- 		  </ul> -->
<!-- 		</li> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    <leadin>Not receiving, Non-Blocking Send</leadin> -->
<!-- 		    If the <progident>IPW0.NB</progident> bit is set -->
<!-- 		    (1), the send phase terminates successfully and -->
<!-- 		    processing proceeds to the receive phase of the -->
<!-- 		    sytem call. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    <leadin>Not Receiving, Blocking Send</leadin> the -->
<!-- 		    invoker blocks until the invokee becomes -->
<!-- 		    available. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 	      </ul> -->
<!-- 	    </li> -->
<!-- 	    <li id="ipc_block_move"> -->
<!-- 	      <p> -->
<!-- 		If the invokee's <progident>IPW0.AS</progident> bit is -->
<!-- 		clear(0), send processing continues at step <xref -->
<!-- 		ref="cap_args"/>, and no page faults will be incurred -->
<!-- 		by either invoker or invokee.  Otherwise: -->
<!-- 	      </p> -->
<!-- 	      <ol> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    The invokee's <progident>OPW0.TS</progident> bit -->
<!-- 		    and the invokee's <progident>OPW0.t</progident> -->
<!-- 		    field are zeroed. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    The invoker-specified indirect strings are -->
<!-- 		    transferred in sequence to the locations specified -->
<!-- 		    by the invokee's buffer registers. -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    Page faults incurred in the invoker address space, if -->
<!-- 		    any, are delivered to the invoker. These faults are -->
<!-- 		    logically delivered before the start of the system -->
<!-- 		    call. -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    Page faults incurred in the invokee address space are -->
<!-- 		    conditionally delivered depending on the invoker's -->
<!-- 		    <progident>IPW0.NB</progident> value: -->
<!-- 		  </p> -->
<!-- 		  <ul> -->
<!-- 		    <li> -->
<!-- 		      <p> -->
<!-- 			If the invoker -->
<!-- 			<progident>IPW0.NB</progident> is set (1): -->
<!-- 		      </p> -->
<!-- 		      <ul> -->
<!-- 			<li> -->
<!-- 			  <p>The current string item transfer terminates.</p> -->
<!-- 			</li> -->
<!-- 			<li> -->
<!-- 			  <p>The invokee's  -->
<!-- 			    <progident>OPW0.TS</progident> bit is set (1).</p> -->
<!-- 			</li> -->
<!-- 			<li> -->
<!-- 			  <p>The send phase completes and execution resumes -->
<!-- 			    with the receive phase.</p> -->
<!-- 			</li> -->
<!-- 		      </ul> -->
<!-- 		    </li> -->
<!-- 		    <li> -->
<!-- 		      <p> -->
<!-- 			Otherwise, a page fault exception is delivered to -->
<!-- 			the invokee. This exception is logically delivered -->
<!-- 			prior to the start of the system call. -->
<!-- 		      </p> -->
<!-- 		    </li> -->
<!-- 		  </ul> -->
<!-- 		  <p> -->
<!-- 		    If a transferred string would overflow the limit -->
<!-- 		    encoded in a non-continued receive buffer, the -->
<!-- 		    remainder of the transmitted string is discarded -->
<!-- 		    and the invokee's <progident>OPW0.TS</progident> -->
<!-- 		    bit is set (1).  String transfer resumes with the -->
<!-- 		    next transmitted string.  It is the responsibility -->
<!-- 		    of the receiver to validate that received string -->
<!-- 		    lengths are consistent with the requirements of -->
<!-- 		    the application-defined protocol. -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    A receive buffer containing a string item having a -->
<!-- 		    zero length indicates that no further strings will -->
<!-- 		    be accepted. This allows an IDL compiler to avoid -->
<!-- 		    saving and restoring buffer registers that are not -->
<!-- 		    used by the current invocation. Transmitted string -->
<!-- 		    items at and beyond this receive buffer will be -->
<!-- 		    truncated and the <progident>OPW0.TS</progident> -->
<!-- 		    bit will be set (1). -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    As each invoker indirect string is processed, the -->
<!-- 		    corresponding string item parameter word -->
<!-- 		    <progident>IPW<em>i</em></progident> is copied to -->
<!-- 		    the invokee's output parameter word -->
<!-- 		    <progident>OPW<em>i</em></progident>. The -->
<!-- 		    invoker's source address is replaced in the output -->
<!-- 		    parameter word with the actual length received -->
<!-- 		    (this supports overrun detection).  On exit, the -->
<!-- 		    invokee's <progident>OPW0.t</progident> field will -->
<!-- 		    give the number of transmitted string items. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 	      </ol> -->
<!-- 	    </li> -->
<!-- 	    <li id="cap_args"> -->
<!-- 	      <p> -->
<!-- 		The invokee's <progident>OPW0.c</progident> and -->
<!-- 		<progident>OPW0.SC</progident> fields are zeroed. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		If <progident>IPW0.SC</progident> is clear (0), -->
<!-- 		send-phase processing processing proceeds to -->
<!-- 		step&nbsp;<xref ref="ipc_untyped_params"/>. No -->
<!-- 		capability-related exceptions will be incurred by the -->
<!-- 		invoker or the invokee. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		Otherwise, the argument capabilities designated by the -->
<!-- 		invoker's <progident>sndCap[0,<em>IPW0.c</em>]</progident> -->
<!-- 		are marshalled.  If a transmitted capability is sent -->
<!-- 		from the address space, marshalling may cause -->
<!-- 		exceptions to be delivered to the invoker. These -->
<!-- 		exceptions are logically delivered prior to the start -->
<!-- 		of the system call. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		The invokee's receive capability locations specified -->
<!-- 		in the invokee -->
<!-- 		<progident>rcvCap[0,<em>c</em>]</progident> registers -->
<!-- 		are now checked for necessary access rights. The value -->
<!-- 		of <em>c</em> is the maximum capability index sent by -->
<!-- 		the invoker, specified in the invoker's -->
<!-- 		<progident>IPW0.c</progident> field.  Page faults -->
<!-- 		incurred during this check are conditionally delivered -->
<!-- 		depending on the invoker's -->
<!-- 		<progident>IPW0.NB</progident> value, according to the -->
<!-- 		same rules using for receiver-side string buffer -->
<!-- 		faults, except that the invokee's -->
<!-- 		<progident>OPW0.TC</progident> bit is set to indicate -->
<!-- 		that capability arguments have been truncated. Send -->
<!-- 		phase execution continues at step&nbsp;<xref -->
<!-- 		ref="ipc_cap_copy"/>. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li id="ipc_cap_copy"> -->
<!-- 	      <p> -->
<!-- 		Argument capabilities to successfully validated -->
<!-- 		capability destinations are transferred to the -->
<!-- 		invokee-designated locations. The invokee's -->
<!-- 		<progident>OPCW0.c</progident> field is updated to -->
<!-- 		indicate the number of capabilities received, and the -->
<!-- 		invokee's <progident>OPCW0.c</progident> field is set -->
<!-- 		to indicate the index of the highest capability -->
<!-- 		transferred. If <progident>OPCW0.TC</progident> has -->
<!-- 		been set, this will be the index of the capability -->
<!-- 		whose transfer could not be performed. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li id="ipc_untyped_params"> -->
<!-- 	      <p> -->
<!-- 		The untyped parameter arguments up to the index -->
<!-- 		specified by the invoker IPW0.c field are copied to -->
<!-- 		the invokee with the following modifications: -->
<!-- 	      </p> -->
<!-- 	      <ul> -->
<!-- 		<li> -->
<!-- 		  <p> -->
<!-- 		    The invokee's <progident>OPW0</progident> value -->
<!-- 		    will contain the values indicated in the preceding -->
<!-- 		    steps. -->
<!-- 		  </p> -->
<!-- 		  <p> -->
<!-- 		    The invokee's <progident>OPW1</progident> value -->
<!-- 		    will contain the protected payload value of the -->
<!-- 		    invoked entry capability. -->
<!-- 		  </p> -->
<!-- 		</li> -->
<!-- 	      </ul> -->
<!-- 	      <p> -->
<!-- 		The invokee's <progident>rcvEpID</progident> field -->
<!-- 		is updated to contain the endpoint ID value of the -->
<!-- 		invoked endpoint. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li id="pp_update"> -->
<!-- 	      <p> -->
<!-- 		If the invoked capability is an entry capability, and -->
<!-- 		the designated endpoint's <progident>PM</progident> -->
<!-- 		bit is set (1), the protected payload value stored in the -->
<!-- 		endpoint is incremented. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		The kernel does not check for payload value -->
<!-- 		overflow. It is the responsibility of the application -->
<!-- 		to replace the receive endpoint payload overflow -->
<!-- 		occurs. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	    <li id="ipc_state_change"> -->
<!-- 	      <p> -->
<!-- 		The invokee enters the <em>running</em> state. Invoker -->
<!-- 		execution proceeds to the receive phase. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	  </ol> -->
<!-- 	</sect2> -->
<!-- 	<sect2> -->
<!-- 	  <title>Receive Phase</title> -->
<!-- 	  <ol> -->
<!-- 	    <li> -->
<!-- 	      <p> -->
<!-- 		If the invoker's <progident>IPW0.NR</progident> bit is -->
<!-- 		set (1), the invoker returns immediately with -->
<!-- 		<progident>OPW0.TC=0</progident> -->
<!-- 		<progident>OPW0.TS=0</progident> -->
<!-- 		<progident>OPW0.SC=0</progident> -->
<!-- 		<progident>OPW0.u=0</progident> -->
<!-- 		<progident>OPW0.t=0</progident>, and -->
<!-- 		<progident>OPW0.c=0</progident>. The invoker continues -->
<!-- 		in the <em>running</em> state. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		If the invoker's <progident>IPW0.NR</progident> bit is -->
<!-- 		clear (0), the invoker now enters the -->
<!-- 		<em>receiving</em> state until an invocation is -->
<!-- 		received. -->
<!-- 	      </p> -->
<!-- 	      <p> -->
<!-- 		On exit, the output parameter words will contain the -->
<!-- 		values indicated above in the description of the send -->
<!-- 		phase. The system call returns to the caller with the -->
<!-- 		caller in the <em>running</em> state. -->
<!-- 	      </p> -->
<!-- 	    </li> -->
<!-- 	  </ol> -->
<!-- 	</sect2> -->
      </sect1>
    </chapter>
    <chapter id="scheduling">
      <title>Schedules</title>
      <sect1>
	<title>Scheduling Model</title>
      </sect1>
    </chapter>
    <chapter>
      <title>Other Kernel Objects</title>
      <p>
	This chapter describes the services provided by the
	miscellaneous kernel capabilities.
      </p>
      <p>
	The <progident>null</progident> capability is used when a
	non-optional capability field must be transmitted but the
	sender does not wish to send a capability in that position.
	Capabilities to destroyed objects become null.
      </p>
      <p>
	The <progident>keybits</progident> capability discloses the
	canonical representation of capablities. The
	<progident>keybits</progident> capability is considered
	sensitive, and should be closely held. The value of the
	hazard bit <term>HZ</term> is always shown as zero.
      </p>
      <p>
	The <progident>discrim</progident> capability classifies
	capabilities into one of a limited set of
	classifications. The purpose of
	<progident>discrim</progident> is to support the
	implementation of the confinement policy by the
	<progident>constructor</progident>, which is one of the core
	Coyotos applications.
      </p>
      <p>
	The <progident>range</progident> capability conveys the
	authority to fabricate and destroy arbitrary object
	capabilities. The <progident>range</progident> capability is
	highly sensitive, and should be closely held.
      </p>
      <p>
	The <progident>sleep</progident> capability allows its
	holder to receive an event at a scheduled time.
      </p>
      <p>
	The <progident>irqCtl</progident> capability allows the
	holder to register interest in hardware interrupt
	events. This capability is highly sensitive, and should be
	closely held.
      </p>
      <p>
	The <progident>schedctl</progident> capability
	allows the holder to alter the kernel-level scheduling
	dispatch table. This capability is highly sensitive, and
	should be closely held.
      </p>
      <p>
	The <progident>checkpoint</progident> capability allows the
	holder to initiate a system-level snapshot operation and
	force the checkpoint age-out logic to run to
	completion. This capability is highly sensitive, and should
	be closely held.
      </p>
      <p>
	The <progident>obstore</progident> capability implements a
	``reverse'' protocol. The object store server uses this
	capability to wait for kernel object fill and flush requests
	and acts on them.
      </p>
    </chapter>
  </part>
  <part>
    <title>Microkernel Interfaces</title>
    <xi:include href="AddressSpace.xmli"/>
    <xi:include href="AppNotice.xmli"/>
    <xi:include href="Cap.xmli"/>
    <xi:include href="CapPage.xmli"/>
    <xi:include href="Checkpoint.xmli"/>
    <xi:include href="Discrim.xmli"/>
    <xi:include href="Endpoint.xmli"/>
    <xi:include href="GPT.xmli"/>
    <xi:include href="IrqCtl.xmli"/>
    <xi:include href="CapBits.xmli"/>
    <xi:include href="LocalWindow.xmli"/>
    <xi:include href="Memory.xmli"/>
    <xi:include href="MemoryHandler.xmli"/>
    <xi:include href="Null.xmli"/>
    <xi:include href="ObStore.xmli"/>
    <xi:include href="Page.xmli"/>
    <xi:include href="Process.xmli"/>
    <xi:include href="ProcessHandler.xmli"/>
    <xi:include href="Range.xmli"/>
    <xi:include href="RcvQueue.xmli"/>
    <xi:include href="SchedCtl.xmli"/>
    <xi:include href="Schedule.xmli"/>
    <xi:include href="Sleep.xmli"/>
    <xi:include href="SysCtl.xmli"/>
    <xi:include href="Window.xmli"/>
  </part>
  <part>
    <title>Architecture Specific Annexes</title>
    <appendix>
      <title>IA-32 Interface</title>
      <p>
	The kernel header file
	<filename>coyotos/i386/UPCB.h</filename> defines the UPCB
	layout for this architecture.
      </p>
      <sect1>
	<title>Execution Models</title>
	<p>
	  The IA-32 implementation supports the ``small spaces''
	  optimization. If a process restricts its address references
	  (ignoring KIP references) to the inclusive range [0,
	  0x10000], the kernel will attempt to run it in a small space
	  region. Control transfers between two applications running
	  in a small address space, or between a large address space
	  and a small address space, are significantly faster than
	  large space control transfer.
	</p>
	<p>
	  By referencing an address outside of the small space bound,
	  a process signals that it wishes to be treated as a large
	  address space process. The user-mode addressable range of a
	  large address space is [0x0,0xC0000000]. Because this
	  transition is transparent to the process, the value returned
	  by 
	  <progident>LSL</progident> (load segment limit) is subject
	  to change between any two instructions. The transition
	  between large and small address space models is otherwise
	  transparent to application code.
	</p>
      </sect1>
      <sect1>
	<title>System Call Trap Interface</title>
	<p>
	  In all cases the register utilization convention follows the
	  requirements of <smallcaps>SYSENTER</smallcaps>:
	</p>
	<floatingtable id="ia32_syscall_conventions" latex.placement="h">
	  <!-- On sysexit, EIP from EDX, ESP from ECX -->
	  <!-- On sysret,  EIP from ECX -->
	  <table latex.center="yes" latex.colspec="lll">
	    <thead>
	      <tr>
		<td><b>Register</b></td> <td><b>Input</b></td>
		<td><b>Output</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>EAX</td>
		<td><progident>IPW0</progident></td>
		<td><progident>OPW0</progident></td>
	      </tr>
	      <tr>
		<td>EBX</td>
		<td><progident>IPW1</progident></td>
		<td><progident>OPW1</progident></td>
	      </tr>
	      <tr>
		<td>ECX</td>
		<td><em>Post-syscall SP</em></td>
		<td><em>Undefined</em></td>
	      </tr>
	      <tr>
		<td>EDX</td>
		<td><em>Post-syscall return PC</em></td>
		<td><em>Undefined</em></td>
	      </tr>
	      <tr>
		<td>ESI</td>
		<td><progident>IPW2</progident></td>
		<td><progident>OPW2</progident></td>
	      </tr>
	      <tr>
		<td>EDI</td>
		<td><progident>IPW3</progident></td>
		<td><progident>OPW3</progident></td>
	      </tr>
	      <tr>
		<td>EBP</td>
		<td><progident>InvokeCap: invCap</progident></td>
		<td><progident>InvokeCap: rcvPP</progident></td>
	      </tr>
	      <tr>
		<td></td>
		<td><progident>Other: <em>unused</em></progident></td>
		<td><progident>Other: <em>unaltered</em></progident></td>
	      </tr>	
	      <tr>
		<td>ESP</td>
		<td><em>Unavailable</em></td>
		<td><em>input ECX value</em></td>
	      </tr>
	    </tbody>
	  </table>
	  <caption>System call entry and exit conventions.</caption>
	</floatingtable>
	<p>
	  Different generations of IA-32 implementations require
	  different system call implementations for
	  efficiency. Depending on the hardware implementation, either
	  a software interrupt (<progident>int $0x31</progident>) the
	  <smallcaps>sysenter</smallcaps> instruction, or the
	  <smallcaps>syscall</smallcaps> instruction may be used. The
	  software interrupt entry point may be used on all platforms.
	  The preferred entry and exit mechanism is left to the kernel
	  implementation. The kernel publishes the preferred mechanism
	  via the <term>kernel interface page</term>. The system call
	  trap instruction appears at offset zero of this page.
	</p>
	<p>
	  The kernel interface page is mapped into all user address
	  spaces at a well-known <em>far</em> address:
	  <progident>0x32:0</progident>.<footnote>
	    <p>
	      The selector value is provisional.
	    </p>
	  </footnote>
	  The protocol for invoking the preferred system call trap
	  instruction is to marshall all arguments 
	  and perform a
	  <em>far jump</em> to this address. The use of a far address
	  allows the kernel interface page to be accessable to both
	  large and small address spaces within a single compilation
	  and execution model.  This address is a well-known constant
	  that is part of the architecture specification, and will not
	  change in future versions of Coyotos.
	</p>
      </sect1>
      <sect1>
	<title>Activation Return</title>
	<p>
	  The kernel supplies a ``return from activation handler''
	  entry point at offset 256 of the kernel interface page. The
	  purpose of this entry point is to allow an activation
	  handler to return to normal mode without entering the
	  kernel. The return to normal mode requires a
	  multi-instruction atomic sequence. The activation return
	  entry point accomplishes this by connivance with the kernel;
	  if a process executing the activation return sequence is
	  interrupted, the kernel will complete the sequence on behalf
	  of the process.
	</p>
	<p>
	  A process returning from activation mode should first store
	  the desired normal-mode PC, SP, and EFLAGS values into the
	  UCPB's <progident>savedPC</progident>,
	  <progident>savedSP</progident>, and
	  <progident>savedFlags</progident> fields. It should then
	  load all registers other than %ESP and %EIP with the desired
	  normal-mode values and branch to the activation return entry
	  point at <progident>0x32:256</progident>. This entry point
	  tests the <progident>upcb.PE</progident> bit, invoking the
	  <progident>Yield()</progident> system call explicitly if
	  <progident>upcb.PE</progident> is non-zero. Otherwise it
	  clears the <progident>upcb.A</progident> bit and proceeds to
	  reload the intended EFLAGS, PC, and SP values by hand. If an
	  interrupt occurs within the activation return sequence, the
	  kernel will execute:
	</p>
	<literallayout>
if (upcb.PE) {
  upcb.a             &lt;- 1;
  upcb.dispatchPC    &lt;- upcb.actPC;
  upcb.dispatchSP    &lt;- upcb.actSP;
  upcb.dispatchFlags &lt;- <em>architecture defined</em>;
  upcb.pe            &lt;- 1 if multiple events pending, 0 otherwise
else {
  upcb.a             &lt;- 0;
  upcb.dispatchPC    &lt;- upcb.savedPC;
  upcb.dispatchSP    &lt;- upcb.savedSP;
  upcb.dispatchFlags &lt;- upcb.savedFlags;
}</literallayout>
      </sect1>
      <sect1>
	<title>Virtual Registers</title>
	<p>
	  The architecture defines the following locations for input
	  and output parameters, buffer registers, and capability
	  invocation paramaters. Locations described with an
	  identifier rather than a register name indicate a field in
	  the UPCB structure.
	</p>
	<table latex.center="yes" latex.colspec="llll">
	  <thead>
	    <tr>
	      <td><b>Virtual Register</b></td>
	      <td><b>Location</b></td>
	      <td><b>Virtual Register</b></td>
	      <td><b>Location</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td>IPW0</td>
	      <td><progident>%eax</progident></td>
	      <td>OPW0</td>
	      <td><progident>%eax</progident></td>
	    </tr>
	    <tr>
	      <td>IPW1</td>
	      <td><progident>%ebx</progident></td>
	      <td>OPW1</td>
	      <td><progident>%ebx</progident></td>
	    </tr>
	    <tr>
	      <td>IPW2</td>
	      <td><progident>%esi</progident></td>
	      <td>OPW2</td>
	      <td><progident>%esi</progident></td>
	    </tr>
	    <tr>
	      <td>IPW3</td>
	      <td><progident>%edi</progident></td>
	      <td>OPW3</td>
	      <td><progident>%edi</progident></td>
	    </tr>
	    <tr>
	      <td>IPW4..IPW63</td>
	      <td><em>caller stack</em></td>
	      <td>OPW4..OPW63</td>
	      <td><progident>upcb.OPW4..upcb.OPW63</progident></td>
	    </tr>
	    <tr>
	      <td>invCap</td>
	      <td><progident>%ebp</progident></td>
	      <td>rcvPP</td>
	      <td><progident>%ebp</progident></td>
	    </tr>
	    <tr>
	      <td>rcvEpID</td>
	      <td><progident>upcb.epID</progident></td>
	      <td>BR0..BR31</td>
	      <td><progident>upcb.BR0..upcb.BR31</progident></td>
	    </tr>
	  </tbody>
	</table>
      </sect1>
      <sect1>
	<title>Thread Identification</title>
	<p>
	  The first two words of the UPCB are used by the
	  application-level runtime system to provide support for
	  multi-threading. Word 0 should be used by the
	  multi-threading library to store the pointer to the thread
	  control block. Word 1 should be used to store the virtual
	  address of the UPCB itself, as seen by the
	  application. Neither word is initialized by the kernel.
	  Provided the address range exposed falls within the
	  user-mode addressable range, the value of UPCB word 1 is
	  loaded as the base address of the segment named by %GS, with
	  a limit value of 0x1000.
	</p>
	<p>
	  The critical effect of this is that %GS:0 can be used to
	  load and store the application-level thread control block
	  pointer, which is in turn used to access thread-local
	  storage <cite ref="elf-handling"/>.
	</p>
	<note>
	  <title>Open Issue</title>
	  <p>
	    While storing the UPCB VA in the UPCB is attractive, it is
	    not necessarily efficient. The problem is that the value
	    must be range checked on every kernel exit because it can
	    be modified by user-mode code. It may be better to
	    introduce a system call for this and store it in the KPCB
	    instead.
	  </p>
	</note>
      </sect1>
    </appendix>
  </part>
  <part>
    <title>Notes on Implementation</title>
    <p>
      The Coyotos specification may be seen as defining an abstract
      machine architecture. In a real-world implementation, this
      abstract machine must be mapped on to a combination of hardware
      and software by the kernel implementation. This mapping must
      satisfy two properties:
    </p>
    <ul>
      <li>
	<p>
	  <b>The permissions of the implementation state must never exceed
	  those of the abstract state.</b> Any instruction whose
	  effect is permitted by the implementation state must be
	  permited by the abstract machine state. The implementation
	  state is a conservative approximation of the abstract state.
	</p>
      </li>
      <li>
	<p>
	  <b>Ignoring latency, every instruction whose execution is
	  permitted by the abstract machine must ultimately be
	  permitted by the implementation.</b> The implementation
	  state is an approximation of the abstract state that is
	  constructed on demand.
	</p>
	<p>
	  The means by which demand update is triggered are the system
	  call trap and the various protection and permissions
	  violation traps.  This induces several requirements on the
	  underlying hardware:
	</p>
	<ul>
	  <li>
	    <p>
	      The hardware must implement page-granularity protections
	      (or better) in its memory management unit.
	    </p>
	  </li>
	  <li>
	    <p>
	      The hardware must implement precise exceptions &mdash;
	      or precise enough that the software implementation can
	      correct them (e.g. the Pentium family's breakpoint trap
	      incorrectly advances the program counter, but the amount
	      of the advance is known and be corrected in software.
	    </p>
	  </li>
	  <li>
	    <p>
	      Preferred hardware must implement a ``no-execute''
	      permission. This is a recently rediscovered feature in
	      the hardware world, and the specification does not
	      require <progident>NX</progident> permissions to be
	      enforced on hardware that does not provide this feature.
	    </p>
	  </li>
	</ul>
      </li>
    </ul>
    <p>
      Any change to the abstract state that reduces permissions must
      be reflected by an immediate change in the hardware state that
      (conservatively) maintains these invariants. In some cases it is
      not obvious how to do this. This part of the specification
      discusses possible implementation techniques for several key
      parts of the dependency tracking implementation.
    </p>
    <p>
      The entirety of this part is non-normative.
    </p>
    <chapter>
      <title>Implementation of Capabilities</title>
      <p>
	Because so much of any implementation depends on the internal
	representation of capabilities, we begin with a brief
	discussion of capability representation choices.
      </p>
      <p>
	It is convenient for capabilities to have two forms, which we
	call <term>prepared</term> and <term>unprepared</term>. The
	unprepared form is the one described in Section~<xref
	ref="caprep"/>. The <progident>P</progident> bit indicates
	whether the capability is prepared (1) or unprepared (0). The
	representation of a prepared capability is a matter that is
	private to the kernel. When the kernel discloses capability
	representation to application code, it <em>always</em>
	discloses the unprepared format.
      </p>
      <sect1>
	<title>Unprepared Capabilities</title>
	<p>
	  An unprepared capability may be valid or invalid, because it
	  is not known from the capability whether the object it names
	  has been destroyed subsequent to the creation of the
	  capability. This can only be known by comparing the
	  <progident>allocCount</progident> of the capability to the
	  <progident>allocCount</progident> of the object itself.
	</p>
	<p>
	  Assuming the capability is valid, the object designated by an
	  unprepared capability may or may not be in memory. This can
	  only be determined by performing an object lookup to discover
	  whether the object is in memory. In all current implemenations
	  of KeyKOS, EROS, and Coyotos, a hash table is maintained that
	  provides a mapping from object id (<progident>OID</progident>)
	  to the actual object for every object that is currently in
	  memory. In systems supporting transparent persistence, there
	  may be <em>two</em> objects for a given
	  <progident>OID</progident>: the current one and the one that
	  was current at the time of the last snapshot.
	</p>
      </sect1>
      <sect1>
	<title>Prepared Capabilities &mdash; Linked Implementation</title>
	<p>
	  In KeyKOS and EROS, a prepared capability designates an
	  object that is known to be in memory. The prepared
	  capability points directly to this object. In addition, the
	  prepared capability resides on a ``key chain'', which is a
	  circularly linked list whose ``head'' is part of the object
	  header. This allows the object to be efficiently found given
	  the capability, and also allows all prepared capabilities to
	  be found given the object.
	</p>
	<figure latex.placement="h">
	  <img source="keychain" width="30" srctype="gif"/>
	  <caption>EROS/KeyKOS key chain</caption>
	</figure>
	<p>
	  There are several advantages to this design:
	</p>
	<ul>
	  <li>
	    <p>
	      Once a capability is determined to be prepared, the
	      object is known to be in memory as a consequence of
	      invariants, and few further checks related to residency
	      or well-formedness are necessary. In addition, the
	      capability is known to be valid, in the sense that its
	      <progident>allocCount</progident> matches that of the
	      target object.
	    </p>
	  </li>
	  <li>
	    <p>
	      When an object is destroyed, it is straightforward to
	      locate the active capabilities to the object and rewrite
	      them as invalid capabilities.
	    </p>
	  </li>
	  <li>
	    <p>
	      When an object is to be removed from memory, it is
	      straightforward to locate all capabilities to the object
	      and restore them to their unprepared form.
	    </p>
	  </li>
	  <li>
	    <p>
	      In either the destruction or pageout case, it is
	      straightforward to identify the <em>locations</em> of
	      all prepared capabilities. KeyKOS and EROS exploit this
	      property very aggressively. They maintain a significant
	      amount of dependency information in hashed structures
	      that are indexed by capability address. For example, the
	      KeyKOS/EROS ``depend table'' is a hash table of
	      (capability address, page table entry address) pairs.
	    </p>
	  </li>
	</ul>
	<p>
	  However, there is a key disadvantage as well:
	</p>
	<ul>
	  <li>
	    <p>
	      Capability copy is a frequent operation. Empirically, we
	      found in EROS that many copied capabilities were
	      prepared, that most overwritten capabilities were
	      prepared, and that updating the key chain when both the
	      source and destination capabilities are prepared entails
	      three cache misses per copy to access the neighbors
	      (Figure&nbsp;<xref ref="keycopy"/>). On
	      modern machines, this cost is a substantial fraction of
	      the total IPC cost.
	    </p>
	  </li>
	  <li>
	    <p>
	      Capability invocation may take time O(<em>n</em>), where
	      <em>n</em> is the size of memory. This is possible
	      because an arbitrary number of resume capabilities may
	      accumulate on the key chain, and the chain needs to be
	      traversed in order to destroy them.
	    </p>
	  </li>
	</ul>
	<figure id="keycopy" latex.placement="h">
	  <img source="keycopy" width="30" srctype="gif"/>
	  <caption>EROS/KeyKOS key copy</caption>
	</figure>
      </sect1>
      <sect1>
	<title>Prepared Capabilities &mdash; Scavenged
	Implementation</title>
	<p>
	  In Coyotos, a prepared capability does <em>not</em>
	  guarantee either that the target object is in memory or that
	  the prepared capability is valid. We are accepting weaker
	  invariants in order to improve capability copy
	  performance. Instead of a linked list, the relationship
	  between a capability and its object is shown in Figure&nbsp;<xref
	  ref="cap-obtable"/>.
	</p>
	<figure id="cap-obtable" latex.placement="h">
	  <img source="cap-obtable" srctype="gif" width="40"/>
	  <caption>Capability/object relationship</caption>
	</figure>
	<p>
	  In this design, the capability points to the object
	  (equivalently: holds an index), but also contains a pointer
	  (equivalently: an index) to an
	  <progident>ObTable</progident> structure. The object pointer
	  is valid only if the capability's
	  <progident>ObTable</progident> reference matches the
	  <progident>ObTable</progident> reference in the object
	  itself. The purpose of the <progident>ObTable</progident>
	  structure is to hold the information needed to deprepare the
	  capability back to its on-disk form. This consists of a copy
	  of the object ID (because that field of the capability is
	  overwritten by the references) and a valid bit.  Under normal circumstances, an object has one
	  <progident>ObTable</progident> entry.<footnote>
	    <p>
	      There may be none if
	      there are no prepared capabilities to this object, but this
	      is a transient case because object page-in is induced only
	      by capability preparation.
	    </p>
	  </footnote>
	</p>
	<p>
	  When an object is paged out, the first step is to change the
	  <progident>ObTable</progident> reference in the object
	  header to Null. This ensures that all outstanding
	  capabilities will be deprepared back to their on-disk
	  format. When an object is destroyed, the valid bit in the
	  current <progident>ObTable</progident> entry is set to
	  ``invalid'' before the <progident>ObTable</progident>
	  reference in the object header is nullified. In this
	  situation, outstanding capabilities will be deprepared to
	  the Null capability.  Capabilities are deprepared through a
	  combination of proactive update when the containing object
	  is written to store and background scavenging.
	</p>
	<sect2>
	  <title>Scavenging</title>
	  <p>
	    This design requires an oversupply of
	    <progident>ObTable</progident> structures.
	    <progident>ObTable</progident> structures are freed by
	    background scavenging. The scavenging proceeds as follows:
	  </p>
	  <ol>
	    <li>
	      <p>
		Make a pass over all 
		<progident>ObTable</progident> structures. Mark the
		ones that are current. Clear the mark on the ones that
		are not current.
	      </p>
	    </li>
	    <li>
	      <p>
		Traverse all in-memory objects that contain
		capabilities. For each capability:
	      </p>
	      <ul>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    current, leave the capability alone.
		  </p>
		</li>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    invalid, deprepare the capability to null.
		  </p>
		</li>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    valid but not current, deprepare the capability
		    back to it's on-disk form.
		  </p>
		</li>
	      </ul>
	    </li>
	    <li>
	      <p>
		Make a second pass over all 
		<progident>ObTable</progident> structures, placing the
		unmarked structures onto the free list.
	      </p>
	    </li>
	  </ol>
	  <p>
	    This algorithm can be implemented incrementally by forcing
	    some progress whenever an <progident>ObTable</progident>
	    entry is allocated.
	  </p>
	  <p>
	    Note that the algorithm is <em>not</em> trying to detect
	    unreferenced objects. This is the responsibility of the
	    ageing logic, which is handled separately.
	  </p>
	  <p>
	    When the algorithm is executed incrementally, there is the
	    usual race between the mark pass and the mutator that is
	    copying and overwriting references. The unfortunate case
	    is the sequence where:
	  </p>
	  <ol>
	    <li>
	      <p>
		The mark pass has moved past capability slot A, but
		has not yet reached slot B.
	      </p>
	    </li>
	    <li>
	      <p>
		Slot B holds the only outstanding capability to some
		object.
	      </p>
	    </li>
	    <li>
	      <p>
		A copy is made from slot B to slot A.
	      </p>
	    </li>
	    <li>
	      <p>
		Slot B is overwritten before it is reached by the mark
		pass. A now holds the only capablity to the
		<progident>ObTable</progident> entry, but it will not
		be seen by the mark pass.
	      </p>
	    </li>
	  </ol>
	  <p>
	    Note that the race condition does not matter if B is a
	    <em>valid</em> capability, because in this case the
	    <progident>ObTable</progident> structure is already
	    marked. The issue arises only when B is an
	    <em>invalid</em> capability. The race is resolved by
	    checking whenever a prepared capability is copied, and
	    updating the newly written capability to the null
	    capability if it is invalid.
	  </p>
	</sect2>
	<sect2>
	  <title>Pros and Cons</title>
	  <p>
	    The primary advantage of this design over the KeyKOS/EROS
	    design is speed of capability copy. There is only one
	    marginal cache miss per copy, which is the probe that
	    checks the capability for validity. If it is feasible to
	    scan all processes in a non-incremental fashion, this
	    probe can be eliminated in the fast IPC path because any
	    copy proceeding <em>from</em> a capability register does
	    not need to be checked for validity. The need for this
	    optimization should be guided by measurement, and our
	    initial implementation will not attempt it.
	  </p>
	  <p>
	    The main disadvantage is that this design requires an
	    incremental scavenging pass whose performance cost is not
	    yet known.
	  </p>
	</sect2>
      </sect1>
    </chapter>
    <chapter>
      <title>Mapping Dependencies</title>
      <p>
	The most challenging set of structures to design in the
	Coyotos implementation is the mechanism for keeping GPT
	structures, objects, and page table entries consistent. There
	are three requirements:
      </p>
      <ol>
	<li>
	  <p>
	    When a page is destroyed or removed from memory,
	    all page table entries that point to that page must be
	    invalidated.
	  </p>
	</li>
	<li>
	  <p>
	    When a GPT is destroyed or removed from memory, all
	    currently valid translations in the page table structures
	    that were constructed by traversing the GPT must be
	    invalidated.
	  </p>
	</li>
	<li>
	  <p>
	    When a capability slot within a GPT is overwritten, all
	    currently valid translations in the page table structures
	    that were constructed by traversing that slot of the GPT
	    must be invalidated. This may viewed as a sub-case of (2).
	  </p>
	</li>
      </ol>
      <sect1>
	<title>Page Removal</title>
	<p>
	  In KeyKOS and EROS, the key chain meant that any
	  implementation of requirement (3) also satisfied requirement
	  (1). When a page is removed from memory, its key chain can be
	  traversed to locate all of the capability slots that reference
	  the page. These can then be used to invalidate the necessary
	  page table entries.
	</p>
	<p>
	  In the Coyotos implementation, which does not have a key
	  chain, we maintain a reverse page table structure known as
	  <progident>PTE<sup>-1</sup></progident>. For every valid
	  page table entry in the hardware page table, we maintain a
	  reverse entry that provides a mapping from the physical
	  object address to the kernel virtual address of its
	  referencing page table entry.
	</p>
	<p>
	  In systems having hierarchical page tables, we maintain this
	  inverse page table structure at all levels of the
	  translation hierarchy. This allows mapping tables to be aged
	  and reclaimed.
	</p>
      </sect1>
      <sect1>
	<title>GPT Dependencies</title>
	<p>
	  The statement of requirements in (2, 3) is a bit subtle. The
	  straightforward implementation of these requirements is to
	  record a pairwise relationship between capability slot
	  addresses and page table entry addresses, and use this to
	  invalidate all page table entries when a slot is overwritten
	  or a GPT is removed. This was, in essence, the implementation
	  used by KeyKOS and EROS, and it is fairly straightforward to
	  see why it satisfies the requirement that ``the permissions of
	  the implementation state must never exceed those of the
	  abstract state.'' However, this implementation is both
	  unnecessarily aggressive and unnecessarily expensive.
	</p>
	<p>
	  Because we do not rely on key rings for page removal,
	  Coyotos has slightly different properties than KeyKOS or
	  EROS. Whenever we consider changing the value of a slot, we
	  always have the address of its containing GPT in
	  hand.<footnote>
	    <p>
	      In EROS, we knew the location of the vector of Nodes
	      (the precursor to GPTs), and we could use this knowledge
	      to infer the containing Node address from any given Node
	      slot address. This inference is not memory safe, and we
	      wanted to avoid it in Coyotos in anticipation of later
	      verification efforts.
	    </p>
	  </footnote>. Coyotos therefore maintains a dependency table
	  that maps from GPT addresses to page table entry
	  addresses. There may be multiple entries in this table for a
	  given GPT. This can happen for two reasons:
	</p>
	<ol>
	  <li>
	    <p>
	      A GPT may produce multiple page tables because it spans
	      multiple entries in a page directory (Figure&nbsp;<xref
	      ref="gpt-pt-span"/>). This arises only in hardware
	      system having hierarhical translation systems, but it
	      can arise at any ``layer'' of the translation system. In
	      fact, a single GPT can span three or more layers if it
	      describes the only valid path across multiple levels of
	      the hardware tables.
	    </p>
	  </li>
	  <li>
	    <p>
	      Because of page table reuse, a GPT may produce both
	      read-only and read-write variants of the same page table.
	    </p>
	  </li>
	</ol>
	<figure id="gpt-pt-span" latex.placement="h">
	  <img source="gpt-pt-span" srctype="gif" width="60"/>
	  <caption>Capability/object relationship</caption>
	</figure>
	<p>
	  The hierarchical case is complicated by the desire for page
	  table sharing. In KeyKOS and EROS, we recorded dependency
	  information at all implicated levels of the hardware
	  translation hierarchy. In Coyotos we do not. Instead, we
	  record dependencies only when the GPT wholly or partially
	  dominates the hardware table. This is sufficient to let is
	  invalidate all <em>paths</em> through the hardware tree that
	  are implicated by changes to a GPT. It does <em>not</em>
	  allow us to invalidate all of the page table entries, but we
	  assert this is not actually necessary to satisfy the
	  requirements.
	</p>
	<p>
	  This assertion is <em>not</em> obvious and will need to be
	  confirmed by demonstration as we develop a statement of
	  invariants maintained by the translation logic in this
	  case. The substance of it, however, is that valid entries
	  higher in the hardware structures do not matter if all of
	  the lower entries they span are correctly invalidated. If
	  the GPT is being destroyed, the lower tables will in due
	  course be reclaimed and the higher-level page table entries
	  will then be invalidated. If the GPT is being overwritten,
	  the higher-level page table entries would get rebuilt in any
	  case, and the permissions of the lower-level page table
	  entries are sufficient to ensure a conservative mapping of
	  the abstract machine's permission state.
	</p>
      </sect1>
      <sect1>
	<title>Optimizations</title>
	<p>
	  Ironically, the new structure should be more compact than
	  the old structure.
	</p>
	<p>
	  <leadin>Inverse Page Table</leadin> The
	  <progident>PTE<sup>-1</sup></progident> table requires only
	  a single word per entry, because the pointer to the PTE can
	  be used to read the physical page address in order to detect
	  hash collisions and stale dependency table entries.
	</p>
	<p>
	  Observe further that the majority of pages and page tables
	  have only one or two simultaneous page table entries. A
	  possible storage optimization is to dedicate two
	  <progident>PTE<sup>-1</sup></progident> entries in the frame
	  management structures for each of these, leaving the general
	  <progident>PTE<sup>-1</sup></progident> table to handle only
	  those pages that are widely shared. Whether this is
	  worthwhile depends on whether a sufficiently good hash
	  function can be discovered to keep hash chains short in the
	  usual case.
	</p>
	<p>
	  <leadin>GPT Dependencies</leadin> Because we use GPT object
	  pointers rather than GPT slot pointers in the GPT dependency
	  table, our GPT dependency table will have a factor of 16
	  (well, given underutilization probably a factor of 5 to 8)
	  reduction in space requirements compared to the old
	  dependency tracking scheme.
	</p>
	<p>
	  Observe that while a GPT may produce entries in multiple
	  page tables, it always produces 2<sup><em>k</em></sup>
	  entries at a natural alignment boundary within those
	  tables. This statement is also true of GPT <em>slots</em>,
	  and offered a basis for run length compression of the GPT
	  dependency table in some implementations. We note that this
	  option remains available in the new implementation.
	</p>
      </sect1>
    </chapter>
  </part>
  <bibliography>
    <bibentry label="elphinstone99vm64">
      Kevin John Elphinstone. <doctitle>Virtual Memory in a 64-Bit
	Microkernel</doctitle>. Ph.D. Dissertation. University of New
      South Wales, School of Computer Science, August 31, 1999.
    </bibentry>
    <bibentry label="hardy1985keykos">
      Norman Hardy. ``The KeyKOS Architecture.'' <doctitle>Operating
        Systems Review</doctitle>, <b>19</b>(4),  October 1985,
        pp. 8&ndash;25.
    </bibentry>
<!--     <bibentry label="landau2005capros"> -->
<!--       Charles Landau. ``CapROS: The Capability-based Reliable -->
<!--         Operating System.'' <tt>http://www.capros.org</tt>. -->
<!--     </bibentry> -->
    <bibentry label="liedtke1995gpt4600">
      Jochen Liedtke and Kevin Elphinstone. <doctitle>Guarded Page Tables on
      the MIPS R4600, or, An Exercise in Architecture-Dependent Micro
      Optimization.</doctitle> Technical Report UNSWCSE-TR-9503,
      University of New South Wales, School of Computer Science, 1995.
    </bibentry>
    <bibentry label="shap1999fastcapsystem">
      J. S. Shapiro, J. M. Smith, and D. J. Farber. ``EROS, A Fast
      Capability System'' <doctitle>Proc. 17th ACM Symposium on Operating
      Systems Principles</doctitle>. Dec 1999. pp. 170&ndash;185. Kiawah
      Island Resort, SC, USA.
    </bibentry>
    <bibentry label="shap2002store">
      J. S. Shapiro, J. Adams. ``Design Evolution of the EROS
      Single-Level Store'' <doctitle>Proc. 2002 USENIX Annual
      Technical Conference</doctitle>. 2002. pp. 59&ndash;72.
    </bibentry>
<!--     <bibentry label="shap2003vulnerabilities"> -->
<!--       J. S. Shapiro. ``Vulnerabilities in Synchronous IPC Design'' -->
<!--       <doctitle>Proc. 2003 IEEE Symposium on Security and -->
<!--       Privacy</doctitle>. 2003.Oakland, CA, USA. -->
<!--     </bibentry> -->
    <bibentry label="shap2004towards">
      J. Shapiro, M. Doerrie, S. Sridhar, M. Miller. ``Towards a
      Verified, General-Purpose Operating System Kernel''
      <doctitle>Proc. NICTA OS Verification Workshop 2004</doctitle>. 
      October, 2004. Sydney, New South Wales, Australia.
    </bibentry>
    <bibentry label="shap00verifying">
      J. S. Shapiro and S. Weber. ``Verifying the EROS Confinement
	Mechanism.'' <doctitle>Proc. 2000 IEEE Symposium on Security and
	Privacy</doctitle>. May 2000. pp. 166&ndash;176. Oakland, CA, USA
    </bibentry>
    <bibentry label="shap04ews">
      J. Shapiro, J. Vanderburgh, E. Northup, and
	D. Chizmadia. ``Design of the EROS Trusted Window System''
	<doctitle>Proc. 13th USENIX Security
	Symposium</doctitle>. 2004
    </bibentry>
    <bibentry label="sag04l4refman">
      &mdash;: L4 <em>eXperimental</em> Kernel Reference Manual. 
      System Architecture Group, Dept. of Computer Science,
      Universit&auml;t Karlsruhe. 2004
    </bibentry>
    <bibentry label="sinha04network">
      A. Sinha, S. Sarat, and J. S. Shapiro. ``Network Subsystems
      Reloaded'' <doctitle>Proc. 2004 USENIX Annual Technical
      Conference</doctitle>. Dec. 2004
    </bibentry>
    <bibentry label="dennis1966semantics">
      J. B. Dennis and E. C. van Horn.
      ``Programming Semantics for Multiprogrammed Computations''
      <doctitle>Communications of the ACM</doctitle>. <b>9</b>(3),
      March 1966.
      pp. 143&ndash;154.
    </bibentry>
    <bibentry label="l3:ipc">
      J. Liedtke. ``Improving IPC by Kernel Design''
      <doctitle>Proc. 14th ACM Symposium on Operating System
      Principles</doctitle>. ACM. pp. 175&ndash;188. 1993
    </bibentry>
    <bibentry label="EROS:IPC">
      J. S. Shapiro, D. J. Farber, and J. M. Smith. ``The Measured
      Performance of a Fast Local IPC'' <doctitle>Proc. 5th
      International Workshop on Object Orientation in Operating
      Systems</doctitle>. Seattle, WA, USA. Nov
      1996. pp. 89&ndash;94. IEEE.
    </bibentry>
    <bibentry label="mach4evolving">
      B. Ford and J. Lepreau. ``Evolving Mach 3.0 to a Migrating
      Threads Model'' <doctitle>Proc. 1994 Winter USENIX
      Conference</doctitle>. Jan 1994. pp. 97&ndash;114.
    </bibentry>
    <bibentry label="thomas90scheduler">
      T. E. Anderson and B. N. Bershad and E. D. Lazowska and
      H. M. Levy.
      ``Scheduler Activations: Effective Kernel Support for the
      User-Level Management of Parallelism'' <doctitle>Proc. 13th ACM
      Symposium on Operating Systems Principles</doctitle>. Pacific
      Grove, CA, USA. pp. 95&ndash;109. 1991.
    </bibentry>
    <bibentry label="marsh91firstclass">
      B. D. Marsh and M. L. Scott and T. J. LeBlank and
      E. P. Markatos,
      ``First-Class User-Level Threads'' <doctitle>Proc 13th ACM
      Symposium on Operating Systems Principles</doctitle>.
      Pacific Grove, CA, USA.
      pp. 110&ndash;121. 1991.
    </bibentry>
    <bibentry label="roscoe1995thesis">
      T. Roscoe.
      <doctitle>The Structure of a Multi-Service Operating
      System</doctitle>.
      Ph.D. Dissertation, University of Cambridge Computer Laboratory
      Technical Report UCAM-CL-TR376. August 1995.
    </bibentry>
    <bibentry label="wulf1974hydra">
      W. A. Wulf, E. S. Cohen, W. M. Corwin, A. K. Jones, R. Levin,
      C. Pierson and Fred J. Pollack. ``HYDRA: The Kernel of a
      Multiprocessor Operating System'' <doctitle>Communications of
      the ACM</doctitle>. <b>17</b>(6), pp. 337&ndash;345. 1974.
    </bibentry>
    <bibentry label="Redell:Thesis">
      D. D. Redell. <doctitle>Naming and Protection in Extensible
      Operating Systems</doctitle>. Ph.D. Dissertation. Department of
      Computer Science, University of California at Berkeley. Nov
      1974.
    </bibentry>
    <bibentry label="KeyKOS:KeySafe">
      S. A. Rajunas. <doctitle>The KeyKOS/KeySAFE System
      Design.</doctitle>
      Key Logic Technical Report SEC009-01. March 1989. Key Logic, Inc.
    </bibentry>
    <bibentry label="kauer2005thesis">
      B. Kauer. <doctitle>L4.sec Implementation &mdash; Kernel Memory
      Management</doctitle> Diploma Thesis, Chair for Operating
      Systems, Technical University of Dresden. Supervisor: Marcus
      Volp. 2005
    </bibentry>
    <bibentry label="mc68851">
      Motorola, Inc. <doctitle>MC68851 Paged Memory Management Unit
	User's Manual</doctitle>.  Prentice Hall, Inc., Englewood
	Cliffs, New Jersey, USA, 1986.
    </bibentry>
    <bibentry label="elf-handling">
      Ulrich Drepper, <doctitle>ELF Handling for Thread-Local
      Storage</doctitle>, Version 0.20. Red Hat Inc., December 21
      2005.
    </bibentry>
  </bibliography>
</book>
