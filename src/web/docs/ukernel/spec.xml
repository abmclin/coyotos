<?xml version="1.0"?>
<!DOCTYPE book PUBLIC "-//EROS Group//DTD OSDoc XML V0.1//EN"
               "http://www.coyotos.org/OSDoc/DTD/osdoc-0.1.dtd" [

<!ENTITY SpecVersion "0.6">
]>
  <book id="ukernel-spec" xmlns:xi="http://www.w3.org/2001/XInclude">
  <docinfo>
<!--     ptsz="12" twocolumn="yes" -->
    <title>Coyotos Microkernel Specification</title>
    <subtitle>Version &SpecVersion;</subtitle>
    <authorgroup>
      <author>
	<firstname>Jonathan</firstname>
	<othername>S.</othername>
	<surname>Shapiro</surname>
	<degree>Ph.D.</degree>
      </author>
      <author>
	<firstname>Jonathan</firstname>
	<othername>W.</othername>
	<surname>Adams</surname>
      </author>
      <affiliation>
	<orgname>The EROS Group, LLC</orgname>
      </affiliation>
    </authorgroup>
    <pubdate>September 10, 2007</pubdate>
    <copyright>
      <year>2007</year> 
      <holder>The EROS Group, LLC</holder>
      <copyterms>
	Verbatim copies of this document may be duplicated or
	distributed in print or electronic form for non-commercial
	purposes.
      </copyterms>
    </copyright>
    <legalnotice>
      <p>
	THIS SPECIFICATION IS PROVIDED ``AS IS'' WITHOUT ANY
	WARRANTIES, INCLUDING ANY WARRANTY OF MERCHANTABILITY,
	NON-INFRINGEMENT, FITNESS FOR ANY PARTICULAR PURPOSE, OR ANY
	WARRANTY OTHERWISE ARISING OF ANY PROPOSAL, SPECIFICATION OR
	SAMPLE.
      </p>
    </legalnotice>
    <categories>
      <category>dev/coyotos</category>
    </categories>
    <synopsis>
      <p>Provisional specification for the Coyotos microkernel.</p>
    </synopsis>
  </docinfo>
  <nocite ref="Redell:Thesis"/>
  <toc/>
  <preface>
    <title>Acknowledgments</title>
    <p>
      Many people have assisted us in evaluating and advancing this
      design:
    </p>
    <blockquote>
      <p>
	Norm Hardy, Charlie Landau, and Bill Frantz of the KeyKOS
	project. Charlie also runs the CapROS project, another
	successor to the EROS system.
      </p>
      <p>
	The members of the <tt>coyotos-dev</tt> mailing list, notably
	Bas Wijnen and Tom Bachmann, Christopher Nelson, Dominique
	Quatravaux, and Pierre Thierry.
      </p>
      <p>
	The members of the L4 community, notably Hermann H&auml;rtig,
	Espen Skoglund, and Kevin Elphinstone.
      </p>
      <p>
	The members of the Systems Research Laboratory at Johns
	Hopkins University, notably Eric Northup, Swaroop Sridhar, and
	M. Scott Doerrie.
      </p>
      <p>
	The external participants in the kernel design review meeting
	of 28-29 March, 2007: Godfrey Vassallo, John Davidsen, Scott
	Doerrie, and Norman Hardy.
      </p>
    </blockquote>
    <p>
      There are surely others that we will come to name as the design
      stabilizes further, and some that we will inadvertently omit. To
      the last, please accept our apologies. As is customary, any flaw
      remaining in this specification is ours.
    </p>
    <p>
      Comments and suggestions concerning this specification are
      welcome. They should be sent to the <tt>coyotos-dev</tt>
      electronic mailing list. In order to send, you must be
      subscribed to the list. The subscription interface may be found
      at:
    </p>
    <blockquote>
      <p>
	<tt>http://www.coyotos.org/mailman/listinfo/coyotos-dev</tt>.
      </p>
    </blockquote>
    <p>
      In order to keep the mail archives readable, we ask that you
      send only ``plain text'' emails.
    </p>
  </preface>
  <preface>
    <title>Preface</title>
    <p>
      Coyotos is a security microkernel. It is a microkernel in the
      sense that it is a minimal protected platform on which a
      complete operating system can be constructed. It is a security
      microkernel in the sense that it is a minimal protected platform
      on which higher level security policies can be constructed.
    </p>
    <sect1>
      <title>The Original Plan</title>
      <p>
	As originally conceived, Coyotos was intended to be a
	relatively minor departure from its predecessor, EROS <cite
	ref="shap2004towards"/>.  EROS <cite
	ref="shap1999fastcapsystem"/> was a small, robust microkernel
	whose central design ideas were pervasive use of capabilities
	<cite ref="dennis1966semantics"/> as the fundamental access
	model, an atomic, blocking capability invocation
	(therefore atomic and blocking IPC) model , and a
	persistent single-level store <cite ref="shap2002store"/>. All
	of these features were inherited with some revision from the
	KeyKOS system. <cite ref="hardy1985keykos"/> Early
	application-level work on EROS, notably the defensible network
	system <cite ref="sinha04network"/> and the secure window
	system <cite ref="shap04ews"/> revealed areas where the EROS
	architecture would clearly benefit from refinement, but did
	not initially suggest fundamental shortcomings in the
	architecture. Coyotos was to have been that minor refinement,
	incorporating a new IPC primitive called ``endpoints'' and a
	revised memory mapping entity called a PATT.  Our main goals were
	cleanup, consistency, and formalization.
      </p>
      <p>
	For algorithmic reasons, the PATT idea did not survive into
	the current specification, and has been replaced by guarded
	page tables <cites> <cite ref="liedtke1995gpt4600"/> <cite
	ref="elphinstone99vm64"/> </cites>. Though they were
	independently invented, guarded page tables may be seen as a
	generalization of the level skipping techniques of the KeyKOS
	translation mechanism or the Motorola MC68851 memory management
	unit <cite ref="mc68851"/>. The variant of guarded page tables
	incorporated here are modified to incorporate the fault
	handler and background space mechanisms of KeyKOS and EROS.
      </p>
      <p>
	In January 2004, a summit meeting of sorts occurred between
	the several research groups working on L4 derivatives and
	Shapiro. The L4 Dresden group, in particular, wanted to get a
	better understanding of capability-based design and kernel
	mechanisms, with the intent that these would be adapted into
	the L4 architecture <cite ref="sag04l4refman"/>. The new
	kernel architecture would come to be known as
	``L4.sec''. There was some discussion of merging the two
	kernels, but no agreement could be reached on the future of
	L4's <tt>map</tt> and <tt>unmap</tt> operation. While the
	failure to merge the architectures was a disappointment, the
	idea that there would be a controlled experiment that would
	allow us to directly evaluate the <tt>map/unmap</tt> approach
	against the EROS <tt>node</tt> approach was a promising result
	in its own right.
      </p>
    </sect1>
    <sect1>
      <title>Overrun by the Hurd</title>
      <p>
	Events intervened in the form of Neal Walfield and Marcus
	Brinkmann, the current architects of the GNU Hurd system.  The
	Hurd is a protected, object-based operating system that was
	initially constructed on top of the Mach microkernel.  Mach
	has a variety of problems that have been thoroughly documented
	in the research literature. Of particular importance to Hurd
	are a lack of resource accounting mechanisms and poor
	performance. As a result of these issues, the Hurd project had
	provisionally decided to move to L4.
      </p>
      <p>
	Unfortunately, modeling copyable, protected object references
	using L4's <tt>map/grant</tt> operations proved unexpectedly
	challenging. This left the Hurd project temporarily disrupted,
	leading Brinkmann and Walfield to seek more information about
	capability-based design.  An extended discussion between
	Shapiro, Walfield, and Brinkmann at the <doctitle>2005 Libre
	Software Meeting</doctitle> about capability systems in
	general and the plans for Coyotos ensued. As more information
	about the L4.sec design emerged <cite ref="kauer2005thesis"/>,
	it became clear that copyable protected references might be
	problematic on the L4.sec interface as well. Walfield and
	Brinkmann traveled to Baltimore for a month-long set of
	design discussions in January 2006, leading to the current
	design for Coyotos.
      </p>
      <p>
	In response to those discussions, we flirted for a while with
	introducing scheduler activations and a new IPC model. It
	didn't pan out. Initially, we thought that activations might
	be lighter weight than synchronous IPC. They aren't, and they
	introduce a lot of complexity in the exception handling
	model. Through editing errors, you may still find traces of
	that effort remaining in this document. If so, they are
	errors, and we would appreciate it if you might bring them to
	our attention.
      </p>
    </sect1>
    <sect1>
      <title>Coyotos Today</title>
      <p>
	The version of Coyotos described here has come full circle,
	and returns to the basic model of the EROS system. The primary
	differences are the introduction of endpoints, a first-class
	process object, and GPTs. It also reflects the January 2006
	discussions between Walfield, Brinkmann, and Shapiro. As a
	result of those discussions, the architecture has been
	challenged a bit harder than it had been.
	Coyotos retains the atomicity and pure capability-based design
	of the EROS system.
      </p>
      <p align="right">
	Jonathan S. Shapiro, Ph.D.<br/>
	The EROS Group, LLC<br/>
	August, 2007
      </p>
    </sect1>
    <!-- <sect1> -->
<!--       <title>A Word on Terminology</title> -->
<!--       <p> -->
<!-- 	Coyotos is based on -->
<!-- 	<term>scheduler activations</term>, a mechanism whose effect -->
<!-- 	is to make user-level threads ``first class.'' Scheduler -->
<!-- 	activations permit a user-level thread scheduler to operate in -->
<!-- 	cooperation with the kernel-level scheduler. This creates a -->
<!-- 	significant confusion when speaking about process dispatch -->
<!-- 	because two levels of dispatch now must occur: the kernel must -->
<!-- 	dispatch the process, and the process's activation handler -->
<!-- 	must dispatch some user-level thread. When a process re-enters -->
<!-- 	the kernel, the kernel must be aware of the current -->
<!-- 	process-level execution mode in order to save the process -->
<!-- 	registers in a way that can later be used by the user-level -->
<!-- 	activation handler. We can no longer speak simply about a -->
<!-- 	process that is running or ready or idle. We must -->
<!-- 	simultaneously speak about whether it is ``activated'' or -->
<!-- 	normal. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	There is also some confusion about the term -->
<!-- 	<term>event</term>. It is common practice in some kernel -->
<!-- 	literature to refer to events in the sense of ``kernel events -->
<!-- 	of interest'' &mdash; things that an application may block -->
<!-- 	for. In a scheduler activation design, the application instead -->
<!-- 	enqueues an ``event wait'' structure (in Coyotos: the SMB) to -->
<!-- 	wait for operation completion and continues execution. There -->
<!-- 	is no process state corresponding to the traditional -->
<!-- 	``blocked'' state. When the operation of interest completes, -->
<!-- 	the enqueued event wait structure is delivered back to the -->
<!-- 	application. -->
<!-- 	in the form of an -->
<!-- 	<term>activation</term>. Activations are preemptive, and cause -->
<!-- 	the receiving application to transition into its activation -->
<!-- 	handler in order to process the event and optionally make a -->
<!-- 	user-level thread switch. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	Scheduler activation designs also use events for something -->
<!-- 	that we normally don't <em>think</em> of as un-blocking: the -->
<!-- 	scheduling mechanism.  In a conventional system, a -->
<!-- 	<em>ready</em> process is actually a <em>blocked</em> process -->
<!-- 	that is waiting for the CPU resource; this is just like any -->
<!-- 	other type of resource blocking. In scheduler activation -->
<!-- 	designs, this insight is made explicit: the transition from -->
<!-- 	<em>ready</em> to <em>running</em> is signalled by an event. -->
<!--       </p> -->
<!--       <p align="right"> -->
<!-- 	Jonathan S. Shapiro, Ph.D.<br/> -->
<!-- 	Department of Computer Science<br/> -->
<!-- 	Johns Hopkins University<br/> -->
<!-- 	January, 2006 -->
<!--       </p> -->
<!--     </sect1> -->
  </preface>
  <chapter>
    <title>Overview</title>
    <p>
      This document describes the abstractions, objects, and interface
      specifications (capability types) implemented by the Coyotos
      microkernel. At some points it includes discussion of the
      intended model of usage by way of motivating or explaining what
      has been incorporated. Such discussions are non-normative.
    </p>
    <p>
      All kernel-implemented objects are named and manipulated by
      means of capabilities, which grant varying degrees of authority
      according to the capability type.  Developers can extend the
      system with new objects by deploying processes that implement
      the associated interfaces. Several such application-implemented
      objects are part of the core Coyotos system.
    </p>
    <sect1>
      <title>Microkernel Objects</title>
      <p>
	The Coyotos kernel provides processes, GPTs (mapping
	structures), schedules, receive queues, pages, and a
	small number of other kernel objects.
      </p>
      <p>
	<leadin>Processes</leadin> Processes are the unit of
	execution, scheduling, and resource binding. A process names
	its address space, its schedule (which governs their execution
	timing) and their fault handler (which receives notice of
	exceptions).
      </p>
      <p>
	<leadin>Schedules</leadin> Schedules are an abstraction of
	computational resources. In order to execute instructions, a
	process must name (via a capability) the schedule under which
	it runs. The schedule, in turn, must convey authority to use
	one or more processors under a defined scheduling contract.
      </p>
      <p>
	<leadin>GPTs</leadin> GPTs are the unit of address mapping
	composition. An address mapping is defined as a mapping from
	addresses to capability slots, and is represented by a
	directed (potentially cyclic) graph of GPTs whose leaf
	capability slots name atomic storage units (pages or
	capability pages). A virtual address is divided into a
	<term>virtual page address</term> and a <term>page
	offset</term>.  Valid virtual page addresses describe paths to
	leaf slots that contain data page or capability page
	capabilities.
      </p>
<!--       <p> -->
<!-- 	<leadin>First-class receive buffers (FCRBs)</leadin> FCRBs -->
<!-- 	capture all of the information necessary for a process to -->
<!-- 	receive an incoming message. The Coyotos messaging aspect -->
<!-- 	bears some resemblance to the first-class messages of HYDRA -->
<!-- 	<cite ref="wulf1974hydra"/>. In certain cases, FCRBs can be -->
<!-- 	used to provide a guaranteed non-blocking, single-delivery -->
<!-- 	notification to the receiving process. This resolves several -->
<!-- 	of the control flow denial of service difficulties that are -->
<!-- 	present in EROS and other systems based on unbuffered, -->
<!-- 	blocking communication systems <cite -->
<!-- 	ref="shap2003vulnerabilities"/>. -->
<!--       </p> -->
      <p>
	<leadin>Endpoints</leadin> An endpoint is a named rendezvous
	point between a message sender and a message receiver. Each
	endpoint carries a receiver-interpreted endpoint
	identifier. In addition, each endpoint provides means for
	ensuring that its capabilities can be used exactly once.
      </p>
      <p>
	<leadin>Receive Queues</leadin> Receive queues provide a means
	for several processes to receive from a single endpoint. The
	receive queue acts as a rendezvous point for the receiving
	processes.  When a message is sent via the endpoint, the
	kernel will select a waiting process from the receive queue
	and deliver the message to that receiver. This permits kernel
	demultiplexing of receive processes, which enhances
	performance on multiprocessors.
      </p>
      <p>
	Receive queues remain an experimental idea, and are not
	implemented by the current kernel.
      </p>
      <p>
	<leadin>Pages</leadin> Pages are the atomic unit of data and
	capability storage allocation. An address space consists of a
	lattice of GPTs whose leaves are pages. Pages are typed: a
	page may contain either data or capabilities, but not
	both. The size of a page is determined by the underlying
	hardware architecture.
      </p>
      <p>
	There are a small number of other kernel-implemented
	capabilities. These primarily provide protected transformation
	operations on capabilities.
      </p>
    </sect1>
    <sect1>
      <title>Entry Capabilities and Extensibility</title>
      <p>
	Endpoint objects have ``entry capabilities''. An entry
	capability does not implement operations on the
	endpoint. Instead, it provides the means by which an
	application introduces new services. Any invocation of an
	entry capability is delivered to the providing object server.
      </p>
    </sect1>
    <sect1 id="persistence">
      <title>Checkpointing and Persistence</title>
      <p>
	Coyotos is a persistent object system. Main memory is treated
	as a <em>cache</em> of a larger backing store. Objects are
	loaded from backing store on demand and are rewritten to the
	backing store as a consequence of age or checkpoint. Following
	a system restart, persistent objects retain their state as of
	the last checkpoint. A checkpoint saves a ``consistent cut''
	of the system. In consequence, processes are recovered in such
	a way that ongoing communications on the local machine may be
	resumed without recovery effort.
      </p>
      <p>
	<leadin>Secure Restart</leadin> On restart, any connection to
	the outside world is <em>severed</em> if continued
	communication on that connection might (conservatively)
	require re-authentication. In particular, network and terminal
	connections are terminated.
      </p>
      <p>
	<leadin>Lost Objects</leadin> One risk in this class of design
	is that objects may be permanently lost as a consequence of
	low-level storage failures (e.g. sector errors). When backing
	store is not already duplexed, the Coyotos object store
	implementation uses software duplexing of critical system
	structures. Applications may also use this mechanism if
	desired.
      </p>
      <p>
	The checkpoint management interfaces used in a driverless kernel are
	still being refined, and are not yet included in this
	specification.
      </p>
    </sect1>
    <sect1>
      <title>Process States and Exceptions</title>
      <p>
	From the kernel perspective, a process has five run states:
	<term>blocked</term>, <term>faulted</term>,
	<term>receiving</term>, <term>ready</term>, and
	<term>running</term>.  A blocked process is waiting for a
	kernel resource. A ready process is attempting to execute
	instructions and is waiting for a CPU. A running process is
	currently executing. A faulted process is not attempting to
	initiate instructions.
      </p>
      <p>
	When a process incurs an exception, the Coyotos kernel
	synthesizes a message on behalf of the faulted process to a
	fault handler. It is the responsibility of the fault handler
	to decide what to do. The kernel does not define a fault
	handling policy.
      </p>
    </sect1>
    <sect1>
      <title>Messages</title>
      <p>
<!-- 	Coyotos provides two types of messages: idempotent and -->
<!-- 	stateful.  -->
	From the sender perspective, message transmission is
	(nearly) atomic. From the receiver perspective, message
	transfer occurs asynchronously. Arrival is signalled by a
	message completion event delivered to the receiver's
	activation handler.
      </p>
      <p>
	<leadin>Relaxed Data Atomicity</leadin> Coyotos permits
	relaxed data atomicity for stateful messages. While a stateful
	receive is pending, the data bytes of the receive area are
	considered undefined and may be modified by the kernel to
	arbitrary values. When receipt has completed, the receive area
	is defined up to the kernel-provided length of the received
	message. The relaxed atomicity rule allows the kernel message
	send implementation to avoid a pre-probe pass on the received
	data area, which significantly improves performance. Note that
	the "undefined" rule explicitly does <em>not</em> apply to
	received capabilities. The complete set of capabilities (if
	any) transferred by a message are required to be transferred
	to receiver-controlled storage atomically. This requirement
	ensures that the inductive state transition requirements of
	the formal capability protection model are satisfied.
      </p>
<!--       <p> -->
<!-- 	<leadin>Idempotent Messages</leadin> An idempotent message is -->
<!-- 	one whose content is set by the receiver (in the FCRB). The -->
<!-- 	information conveyed by the arrival of an idempotent message -->
<!-- 	is the fact that it has been transmitted (fired) one or more -->
<!-- 	times by one or more senders since it was last received. If -->
<!-- 	the receiver is currently executing an activation from a -->
<!-- 	previous transmission of the same idempotent message at the -->
<!-- 	time of a subsequent send, the idempotent message will be -->
<!-- 	delivered again. Sends on idempotent message FCRBs do not -->
<!-- 	block. -->
<!--       </p> -->
<!--       <p> -->
<!-- 	<leadin>Stateful messages</leadin> A stateful message is one -->
<!-- 	where the sender defines the message payload and the receiver -->
<!-- 	specifies (via a stateful FCRB) the location(s) in the -->
<!-- 	receiver address space where the payload should be -->
<!-- 	delivered. A stateful receive FCRB may be either -->
<!-- 	<em>pending</em> or <em>delivered</em>. A send operation on a -->
<!-- 	stateful FCRB will not make progress until that FCRB becomes -->
<!-- 	pending. On completion, it causes the FCRB state to transition -->
<!-- 	from pending to delivered. The receiver must explicitly reset -->
<!-- 	the FCRB state before subsequent attempts to send on that FCRB -->
<!-- 	will make progress. This ensures that the received message -->
<!-- 	payload cannot be overwritten by successive senders before -->
<!-- 	processing. -->
<!--       </p> -->
      <p>
	<leadin>Blocking Send</leadin> A blocking send guarantees
	eventual delivery provided the operation completes and the
	receiver is not destroyed before delivery. Page faults at the
	receiver's designated receive location(s) will be delivered to
	the receiver-designated fault handlers as required. When fault
	handling has completed, the sender will retry the send
	operation from the beginning.<footnote><p>The need to retry
	from the beginning is onerous, and the specification will
	eventually be refined to allow optimization in this
	case.</p></footnote>  Senders may implement watchdog
	timeouts on send operations by arranging to post exceptions to
	themselves after a timed delay.
      </p>
      <p>
	<leadin>Non-blocking Send</leadin> A non-blocking send will be
	silently discarded if any condition arises that would cause a
	blocking send to block.  It will be truncated if a receiver
	page fault occurs during transmission. If truncation occurs,
	the receiver is notified of the partial delivery.
      </p>
    </sect1>
    <sect1>
      <title>Naming and Invocation</title>
      <p>
	Coyotos objects are named by capabilities. A capability is a
	kernel-protected value that names a resource and identifies
	some interface (equivalently: facet or object) of that
	resource. The interface in turn defines methods that the
	invoker can invoke by sending a message specifying the
	corresponding method code point. Thus, every invocation
	consists of a message send to a particular method of a
	particular interface of a particular resource, performed by
	invoking a capability. This is true both for
	server-implemented interfaces and kernel-implemented
	interfaces.
      </p>
      <p>
	The Coyotos invocation mechanism is derived in part from the
	EROS design. The invocation payload has been enriched, but the
	invocation state model has been simplified. An invocation
	consists of a send phase followed by an optional asynchronous
	receive phase. The send phase may specify blocking or
	non-blocking behavior. If a non-blocking send is unable to
	make immediate progress, its message payload is truncated or
	dropped. The receive phase, if present, blocks until an
	incoming message arrives, and can optionally require that the
	incoming message arrive on a particular endpoint identifier.
      </p>
      <p>
	The Coyotos kernel implements only one major system call:
	<progident>InvokeCap</progident>.  A small number of
	additional system calls exist to implement pseudo-instructions
	such as capability load and store.
      </p>
      <p>
	Entry capabilities contain a 32-bit protected payload
	field. The endpoints that they name contain a 64-bit endpoint
	identifier. Both values are delivered to the recipient as part
	of an incoming message. Neither is readable or modifiable by
	the capability's invoker. Servers may use these values to
	distinguish interfaces, object identities, permissions, or
	other desired characteristic.
      </p>
    </sect1>
    <sect1>
      <title>Exception and Interrupt Handling</title>
      <p>
	For reasons of performance, the Coyotos kernel handles
	scheduling-related interrupts directly. It does not specify
	or implement a policy for other interrupt handling. The kernel
	maintains a capability-named interface for interrupt handler
	registry. With the exception of low-level scheduling
	preemption, all policy and processing associated with
	interrupts is handled by application-level code.
      </p>
      <p>
	The Coyotos kernel also pushes responsibility for exception
	handling policy to application level. When runtime application
	exceptions occur, the kernel delivers the state associated
	with the exception to an external fault handler
	designated by an endpoint.
      </p>
    </sect1>
    <sect1>
      <title>Protection Model</title>
      <p>
	An essential part of the security microkernel concept is that
	security policy &mdash; including mandatory security policy
	&mdash; should be implemented by application code. The code
	that enforces system-wide policy needs to be protected and
	must not be evaded, but it does not necessarily need to run in
	supervisor mode.
      </p>
      <p>
	In keeping with this philosophy, the Coyotos kernel does not
	implement a security policy. Coyotos provides primitive
	protection support in the form of protected
	capabilities. Applications can invoke services only by
	invoking capabilities. Capabilities are kernel protected, and
	can be obtained only by transfer over capability-authorized
	channels. It has been shown formally that this restriction is
	sufficient to support (overt) confinement of subsystems <cite
	ref="shap00verifying"/>, and that given overt confinement, a
	higher-level security policy can be implemented either by
	construction or by an application-level reference monitor
	<cite ref="KeyKOS:KeySafe"/>.
      </p>
      <p>
	A useful property of capability systems is that they directly
	express the ``relies-on'' relationships between components. If
	an object or subsystem <em>A</em> depends directly on a second
	object or subsystm <em>B</em> for its operation, then
	<em>A</em> necessarily holds a capability to <em>B</em>. In
	the absence of such a capability, <em>A</em> cannot invoke
	<em>B</em> at all (or even know if the existence of
	<em>B</em>). A key point here is that <em>A</em> may rely on
	<em>B</em> only in a qualified way, and (in some cases) may be
	able to take measures to guard against failures or hostility
	from <em>B</em>. This allows applications to take direct
	responsibility for their dependencies, and also to impose
	context-sensitive access restrictions on their providers.
      </p>
      <p>
	For this reason, we try to avoid the term ``trust'' in our
	designs, preferring instead to use ``relies on.''
      </p>
    </sect1>
  </chapter>
  <part>
    <title>Microkernel Abstractions</title>
    <chapter id="Capabilities">
      <title>Capabilities</title>
      <p>
	The Coyotos kernel implements a number of object types, each
	of which has a corresponding capability type:
      </p>
      <table latex.center="yes" id="cap_types" latex.colspec="llp{3.4in}l">
	<thead>
	  <tr>
	    <td><b>Encoding</b></td>
	    <td><b>Type</b></td>
	    <td><b>Description</b></td>
	    <td><b>Restrictions</b></td>
	  </tr>
	</thead>
	<tbody>
	  <tr>
	    <td>0</td>
	    <td>Null</td>
	    <td>
	      <p>
		Universal, invalid capability.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>1</td>
	    <td>Window</td>
	    <td>
	      <p>
		A local mapping window (Chapter&nbsp;<xref
		ref="AddressSpaces"/>).
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>2</td>
	    <td>Background</td>
	    <td>
	      <p>
		A background mapping window (Chapter&nbsp;<xref
		ref="AddressSpaces"/>).
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>3</td>
	    <td>KeyBits</td>
	    <td>
	      <p>
		Discloses the bit representation of
		capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>4</td>
	    <td>Discrim</td>
	    <td>
	      <p>
		Classifies capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>5</td>
	    <td>Range</td>
	    <td>
	      <p>
		Fabricates object capabilities.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>6</td>
	    <td>Sleep</td>
	    <td>
	      <p>
		Interface to the kernel interval timer.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>7</td>
	    <td>IRQ Control</td>
	    <td>
	      <p>
		Interrupt request line control interface.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>8</td>
	    <td>Schedule Control</td>
	    <td>
	      <p>
		Interface to the kernel master scheduling
		table.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>9</td>
	    <td>Checkpoint</td>
	    <td>
	      <p>
		Control capability for the kernel
		checkpoint mechanism.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>10</td>
	    <td>ObStore</td>
	    <td>
	      <p>
		Interface between kernel and object store
		manager.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>11</td>
	    <td>Pin Control</td>
	    <td>
	      <p>
		Permission to pin objects in memory.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>12</td>
	    <td>Schedule</td>
	    <td>
	      <p>
		Permission to execute under a particular schedule.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>13</td>
	    <td>SysCtl</td>
	    <td>
	      <p>
		Start, stop system, enter sleep states.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>14</td>
	    <td>KernLog</td>
	    <td>
	      <p>
		Append text to kernel log.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>15</td>
	    <td>IOPriv</td>
	    <td>
	      <p>
		Authority to read/write IO ports.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>16</td>
	    <td>IrqWait</td>
	    <td>
	      <p>
		Authority to wait for an arriving interrupt.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td><em>17-31</em></td>
	    <td><em>Reserved</em></td>
	    <td>
	      <p>
		<em>Encodings reserved for future use.</em>
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>32</td>
	    <td>Endpoint</td>
	    <td>
	      <p>
		Control capability for an endpoint.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>33</td>
	    <td>Page</td>
	    <td>
	      <p>
		Data page. The size of a page is determined by the
		underlying hardware page size.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>34</td>
	    <td>CapPage</td>
	    <td>
	      <p>
		Capability page. The size of a capability page is
		determined by the page size of the underlying
		hardware page size.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK
	    </td>
	  </tr>
	  <tr>
	    <td>35</td>
	    <td>GPT</td>
	    <td>
	      <p>
		Guarded Page Table. Used to compose
		larger address spaces from pages.
	      </p>
	    </td>
	    <td>
	      RO,NX,WK,OP
	    </td>
	  </tr>
	  <tr>
	    <td>36</td>
	    <td>Process</td>
	    <td>
	      <p>
		Capability that manipulates the kernel process
		abstraction.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>37</td>
	    <td>AppNotice</td>
	    <td>
	      <p>
		Capability that permits posting of non-blocking,
		application-defined software notices.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td><em>38-62</em></td>
	    <td><em>Reserved</em></td>
	    <td>
	      <p>
		<em>Encodings reserved for future use.</em>
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>63</td>
	    <td>Entry</td>
	    <td>
	      <p>
		Authority to send to the process designated by an Endpoint.
	      </p>
	    </td>
	  </tr>
	</tbody>
      </table>
      <p>
	The <term>RO</term>, <term>NX</term>, <term>WK</term>, and 
	<term>OP</term> restrictions respectively indicate, read-only,
	non-executable, weak, and opaque permission restrictions. These
	are described in detail in the chapter on address spaces.
      </p>
      <sect1 id="caprep">
	<title>Representation</title>
	<p>
	  A capability is 16 bytes, and uses the same representation
	  on both 32-bit and 64-bit platforms.  The capability
	  structure is a ``tagged union'' whose details depend on the
	  capability type field. The kernel is entitled to use
	  optimized representations internally. The representation
	  given below is the representation disclosed by KeyBits,
	  which is the representation typically used on disk.
	</p>
	<p>
	  Except where otherwise indicated, reserved fields must be
	  zero-filled. The <term>P</term> (prepared) bit and the
	  <term>hz</term> (hazard) bit are kernel internal, and are
	  always zeroed by <progident>keybits</progident> when the
	  capability representation is returned.
	</p>
	<sect2 id="memcaps">
	  <title>Capabilities to Memory Objects</title>
	  <p>
	    Memory capabilities include page, cappage, GPT, local
	    window capabilities, and background window
	    capabilities. All of these are used to describe portions
	    of the address space.  The format of page, cappage, and
	    GPT capabilities is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-mem" width="75" srctype="sbox"/>
	    <caption>Memory object capability</caption>
	  </figure>
	  <p>
	    The format of a window capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-window" width="75" srctype="sbox"/>
	    <caption>Mapping window capability</caption>
	  </figure>
	  <p indent="no">
	    The <em>rootSlot</em> field of the window capability is used
	    only for local window capabilities, this field is reserved
	    in background window capabilities.
	  </p>
	  <p indent="no">
	    <leadin>Invariant:</leadin>
	    <progident>l2g&nbsp;&le;&nbsp;64</progident><br/>
	    <leadin>Invariant:</leadin>
	    <progident>(l2g&nbsp;==&nbsp;64)&nbsp;&rArr;&nbsp;(guard&nbsp;==&nbsp;0)</progident><footnote>
	      <p>This invariant
		ensures that no bounds check is required before
		performing C shift operations whose size equals the
		machine word size. On most architectures such shift
		operations truncate the shift amount, but if the value
		being shifted is zero any shift (including none at all)
		will produce the right answer during address space
		traversal.</p>
	    </footnote><br/> 
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(C&nbsp;==&nbsp;1)&nbsp;&rArr;&nbsp;(l2g&nbsp;-&nbsp;l2v)&nbsp;&les;&nbsp;3</progident><br/> -->
	    <leadin>Invariant:</leadin>
	    <progident>((guard&nbsp;&lt;&lt;&nbsp;l2g)&nbsp;&gt;&gt;&nbsp;l2g)&nbsp;==&nbsp;guard</progident><footnote>
	      <p>This invariant ensures that any bits of the guard
		value that would appear (after the normalizing shift)
	    above the highest valid bit position in an address must be
	    zero.</p>
	    </footnote><br/>
	    <leadin>Invariant:</leadin>
	    <progident>l2g&nbsp;&ge;&nbsp;log2(<em>page&nbsp;size</em>)</progident><br/>
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>l2g&nbsp;&ge;&nbsp;l2v</progident><br/> -->
	    <leadin>Invariant:</leadin>
	    <progident>(offset&nbsp;mod&nbsp;2<sup>l2g</sup>)&nbsp;==&nbsp;0</progident><br/>
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(l2g&nbsp;-&nbsp;l2v)&nbsp;&les;&nbsp;4</progident><br/> -->
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(type&nbsp;==&nbsp;Page)&nbsp;&rArr;&nbsp;(l2g&nbsp;==&nbsp;l2v)</progident><br/> -->
<!-- 	    <leadin>Invariant:</leadin> -->
<!-- 	    <progident>(type&nbsp;==&nbsp;CapPage)&nbsp;&rArr;&nbsp;(l2g&nbsp;==&nbsp;l2v)</progident> -->
	  </p>
	  <p indent="no">
	    These invariants are ensured by the operations that
	    fabricate the respective capabilities. The balance of the
	    system is entitled to assume that they hold.
	  </p>
	  <p>
	    When traversing a memory capability, the virtual address
	    <progident>va</progident> is defined as the bitwise
	    concatenation of three fields
	    <progident>g+u+v</progident>, where
	    <progident>g</progident> is a variable length,
	    possibly empty bit string that will be used as a guard
	    value,
	    <progident>u</progident> is a variable length, possibly
	    empty bit string that will be
	    used to index into the slots of the named GPT (if any),
	    and <progident>v</progident> is the virtual address that
	    will remain to be translated at the next step (if any).
	    The length <progident>|v|</progident> is determined by the
	    <progident>l2v</progident> field of the named Page,
	    CapPage, or GPT.
	    The capability field
	    <progident>l2g</progident> contains length of the bit string
	    <progident>|u+v|</progident>. The value of the
	    effective guard is a multiple of
	    <progident>2<sup>l2g</sup></progident>.
	    For page and capability page capabilities, the value
	    <progident>l2g</progident> also specifies the target page
	    size. This is possible because neither
	    pages nor capability pages have slots to be indexed.
	  </p>
	</sect2>
	<sect2 id="msgcaps">
	  <title>Message-Related Capabilities</title>
	  <p>
	    Endpoint capabilities currently do not carry permission
	    bits, but are otherwise similar in layout to memory
	    capabilities. The protected payload field is reserved in
	    the respective control capabilities, and should be zero.
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-message" width="75" srctype="sbox"/>
	    <caption>Endpoint capability</caption>
	  </figure>
	  <p>
	    Invocations of an endpoint capability ignore the protected
	    payload and provide access to the kernel-implemented
	    object. Invocations of an Entry capability are delivered
	    to an implementing process designated by the endpoint. The
	    protected payload field of the endpoint capability is
	    provided as an additional output of the invocation.
	  </p>
	</sect2>
	<sect2 id="processcaps">
	  <title>Capabilities to Processes</title>
	  <p>
	    The format of a process capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-process" width="75" srctype="sbox"/>
	    <caption>Process capability</caption>
	  </figure>
	</sect2>
	<sect2 id="misccaps">
	  <title>Miscellaneous Capabilities</title>
	  <p>
	    The format of a miscellaneous capability is:
	  </p>
	  <figure latex.placement="h">
	    <img source="cap-misc" width="75" srctype="sbox"/>
	    <caption>Miscellaneous capability</caption>
	  </figure>
	</sect2>
      </sect1>
      <sect1 id="cap_validity">
	<title>Valid Capabilities</title>
	<p>
	  Wherever this specification refers to a capability of a
	  specific type, it should be taken to mean a <em>valid</em>
	  capability of the stated type.  The meaning of an invocation
	  of a valid capability is determined by its implementation
	  provider (kernel or server).
	</p>
	<p>
	  A non-object capability is any capability whose external
	  representation does not include an allocation count.  A
	  non-object capability is always valid. Non-object
	  capabilities are not revocable.
	</p>
	<p>
	  All other capabilities are object capabilities. An object
	  capability is valid if and only if all of the following
	  conditions are met:
	</p>
	<ul>
	  <li>
	    <p>
	      There exists some object with a matching object
	      identifier (OID) whose type is compatible with the type
	      of the capability.<footnote>
		<p>
		  This specification intentionally does not take a
		  position on whether OIDs are globally unique or only
		  unique with respect to objects of compatible
		  representation type. This choice is left to the
		  implementation.
		</p>
	      </footnote>
	    </p>
	    <p>
	      This condition may be violated if backing store is lost
	      or corrupted, or through a bug in the object manager.
	    </p>
	  </li>
	  <li>
	    <p>
	      The allocation count in the capability matches the
	      allocation count in the object.
	    </p>
	    <p>
	      This condition ceases to be true when an object is
	      revoked (see <link
	      href="#coyotos.range.rescind"><progident>coyotos.range.rescind</progident></link>).
	    </p>
	  </li>
	  <li>
	    <p>
	      In the case of an endpoint capability whose
	      <progident>PM</progident> bit is set, the protected
	      payload field of the endpoint capability matches the
	      protected payload field of the endpoint object that it
	      names.
	    </p>
	  </li>
	</ul>
	<p>
	  All other object capabilities are invalid.  An invalid
	  capability behaves in all observable respects as if it were
	  the <link href="#coyotos.null">Null capability</link>. This
	  applies both to invocation of an invalid capability and to
	  operations that act on invalid capabilities (notably <link
	  href="#coyotos.keybits">KeyBits</link>, which has
	  implications for debugging invalid capabilities). The kernel
	  is free to overwrite any capability location with a Null
	  capability when it determines that the capability contained
	  in that location is invalid.
	</p>
      </sect1>
      <sect1 id="capability_prepare">
	<title>Capability Prepare</title>
	<p>
	  Coyotos is an object paging system. Both object load and
	  object unload are driven by the use of
	  capabilities. Ignoring latency, this paging behavior is
	  normally invisible to applications. The exception is that
	  object page-in may reveal low-level storage failures that
	  make an object unrecoverable.
	</p>
	<p>
	  Whenever a capability is used, the kernel internally
	  performs a <em>prepare</em> operation on the
	  capability. Conceptually, this prepare step is being done by
	  the process that is performing the current system call. The
	  prepare operation may have several outcomes:
	</p>
	<ul>
	  <li>
	    <p>
	      If the capability is a non-object capability, the
	      prepare operation succeeds (by definition).
	    </p>
	  </li>
	  <li>
	    <p>
	      If the capability names an object, but its
	      <progident>allocCount</progident> does not match the
	      <progident>allocCount</progident> of the corresponding
	      object, the capability is re-written (in place) to the
	      Null capability.
	    </p>
	    <p>
	      The containing object is not marked modified. If
	      other operations cause the containing object to be
	      modified, the Null capability will be written to
	      disk. Otherwise, subsequent reloads of the object
	      will re-obtain the stale capability and this check
	      will be performed again with the same result.
	    </p>
	    <p>
	      Several optimizations and mechanisms are used to ensure
	      that the disk allocation count does not overflow.
	    </p>
	  </li>
	  <li>
	    <p>
	      If the object named by the capability is not in memory,
	      steps are taken to load it. The preparing process is
	      enqueued to wait for the completion of this request, and
	      re-starts its operation when the object has been loaded.
	      In rare cases, this step may result in an
	      <progident>ObjectContentLost</progident> exception if
	      the backing store has experienced an unrecoverable
	      storage error.
	    </p>
	  </li>
	  <li>
	    <p>
	      If the object named by the capability is in memory, it
	      is locked for the duration of the current system call
	      unless they are unlocked explicitly.
	    </p>
	  </li>
	</ul>
	<p>
	  A capability is ``used'' if:
	</p>
	<ul>
	  <li>
	    <p>
	      The capability is invoked by the current system call.
	    </p>
	  </li>
	  <li>
	    <p>
	      The capability designates the invokee of the current
	      system call.
	    </p>
	  </li>
	  <li>
	    <p>
	      Fetching a capability argument or storing a capability
	      result requires memory traversal, in which case all
	      capabilities in the traversed slots are used.
	    </p>
	  </li>
	  <li>
	    <p>
	      The operation requested by the current system call
	      accesses or mutates the target object of the capability.
	    </p>
	  </li>
	</ul>
	<p>
	  Coyotos implementations are required to be atomic. This
	  implies that all resource acquisitions (and therefore all
	  capability prepares) must be acquired before any observable
	  side-effect of a system call occurs.
	</p>
      </sect1>
      <sect1>
	<title>Extensibility</title>
	<p>
	  Coyotos is an extensible object system in the sense of Hydra
	  <cite ref="wulf1974hydra"/>.  New objects may be introduced
	  by designing a process that implements the desired
	  object. Capabilities to these objects are implemented as
	  Entry capabilities. The kernel checks these capabilities
	  for validity, and optionally for a protected payload match
	  (see Chapter&nbsp;<xref ref="invocation"/>), but does not
	  otherwise define semantics for these capabilities.
	</p>
	<p>
	  Because the kernel does not know the semantics of these
	  extensions, entry capabilities are not considered ``safe''
	  by the <link
	  href="#coyotos.discrim.classify"><progident>coyotos.discrim.classify</progident></link>
	  operation.
	</p>
      </sect1>
    </chapter>
    <chapter id="processes">
      <title>Processes</title>
      <p>
	A Coyotos process provides an abstraction of the user-mode
	execution engine presented by the underlying
	microprocessor. From the kernel perspective, a process is the
	unit that is dispatched by the kernel for execution.
      </p>
      <p>
	Coyotos does not distinguish between processes and threads. A
	process encapsulates a single kernel thread of
	execution. Coyotos address spaces are first-class objects. Two
	(or more) processes may be constructed that designate the same
	address space. This achieves concurrent
	execution of multiple kernel threads of control within a
	common addressing environment and resource pool.
      </p>
      <p>
	Coyotos implements the system calls described in
	Chapter&nbsp;<xref ref="syscalls"/>. Most of these should be
	viewed as software-defined instructions. The exception is the
	<progident>InvokeCap</progident> system call, which performs
	capability invocation (see Chapter&nbsp;<xref
	ref="invocation"/>). The majority of the kernel's function is
	provided in the form of kernel-implemented objects
	(equivalently: services) that are named by capabilities. These
	services are invoked in the usual way by invoking their
	capabilities.
      </p>
      <sect1 id="proc_state">
	<title>State of a Process</title>
	<p>
	  The state of a process may be divided conceptually into
	  kernel (privileged or sensitive) state and user
	  (non-privileged) state. <term>User state</term> is that
	  state which a process may modify directly without kernel
	  intervention. This includes architecture-defined
	  non-privileged register state. It also includes additional
	  ``pseudo registers'' defined by Coyotos that support the
	  capability invocation mechanism.
	</p>
	<p>
	  <term>Kernel state</term> is that state which records or
	  discloses protection information, or for which the kernel
	  must guarantee invariants for reasons of security,
	  robustness, or operational consistency. The representation
	  of capabilities, for example, is kernel state. The Coyotos
	  process structure contains space to save both the kernel
	  state and the user state of a process.
	</p>
	<p>
	  On some hardware architectures, the separation between
	  kernel state and user state is not cleanly accomplished by
	  the architecture. The most common examples of this involve
	  design failures in the architected processor status word.
	  The IA-32 <smallcaps>eflags</smallcaps> register, for
	  example, includes state such as the supervisor mode bit and
	  the current ``IO privilege level.'' Such fields present a
	  problem because the balance of the
	  <smallcaps>eflags</smallcaps> register must be modifiable by
	  untrusted code. When an unprivileged application runs normal
	  instructions, the hardware generally protects these bits
	  from modification. On such architectures, Coyotos must
	  ensure that any registers modified by get/set registers and
	  similar operations properly protect these fields. The
	  architecture-specific annex for each architecture identifies
	  any such registers and their update constraints.
	</p>
	<sect2 id="proc_kernel_state">
	  <title>Per-process State</title>
	  <figure id="fig:kpcb" latex.position="htb">
	    <img source="process" width="75" srctype="sbox"/>
	    <caption>Per-Process kernel state</caption>
	  </figure>
	  <p>
	    Each process has the following state:
	  </p>
	  <ul>
	    <li>
	      <p>
		The process run state. This field indicates whether
		the process is running (0), receiving (1), or faulted
		(2).
	      </p>
	    </li>
	    <li>
	      <p>
		The process flags word. This word contains the process
		run state and several bits that control fault-related
		and debugging-related behavior.
	      </p>
	    </li>
	    <li>
	      <p>
		A software-defined notices bitfield,
		<term>notices</term>, indicating (by bit position)
		the software-defined notices that are pending for
		this process.
	      </p>
	    </li>
	    <li>
	      <p>
		32 capability ``registers'' that are implemented in
		software by the Coyotos kernel.
	      </p>
	    </li>
	    <li>
	      <p>
		Capability slots that support process recognition and
		identification: <term>brand</term> and the
		<term>cohort</term>.
	      </p>
	    </li>
	    <li>
	      <p>
		Capability slots that identify resources on which the
		process depends: the address space, the schedule, and
		the external fault handler.
	      </p>
	      <p>
		Coyotos address spaces are
		``first class''. An address space may exist without
		having any associated process. Multiple processes may
		name the same address space by placing the same
		address space capability in their respective address
		space slots. Schedules are similarly ``first class.''
	      </p>
	    </li>
	    <li>
	      <p>
		Slots related to exception handling.
	      </p>
	      <p>
		The <term>faultCode</term>
		and <term>faultInfo</term> are conceptually
		similar to the underlying hardware processor's
		exception registers. A process-incurred exception
		causes these registers to be updated with the
		information necessary for error diagnosis and possible
		resolution. The exception fault code space unifies
		both hardware-defined and kernel-defined exceptions
		into a single code point space.
	      </p>
	      <p>
		The <term>handler</term> capability slot contains an
		entry capability to the external fault handler (if
		any). This is an external process that should be
		notified whenever this process incurs a fault.
	      </p>
	    </li>
	    <li>
	      <p>
		Storage for the architecture-defined non-privileged
		register set. Access to these registers is by means of
		invocations on the architecture-specific process
		capability.
	      </p>
	    </li>
	  </ul>
	  <p>
	    The per-process capability state, fault code, and
	    fault information can be accessed and manipulated only
	    through invocations of the process capability. 
	  </p>
	  <p>
	    The process flags are shown in Figure&nbsp;<xref
	    ref="fig:proc-flags"/>.  The fields have
	    the following meanings:
	  </p>
	  <figure id="fig:proc-flags" latex.position="h">
	    <img source="proc-flags" width="75" srctype="sbox"/>
	    <caption>Process flags word</caption>
	  </figure>
	  <table latex.long="yes" latex.center="yes" latex.colspec="lp{5.5in}">
	    <thead>
	      <tr>
		<td><b>Field</b></td>
		<td><b>Meaning</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td><term>xm</term></td>
		<td>
		  <p>
		    <leadin>Execution Model</leadin> indicates whether
		    this process uses a 32-bit (0) or 64-bit (1)
		    execution model.  This bit is significant mainly
		    on architectures having multiple execution models,
		    such as <progident>amd64</progident>.  It controls
		    certain aspects of cross-model invocations.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>sx</term></td>
		<td>
		  <p>
		    <leadin>Slice Expired</leadin> This bit is set by
		    the kernel when the process's real-time slice has
		    expired. The slice expired event is considered an
		    application-defined interrupt. Use and delivery of
		    the <term>sx</term> notification is discussed in
		    Chapter&nbsp;<xref ref="scheduling"/>.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>sn</term></td>
		<td>
		  <p>
		    <leadin>Soft Notice</leadin>
		    This bit is set by the kernel whenever a
		    new bit is set in the pending
		    application-defined notices field.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>tc</term></td>
		<td>
		  <p>
		    <leadin>Trap On Call</leadin> indicates that the
		    process should incur a ``trap on syscall exception
		    when it attempts to perform a system call. This
		    trap will occur <em>after</em> registers have been
		    saved to the process structure, but
		    <em>before</em> arguments have been examined by
		    the kernel. In particular, the system call number
		    will not yet have been examined by the kernel.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>tr</term></td>
		<td>
		  <p>
		    <leadin>Trap On Return</leadin> indicates that the
		    process should incur a ``trap on system call
		    return exception when it exits or bypasses the
		    receive state following a successful
		    invocation. This trap occurs just <em>after</em>
		    the parameter words (if any) have been copied out
		    to the application.  In consequence, it occurs
		    after any associated exceptions are processed by
		    the recipient.  Control has not been returned to
		    the receiver.
		  </p>
		  <p>
		    If this bit is set at process system call return,
		    a <progident>process.FC_SysCallReturn</progident>
		    fault will be set in the process state just prior
		    to returning.  The
		    <progident>process.resume()</progident> does not
		    cause the invokee to resume in the system call
		    exit path, so this exception will not re-occur on
		    resumption.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>cs</term></td>
		<td>
		  <p>
		    <leadin>Call Step</leadin> if set (1), indicates
		    that the <term>tc</term> bit should be ignored at
		    the next point where it would normally take
		    effect.
		  </p>
		  <p>
		    This bit is set as a side effect of the
		    <progident>process.resume()</progident> operation
		    if the currently pending fault code is
		    <progident>process.FC_SysCallEntry</progident>.
		    It is cleared whenever the process proceeds
		    successfully to the commit point of the current
		    system call.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td><term>pc</term></td>
		<td>
		  <p>
		    <leadin>Parameter Copyout</leadin> This bit is set
		    by the kernel whenever a parameter copyout from
		    the parameter scratchpad area is required before
		    resuming user-mode execution of the current
		    process.
		  </p>
		</td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
      </sect1>
      <sect1 id="proc_exec_model">
	<title>Execution Model</title>
	<p>
	  The instruction set available to a Coyotos process consists
	  of the user mode (non-privileged) instruction set of the
	  underlying processor architecture, the kernel-implemented
	  <progident>InvokeCap</progident> instruction (which
	  is the subject of Chapter&nbsp;<xref ref="invocation"/>).
	</p>
	<p>
	  From the perspective of the kernel, a process exists in one
	  of the following run states:
	</p>
	<deflist>
	  <defli>
	    <label><term>blocked</term></label>
	    <li>
	      <p>
		Process is attempting to send, but is blocked
		availability of a kernel resource. Process has no
		current or pending software interrupts. On release,
		process will resume in the <em>ready</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>receiving</term></label>
	    <li>
	      <p>
		Process is waiting for an incoming message from an
		endpoint, and has no current or pending software
		interrupts. On receipt, process will resume in the
		<em>ready</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>ready</term></label>
	    <li>
	      <p>
		Process is attempting to execute instructions. Process
		may have current or pending software
		interrupts. Pending exceptions will be delivered when
		the process transitions to the <em>running</em> state.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>running</term></label>
	    <li>
	      <p>
		Process is assigned to a CPU and is executing
		instructions.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>faulted</term></label>
	    <li>
	      <p>
		Process has incurred an exception that has been
		reported to the external fault handler designated by
		the process's <progident>handler</progident>
		capability. Process will not executing instructions.
	      </p>
	    </li>
	  </defli>
	</deflist>
	<p>
	  The state transition diagram is shown in Figure&nbsp;<xref
	  ref="fig.transition"/>.
	</p>
	<figure id="fig.transition" latex.placement="bth">
	  <img source="transitions" width="30" srctype="gif"/>
	  <caption>Process state transitions</caption>
	</figure>
	<p>
	  The <em>blocked</em> state is not externally observable. A
	  blocked process has an externally reported
	  <progident>runState</progident> of ``running''. Such a
	  process is deemed to be running without making progress or
	  consuming CPU cycles.  The receiving state it also not
	  externally observable. A receiving process is executing the
	  receive phase of a capability invocation very slowly.
	</p>
	<p>
	  A process that is in the <em>running</em> state will
	  initiate instructions as long as its process
	  <progident>faultCode</progident> field is set to
	  <progident>FC_NoFault</progident> (0). Execution behavior
	  when any other value is stored in the
	  <progident>faultCode</progident> field is discussed in
	  Section&nbsp;<xref ref="ExceptionHandling"/>.
	</p>
      </sect1>
      <sect1 id="ExceptionHandling">
	<title>Exception Handling</title>
	<p>
	  An exception occurs as the result of an instruction executed
	  by the process.  Every exception has an associated fault
	  code. Specific exceptions may define an additional pointer
	  value to be delivered as additional fault information. The
	  fault code and fault information are delivered to the
	  process by storing them in the
	  <progident>faultCode</progident> and
	  <progident>faultInfo</progident> fields of the Process and
	  causing the process to resume execution.
	</p>
	<sect2 id="ExceptionDelivery">
	  <title>Exception Delivery</title>
	  <p>
	    When a process attempts to initiate instructions with a
	    <progident>faultCode</progident> other than
	    <progident>FC_NoFault</progident>, the behavior is as
	    follows:
	  </p>
	  <ol>
	    <li>
	      <p>
		If an Entry capability is stored in the
		process's <progident>handler</progident> slot, the
		kernel synthesizes a message to this endpoint on
		behalf of the faulting process. The message will
		provide the <progident>faultCode</progident> and
		<progident>faultInfo</progident> values and a
		process capability to the faulted
		process. Disposition of the faulted process is now
		at the discretion of the fault handler.
	      </p>
	      <p>
		If the handler process is blocked, handler message
		delivery will be re-attempted when the external
		handler process becomes unblocked.
	      </p>
	    </li>
	    <li>
	      <p>
		The process enters the <em>faulted</em> state
		(runState = stopped) and ceases to execute
		instructions.
	      </p>
	    </li>
	  </ol>
	  <p>
	    In the absence of a specified external handler, a
	    process attempting to deliver a fault notification to its
	    external handler will effectively cease to execute
	    instructions without notice to anyone. It is the
	    responsibility of the programmer to ensure that an
	    external handler capability is defined if noticing
	    this condition is required.
	  </p>
	  <p>
	    Note that the state of the per-process
	    <progident>handler</progident> slot is checked on each
	    delivery attempt. If a process blocks attempting to
	    deliver its fault information to an external fault
	    handler, and the <progident>handler</progident> slot is
	    modified before the external handler becomes unblocked,
	    the fault may end up being delivered to a different
	    handler or to no handler at all depending on the new value
	    of the <progident>handler</progident> slot.
	  </p>
	</sect2>
	<sect2>
	  <title>Return From Out-of-Process Handler</title>
	  <p>
	    If an exception has been delivered to a handler, the
	    handler must take action to clear the fault. It does this
	    by invoking the process capability provided by the kernel
	    upcall to clear the fault and return the process to the
	    running state.
	  </p>
	</sect2>
      </sect1>
      <sect1>
	<title>Application-Defined Notifications</title>
	<p>
	  Coyotos supports application-defined non-blocking
	  notifications via the <link
	  href="#coyotos.AppNotice"><progident>AppNotice</progident></link>
	  capability type. A notification is posted by invoking the
	  <progident>AppNotice</progident> capability with 32-bit mask
	  indicating the notifications (in the range 0..31) to be
	  posted.  The set of authorized notifications is determined
	  at the time the <progident>AppNotice</progident> capability
	  is fabricated. The effect of posting a set of
	  application-defined notices is to set the corresponding bits
	  of the target process <progident>softNotices</progident>
	  word, and to set the <progident>sn</progident> bit of the
	  target process flags if the value of
	  <progident>notices</progident> has changed as a
	  consequence of this posting (i.e. if the notice was not
	  already pending). Of the set of notices posted, only the
	  authorized subset is delivered.
	</p>
	<p>
	  If any notices are pending when the recipient enters an open
	  wait, they will be delivered as a message, with a specified
	  endpoint ID of <tt>~0ull</tt> and a protected payload value
	  of zero. Delivery of pending notices has higher priority
	  than other incoming messages.
	</p>
	<p>
	  Delivery of application-defined notices is suppressed during
	  a closed wait.
	</p>
      </sect1>
    </chapter>
    <chapter id="AddressSpaces">
      <title>Address Spaces</title>
      <p>
	The Coyotos architecture defines 64-bit address spaces for
	both 32-bit and 64-bit machines. On 32-bit machines, the
	leading 2<sup>32</sup> byte positions are addressable by
	hardware load and store instructions.  That is, the
	hardware-accessible map is a <em>window</em> onto the leading
	subrange of the software-defined space.
      </p>
      <p>
	On some architectures, a portion of the hardware-addressable
	space may be reserved for use by the kernel. On such machines,
	the hardware-accessible address space is overlaid by the
	kernel-defined region.
      </p>
      <sect1 id="memobs">
	<title>Memory Objects and Address Interpretation</title>
	<p>
	  Three objects are used to define Coyotos address spaces:
	  pages, cappages, and GPTs. Capabilities to these objects may
	  be invoked in the usual way. The interface definitions for
	  these objects are provided in Part II.
	</p>
	<p>
	  The meaning of a data (capability) address reference is
	  determined by starting at the data (capability) address
	  space capability of the referencing process and traversing
	  memory objects until the address has been successfully
	  translated or an exception has occurred. The traversal
	  process is similar to the traversal of hardware-based
	  hierarchical translation tables, but there are several
	  differences:
	</p>
	<ul>
	  <li>
	    <p>
	      The Coyotos mapping structures provide support for
	      per-region fault handlers. Any region of size
	      2<sup><em>k</em></sup> pages may have an associated
	      fault handler. When a memory fault is reported to the
	      in-process fault handler, the in-process handler may
	      optionally forward memory fault messages to the
	      per-region handler in order to request region-specific
	      fault handling.
	    </p>
	  </li>
	  <li>
	    <p>
	      The ``levels'' of the mapping hierarchy are dynamically
	      determined. Smaller subspaces may appear where a larger
	      space is expected, with the effect that the ``missing''
	      regions are considered invalid addresses. Larger
	      subspaces may appear where a smaller space would
	      naturally appear, with the effect that only the leading
	      subrange of the larger subspace is addressable through
	      this mapping.
	    </p>
	  </li>
	  <li>
	    <p>
	      A mechanism is provided for mapping ``windows'' onto
	      other address spaces by reference. This enables one
	      address space to map (portions of) another even when the
	      second space is opaque.
	    </p>
	  </li>
	  <li>
	    <p>
	      In order to support certain essential types of
	      addressing flexibility &mdash; notably windows &mdash;
	      it is necessary to allow some unusual arrangements of
	      the hierarchical structures. An unfortunate consequence
	      of this is that it is possible for a hostile or
	      erroneous program to create statically cyclic address
	      spaces. Such spaces are <term>malformed</term>, and
	      attempts to reference a cyclically defined address
	      generate a <progident>MalformedSpace</progident>
	      exception.
	    </p>
	  </li>
	</ul>
	<sect2>
	  <title>Permissions</title>
	  <p>
	    All memory object capabilities carry a four-bit field, "restr",
	    which specify restrictions on which types of access may legally be
	    performed:
	  </p>
	  <deflist>
	    <defli>
	      <label><term>RO</term></label>
	      <li>
		<p>
		  <leadin>Read Only (0x1)</leadin> Attempts to perform write
		  references  along any address translation path that
		  traverses this capability are prohibited.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>NX</term></label>
	      <li>
		<p>
		  <leadin>No Execute (0x2)</leadin> Instruction fetch
		  references along any address translation path that
		  traverses this capability are prohibited. Attempts to
		  perform instruction fetches at such addresses generate
		  an <progident>NoExecute</progident> exception.
		</p>
		<note>
		  <title>Issue</title>
		  <p>
		    I have not yet examined the exception handling
		    policy for machines that implement <term>NX</term>
		    to confirm that a differentiated access violation
		    type is generated at the hardware level.
		  </p>
		</note>
		<p>
		  On hardware that does not support the
		  <term>NX</term> restriction, the <term>NX</term> bit
		  is ignored.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>WK</term></label>
	      <li>
		<p>
		  <leadin>Weak (0x4)</leadin> A capability read reference
		  along an address translation path that traverses a
		  capability with this bit set conservatively
		  downgrades the returned capability, if required, in
		  a way that ensures <em>transitively</em> read-only
		  authority.
		</p>
		<p>
		  Capability and data stores that traverse a weak
		  capability in the translation path generate an
		  access violation exception.
		</p>
	      </li>
	    </defli>
	    <defli>
	      <label><term>OP</term></label>
	      <li>
		<p>
		  <leadin>Opaque (0x8)</leadin> The address space
		  structure may not be accessed or modified through
		  any GPT capability with the Opaque bit set.
		</p>
	      </li>
	    </defli>
	  </deflist>
	  <p>
	    The result of translation of the form
	    <progident>translate(space,addr,access-type)</progident>
	    is either an exception or a valid translation of the form
	    <progident>(page,offset)</progident>. If an exception is
	    generated, the type of the exception and the originally
	    referenced address are reported to a handler (if one is
	    defined), the faulting instruction (if any) has no
	    effect), and the program counter is not advanced. The
	    defined reference types are:
	  </p>
	  <deflist latex.colspec="ll">
	    <defli>
	      <label><b>Fetch</b></label>
	      <li>
		<p>Instruction load from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Load Data</b></label>
	      <li>
		<p>Read data from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Load Capability</b></label>
	      <li>
		<p>Read capability from address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Store Data</b></label>
	      <li>
		<p>Write data to address space.</p>
	      </li>
	    </defli>
	    <defli>
	      <label><b>Store Capability</b></label>
	      <li>
		<p>Write capability to address space.</p>
	      </li>
	    </defli>
	  </deflist>
	</sect2>
	<sect2>
	  <title>References and Access Violations</title>
	  <p>
	    The rules for address translation are given below in the
	    discussions of individual memory objects. As traversal of
	    the memory objects proceeds, the <em>effective
	    restrictions</em> associated with the address are computed
	    by beginning with no initial restrictions and performing a
	    cumulating logical <em>or</em> with the restriction bits in
	    each traversed capability as translation progresses.
	  </p>
	  <p>
	    If a capability is traversed during translation that
	    cannot legally appear within an address space, a
	    <progident>Malformedpace</progident> exception is
	    generated according to the reference type.
	  </p>
	  <p>
	    If the traversed path is well-formed, but the address
	    cannot be completely translated, an
	    <progident>InvalidAddress</progident> exception is
	    generated according to the reference type. Untranslatable
	    fetch references generate the
	    <progident>InvalidAddress</progident> exception.
	  </p>
	  <p>
	    If an address is completely translatable, the resulting
	    permission restrictions may not permit the reference
	    type. In this case an exception will be generated
	    according to the following rules:
	  </p>
	  <table latex.center="yes" latex.colspec="lll">
	    <thead>
	      <tr>
		<td><b>Ref Type</b></td>
		<td><b>Permissions</b></td>
		<td><b>Result</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>Fetch</td>
		<td>NX</td>
		<td>Exception: 
		  <progident>NoExecute</progident></td>
	      </tr>
	      <tr>
		<td>Capability Store, Data Store</td>
		<td>RO <em>or</em> WK</td>
		<td>Exception: 
		  <progident>AccessViolation</progident></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    If the permissions are sufficient to allow the operation,
	    a final check is made to ensure that the type of the load
	    or store operation (data or capability) matches the type
	    of the page mapped at that address (Page, CapPage). If a
	    type mismatch occurs, a
	    <progident>DataAccessTypeError</progident> or
	    <progident>CapAccessTypeError</progident> exception is
	    raised.
	  </p>
	  <p>
	    A capability load that traverses a path having
	    <progident>WK</progident> restrictions will succeed, but
	    will return a downgraded result as follows:
	  </p>
	  <table latex.center="yes" latex.colspec="ll">
	    <thead>
	      <tr>
		<td><b>Capability At Address</b></td>
		<td><b>Result</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>Page, CapPage, GPT, Window, Endpoint</td>
		<td>Copy with RO, WK bits set.</td>
	      </tr>
	      <tr>
		<td>Discrim</td>
		<td>Return value is unchanged.</td>
	      </tr>
	      <tr>
		<td><em>other</em></td>
		<td>Null capability is returned.</td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
      </sect1>
      <sect1 id="pages">
	<title>Pages and Capability Pages</title>
	<p>
	  The smallest mappable unit, and therefore the smallest
	  address space, is the page or the cappage. A page is the
	  atomic unit of data storage whose size is
	  implementation-defined. A capability page is a page-sized
	  unit that holds capabilities rather than data. Capabilities
	  are byte-addressed opaque 16-byte quantities that are
	  aligned at 16 byte boundaries.
	</p>
	<p>
	  Coyotos implements a single page size whose size matches
	  some hardware page size implemented by the underlying
	  hardware. On processors that implement multiple page sizes,
	  the selected page size need not be the smallest size
	  supported by the underlying hardware.  It is
	  implementation-dependent whether the kernel will attempt to
	  exploit larger hardware page sizes if available. If such
	  exploitation is attempted, it is accomplished by
	  re-synthesizing larger pages by physical arrangement of
	  standard-sized pages. The atomic unit of mapping and
	  permissions remains the Coyotos page size.
	</p>
	<p>
	  A page capability may be inserted into the
	  address space slot of a process, with the
	  effect of defining an address space having valid offsets
	  between [<em>guard</em>,<em>guard+pgsize</em>-1]. Attempts
	  to reference offsets outside this range result in an invalid
	  address exception.
	</p>
	<p>
	  Capability pages are byte-addressable units. However,
	  capabilities must be stored and referenced at naturally
	  aligned (16 byte) boundaries.
	</p>
	<p>
	  Address translation of an address <em>addr</em> with respect
	  to a page or cappage capability is defined as follows:
	</p>
	<ol>
	  <li>
	    <p>
	      If the value of <em>addr</em> exceeds the page size, an
	      <progident>InvalidAddress</progident> exception is
	      generated.
	    </p>
	  </li>
	  <li>
	    <p>
	      Otherwise: the <em>addr</em> is a valid offset, and the
	      overall address reference is valid.
	    </p>
	  </li>
	</ol>
      </sect1>
      <sect1 id="as_compose">
	<title>Address Space Composition</title>
	<p>
	  Address spaces are composed by means of the GPT object.  A
	  GPT is simply a fixed-length vector of capabilities
	  (currently 16), each of which is paired with a
	  <term>guard</term>. In Coyotos, the guard has been
	  incorporated into the capability format itself.
	  The state of a GPT is shown below.
	</p>
	<figure latex.placement="h">
	  <img source="gpt" width="75" srctype="sbox"/>
	  <caption>GPT State</caption>
	</figure>
	<p>
	  <leadin>Invariant:</leadin>
	  <progident>l2v&nbsp;&ge;&nbsp;log2(<em>page&nbsp;size</em>)</progident><br/>
	</p>
	<p>
	  The meanings of the GPT fields are:
	</p>
	<deflist>

	  <defli>
	    <label><term>l2v</term></label>
	    <li>
	      <p>
		<leadin>Subspace size</leadin> Each slot of the GPT
		names a subspace of size
		<progident>2<sup>l2v</sup></progident> bytes.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>ha</term></label>
	    <li>
	      <p>
		<leadin>fault handler</leadin> Slot 15 of the GPT
		contains an Entry capability to the fault handler.
	      </p>
	      <p>
		Care should be taken to set the
		<progident>l2v</progident> value appropriately when
		the <progident>ha</progident> bit is set. If the
		translation algorithm traverses an Entry capability in
		the normal course of translation, a malformed space
		exception will be generated.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>bg</term></label>
	    <li>
	      <p>
		<leadin>background space</leadin> Slot 14 of the GPT contains a
		memory capability to a background space (see window
		capabilities).
	      </p>
	      <p>
		Care should be taken to set the
		<progident>l2v</progident> value appropriately when
		the <progident>bg</progident> bit is set. If the
		translation algorithm traverses a background
		capability during the normal course of translation,
		the translation result will appear as if a larger
		space was entered.
	      </p>
	    </li>
	  </defli>
	  <defli>
	    <label><term>cap[0..15]</term></label>
	    <li>
	      <p>
		Capabilities to subspaces.
	      </p>
	    </li>
	  </defli>
	</deflist>
	<p indent="no">
	  When the <progident>ha</progident> or
	  <progident>bg</progident> bits are set, it is the
	  responsibility of the process managing the GPT to ensure
	  that the <progident>l2v</progident> value prevents
	  collision. 
	</p>
	<sect2 id="xlate_algorithm">
	  <title>Translation Algorithm</title>
	  <p>
	    <leadin>Note: </leadin>
	    In the discussion that follows, it may be useful to
	    refer to the capability representation for window and
	    memory object capabilities (see Chapter 2), with
	    particular reference to the <progident>l2v</progident>
	    and <progident>l2g</progident> fields.
	  </p>
	  <p>
	    Address translation is performed by translating an
	    unsigned virtual address <progident>va</progident> with
	    respect to some memory capability <progident>C</progident>
	    (a GPT, page, capability page, or window capability).
	    Translation begins at the address space capability of the
	    process structure with a 64-bit virtual address.  In the
	    normal case, the progress of translation causes bits to be
	    ``consumed'' from the left, leading to virtual addresses
	    of progressively smaller magnitudes.  Window capabilities,
	    however, may cause the remaining virtual address to grow
	    as translation proceeds.
	  </p>
	  <p>
	    The virtual address <progident>va</progident> that is
	    currently being translated is conceptually divided into
	    three fields <em>g</em>, <em>u</em>, and
	    <em>v</em>. 
	    The
	    <progident>g</progident> field (which may be zero width)
	    contains the <term>guard</term> value. 
	    The <em>u</em> field contains the index value
	    that will be used to index into the next GPT. 
	    The
	    <progident>v</progident> field contains either the
	    address bits that will remain to be translated when the
	    current step has completed (GPT or window capability) or
	    the page offset bits (page or capability page capability).
	  </p>
	  <figure latex.placement="h">
	    <img source="gpt-va" width="75" srctype="sbox"/>
	    <caption>Virtual address structure</caption>
	  </figure>
	  <p>
	    In reading the following section, recall the invariants
	    described in Section&nbsp;<xref ref="memcaps"/>. These are
	    checked at capability fabrication time, and are assumed to
	    hold by the following algorithm statements.
	  </p>
	  <p>
	    The values of <em>g</em>, <em>u</em>, and <em>v</em> are
	    computed from the capability <progident>C</progident> and
	    the address <progident>va</progident> as follows:
	  </p>
	  <literallayout>
g = va &gt;&gt; C.l2g;
guard = C.guard &lt;&lt; C.l2g;
u = (va - guard) &gt;&gt; C.l2v;
v = va &amp; ((1u &lt;&lt; C.l2v) - 1);</literallayout>
	  <p>
	    At the start of translation, the background space
	    capability <progident>C<sub>background</sub></progident>
	    and the memory handler capability
	    <progident>C<sub>handler</sub></progident> are initialized
	    to the Null capability, the virtual address is as provided
	    by the hardware (or possibly the IPC logic) and the
	    effective access restrictions <progident>AR</progident> is
	    the empty set.  Translation proceeds by iteration, with
	    each iteration performing the following steps in sequence:
	  </p>
	  <ol>
	    <li>
	      <p>
		The <progident>g</progident> value is compared to the
		 zero-extended guard value stored in the
		 capability. If they do not match, the address is
		 invalid and an <progident>InvalidAddress</progident>
		 exception is generated.
	      </p>
	    </li>
	    <li>
	      <p>
		If the <progident>u</progident> value exceeds the
		number of slots in the GPT, the address is invalid and
		an <progident>InvalidAddress</progident> exception is
		generated.
	      </p>
	    </li>
	    <li>
	      <p>
		The effective access restrictions are updated from the
		capability <progident>C</progident> by:
	      </p>
	      <literallayout>
AR:=AR+C.restr</literallayout>
	      <p indent="no">
		If the resulting effective access restrictions are
		insufficient for the requested access type, an
		<progident>AccessViolation</progident> exception is
		generated.
	      </p>
	    </li>
	    <li>
	      <p>
		Processing now proceeds according to the capability
		type:
	      </p>
	      <ul>
		<li>
		  <p>
		    If the capability type
		    <progident>C.type</progident> is
		    <progident>Page</progident> or
		    <progident>CapPage</progident>, translation has
		    completed successfully.
		  </p>
		</li>
		<li>
		  <p>
		    If a local or background window capability appears
		    in the address space slot of a process, all
		    addresses are deemed invalid.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability is a local window capability
		    appearing within some GPT, translation proceeds
		    from the capability contained in the
		    <em>rootSlot</em> slot of the GPT containing the
		    local window capability at the offset named by the
		    capability.
		  </p>
		  <literallayout>
va := v + C.offset
C := containingGPT[C.rootSlot]</literallayout>
		  <p>
		    Note that the invariants of Section&nbsp;<xref
		    ref="memcaps"/> guarantee that there is no bitwise
		    overlap between <progident>v</progident> and
		    <progident>C.offset</progident>. That is: the
		    addition can be correctly implemented as a bitwise
		    ``or'' operation.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability is a background window
		    capability, translation proceeds from the
		    capability to the background space with
		  </p>
		  <literallayout>
va := v + C.offset
C := C<sub>background</sub></literallayout>
		  <p>
		    Note that the invariants of Section&nbsp;<xref
		    ref="memcaps"/> guarantee that there is no bitwise
		    overlap between <progident>v</progident> and
		    <progident>C.offset</progident>. That is: the
		    addition can be correctly implemented as a bitwise
		    ``or'' operation.
		  </p>
		  <p>
		    Recall that
		    <progident>C<sub>background</sub></progident> is
		    initialized to Null at the start of
		    translation. If no other background capability has
		    been defined at the point where the background
		    window capability is encountered, all addresses
		    that fall within the background window are
		    invalid.
		  </p>
		</li>
		<li>
		  <p>
		    If the capability type is
		    <progident>GPT</progident>, translation proceeds
		    with
		  </p>
		  <literallayout>
gpt := target-of(C);
if (gpt-&gt;bg)
  C<sub>background</sub> = gpt-&gt;cap[14];
if (gpt-&gt;ha)
  C<sub>handler</sub> = gpt-&gt;cap[15];
va := v
C := gpt-&gt;cap[<em>u</em>]</literallayout>
		</li>
		<li>
		  <p>
		    If the capability is a <progident>Null</progident>
		    capability, an
		    <progident>InvalidAddress</progident>
		    exception is generated.
		  </p>
		</li>
		<li>
		  <p>
		    Otherwise, a
		    <progident>MalformedSpace</progident>
		    exception is generated.
		  </p>
		</li>
	      </ul>
	    </li>
	  </ol>
	</sect2>
	<sect2>
	  <title>Exception Handling</title>
	  <p>
	    If an exception is generated by the translation mechanism,
	    and the memory exception handler capability
	    <progident>C<sub>handler</sub></progident> is not
	    <progident>Null</progident>, then the exception will be
	    delivered to the memory exception handler. Otherwise, the
	    exception type and address are stored in the process's
	    <progident>faultCode</progident> and
	    <progident>faultInfo</progident> slots, respectively, and
	    the process is set running with the pending fault code,
	    and the exception is then delivered as described in
	    Section&nbsp;<xref ref="ExceptionDelivery"/>.
	  </p>
	</sect2>
	<sect2>
	  <title>Cycle Detection</title>
	  <p>
	    It is possible for an erroneous or hostile program to
	    arrange GPT objects in such a way as to create a static
	    cycle. Such an address space is <em>malformed</em>, and
	    attempts to traverse such a cycle during address
	    translation result in an
	    <progident>MalformedSpace</progident> exception.
	  </p>
	  <p>
	    No final selection has been made for a method of cycle
	    detection. Three rules have been proposed:
	  </p>
	  <ol>
	    <li>
	      <p>
		A bound on the total number of GPT structures that
		will be visited before generating a
		<progident>MalformedSpace</progident> exception.
	      </p>
	      <p>
		This method has been rejected. It has the unfortunate
		property that existing, valid addressing structures
		can be rendered invalid by ``splitting'' an existing
		GPT. We want to preserve the ability to split without
		semantic alteration in order to be able to map
		subspaces.
	      </p>
	    </li>
	    <li>
	      <p>
		A bound on the total number of capabilities
		<em>that do not translate new bits</em> that will be
		visited before generating a
		<progident>MalformedSpace</progident> exception.
	      </p>
	      <p>
		This method keeps track of
		<progident>|v<sub>least</sub>|</progident>, the shortest
		virtual address that has been obtained by translation
		to the current point. If
		<progident>C.l2v&ge;|v<sub>least</sub>|</progident>,
		then the current capability does not translate new bits.
	      </p>
	      <p>
		This method has been rejected. It has the unfortunate
		property that existing, valid addressing structures
		can be rendered invalid by ``splitting'' an existing
		GPT. We want to preserve the ability to split without
		semantic alteration in order to be able to map
		subspaces.
	      </p>
	    </li>
	    <li>
	      <p>
		A bound on the total number of <em>bits</em> visited
		for translation, defined as the cumulative sum of
		<progident>(|va|-|v|)</progident> for all
		capabilities visited during a translation attempt.
	      </p>
	      <p>
		This approach preserves the possibility of a
		correctness-preserving split operation.
	      </p>
	    </li>
	  </ol>
	  <p>
	    All methods of cycle detection introduce a complication
	    for implementers: the validity of addresses within a
	    subspace is contextually dependent on the number of
	    bound-countable events in the prefix path leading to that
	    subtree. This means that two process address spaces may
	    both have some subspace mapped at otherwise valid
	    subspaces addresses, and selected subranges of the mapped
	    subspace may nonetheless be valid in one space but not in
	    the other.
	  </p>
	  <p>
	    Because of this problem, care must be taken when
	    implementing page table sharing to ensure that page tables
	    are shared only when all possible references through that
	    hardware table are equally valid in all referencing
	    contexts. If this is not done, one process would be able
	    to produce valid mappings in the hardware mapping table
	    that would be usable by the second, even though the second
	    lacks the ability to produce those hardware mappings for
	    itself.
	  </p>
	</sect2>
<!-- 	<sect2> -->
<!-- 	  <title>Region-Specific Fault Handling</title> -->
<!-- 	  <note> -->
<!-- 	    <title>Pending Edit</title> -->
<!-- 	    <p> -->
<!-- 	      This needs to be fleshed out. The idea is that this is -->
<!-- 	      an invocation that is sent to the per-region fault -->
<!-- 	      handler, but the traversal is done with kernel support -->
<!-- 	      and the kernel ensures that the message is ``valid.'' -->
<!-- 	    </p> -->
<!-- 	  </note> -->
<!-- 	  <p> -->
<!-- 	    An address space fault can be propagated to the memory -->
<!-- 	    fault handler by means of the <progident>probe</progident> -->
<!-- 	    operation on the GPT capability. -->
<!-- 	  </p> -->
<!-- 	  <p> -->
<!-- 	    The rule for processing address probe operations and -->
<!-- 	    background spaces is to use the ``nearest enclosing -->
<!-- 	    context''. A probe message is delivered by logically -->
<!-- 	    traversing the address space mapping structures until a -->
<!-- 	    fault would occur for the given address and access type, -->
<!-- 	    and the fault message is delivered to the fault handler -->
<!-- 	    named by <progident>C<sub>handler</sub></progident> at the -->
<!-- 	    time the fault is observed. Similarly, window capabilities -->
<!-- 	    cause translation to proceed through the prevailing -->
<!-- 	    <progident>C<sub>background</sub></progident> capability -->
<!-- 	    at the time the window capability is encountered. -->
<!-- 	  </p> -->
<!-- 	</sect2> -->
      </sect1>
      <sect1 id="split">
	<title>Address Space Splitting</title>
	<note>
	  <title>Experimental</title>
	  <p>
	    The feature described in this section is experimental. It
	    is not presently implemented, and may be removed in future
	    versions of Coyotos.
	  </p>
	</note>
	<p>
	  In order to support the subspace transfer item described in
	  the capability invocation chapter, Coyotos introduces a new
	  type of exception that may occur in an address space:
	  the <progident>SplitFault</progident>.
	</p>
	<p>
	  Split faults allow an invoker to send a single capability to
	  an arbitrary 2<sup><em>k</em></sup> page region of an
	  address space, provided that the region is naturally aligned
	  and the invoker has sufficient access rights to extract the
	  dominating capability. Similarly, they permit a receiver to
	  generate appropriate ``holes'' into which such a capability
	  must be received.
	</p>
	<p>
	  The problem solved by split faults is that there may not be
	  any naturally dominating GPT for the subspace. 

	  For example, in a system having 4 kilobyte (2<sup>12</sup>
	  byte) pages, the invoker may wish to transmit a
	  2<sup>11</sup> page (2<sup>23</sup> byte) subspace, but the
	  subspace may currently be dominated by a GPT having
	  <progident>l2v=21</progident>. That is: there is no single
	  slot in the GPT that directly holds a capability of the
	  desired span.  Before a single dominating capability can be
	  sent, this GPT must be ``split'' into an arrangement where
	  the target subtree has a single dominating GPT with
	  <progident>l2v=23</progident>.  When such a send is
	  attempted, the invoker will receive a
	  <progident>SplitFault</progident> exception. This is an
	  advisory that the GPT must be split in order to bring a
	  dominating GPT into existence.
	</p>
	<p>
	  Similarly, if a receiver specifies a ``hole'' of some size
	  <tt>2<sup>hlsz</sup></tt> pages, there must exist some GPT
	  in the receiver tree that could receive (with an appropriate
	  guard value) a capability dominating a tree of the requested
	  size.
	</p>
	<p>
	  The reason this feature is considered experimental is that
	  the correct strategy for splitting GPTs is not obvious.
	</p>
<!-- 	<ul> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      <progident>r<sub>patt</sub> &le; hlsz &le; -->
<!-- 	      h<sub>patt</sub></progident> -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      The receiving PATT either has some slot free or some -->
<!-- 	      pattern that exactly matches the target address. -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	  <li> -->
<!-- 	    <p> -->
<!-- 	      The receiver has write permissions on the appropriate -->
<!-- 	      PATT slot. This requires both that the permissions check -->
<!-- 	      described above are satisfied and that no PATT -->
<!-- 	      capability on the path from the address space root to -->
<!-- 	      the modified PATT is opaque. -->
<!-- 	    </p> -->
<!-- 	  </li> -->
<!-- 	</ul> -->
	<p>
	  The address space splitting idea is not yet fully
	  developed. There are certainly holes, including necessary
	  but undefined exception types, that need to be resolved in
	  the definition above.
	</p>
      </sect1>
    </chapter>
    <chapter id="invocation">
      <title>Capability Invocation (including IPC)</title>
      <p>
	Coyotos is an object-based system. A process wishing to
	perform an operation (equivalently: invoke a service) does so
	by invoking some capability that it holds. The capability has
	a defined interface that specifies some set of invokable
	methods, including their argument and return types.  The
	provider of these methods may be either the kernel or an
	application; the invocation mechanism is the same in either
	case.  That is: Coyotos is an extensible object system <cite
	ref="wulf1974hydra"/>.  The primary system call in Coyotos is
	the ``invoke capability'' system call (Section&nbsp;<xref
	ref="syscall_invcap"/>). Other system calls defined by the
	Coyotos specification may all be viewed as convenience
	wrappers for capability method invocations.
      </p>
      <p>
	Because kernel-provided and application-provided services
	share a common invocation mechanism, it is necessary to
	specify both the low-level binding of capability interfaces
	and the externally observable semantics of capability
	invocation. While the specific binding is
	architecture-dependent, this chapter includes recommendations
	on bindings that suffice for most platforms.
      </p>
      <p>
	The invoke capability system call implements a variant of
	the <em>SendAndWait</em> primitive proposed by Liedtke <cite
	  ref="l3:ipc"/> or the <smallcaps>call</smallcaps> and
	<smallcaps>return</smallcaps> primitives of EROS <cite
	  ref="shap1999fastcapsystem"/>. The send phase of the
	invocation can be blocking or non-blocking. If a
	non-blocking send is performed, some or all of the message
	may be truncated.  The receive phase may wait for an
	arbitrary endpoint (an ``open wait'') or a specific endpoint
	(a ``closed wait''). The receive phase is optional.
      </p>
      <sect1 id="msg_payload">
	<title>Invocation Payload</title>
	<p>
	  An invocation passes a message that consists of:
	</p>
	<ul>
	  <li>
	    <p>
	      Up to 8 direct words, the first of which is the
	      invocation control word. The size of these words is
	      architecture dependent. These words may be carried in
	      registers or memory, as specified by the
	      architecture-specific annex for the target platform.
	      The index of the last word transmitted is given by
	      <progident>IPR0.ldw</progident>.
	    </p>
	    <p>
	      Input parameter word 0 of the invoke capability
	      operation contains control information describing the
	      rest of the message payload:
	    </p>
	    <figure latex.placement="h">
	      <img source="syscall-invcap-ipw0" width="75"
		srctype="sbox"/>
	      <caption>Invocation control word (input)</caption>
	    </figure>
	    <p>
	      Provided the invokee is valid and well-formed, a message
	      consisting solely of untyped parameter words is
	      guaranteed to proceed without exceptions on all
	      architectures.
	    </p>
	  </li>
	  <li>
	    <p>
	      Up to four capabilities. Capabilities are transmitted if
	      <progident>IPR0.SC=1</progident>. If so,
	      <progident>IPR0.lsc</progident> gives the index of the
	      last capability transmitted.  Capabilities are received
	      if <progident>IPR0.AC=1</progident>. If so,
	      <progident>IPR0.lrc</progident> gives the index of the
	      last capability that will be accepted.
	    </p>
	  </li>
	  <li>
	    <p>
	      An <term>indirect string</term> of up to 64 kilobytes.
	      The length of this string is given in a parameter word
	      to the system call.
	    </p>
	  </li>
	</ul>
	<p>
	  In addition to the payload of the invocation, the invoker
	  specifies:
	</p>
	<ul>
	  <li>
	    <p>
	      The capability to be invoked.
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether they are willing to block in order for the
	      message to be delivered (<progident>IPR0.NB</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether to fabricate a reply capability
	      (<progident>IPR0.RC</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether the receive phase should be performed
	      (<progident>IPR0.RP</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether copy-out of soft registers should be performed
	      on those architectures that define soft registers.
	      (<progident>IPR0.CO</progident>).
	    </p>
	  </li>
	  <li>
	    <p>
	      Whether the receive phase should accept messages only
	      from a particular endpoint
	      (<progident>IPR0.CW</progident>,
	      <progident>upcb.rcvEpID</progident>).
	    </p>
	  </li>
	</ul>
	<p>
	  If a receive phase is executed, the receiver receives the
	  following information in addition to the invocation payload:
	</p>
	<ul>
	  <li>
	    <p>
	      The endpoint identifier of the Endpoint on which the
	      invocation was received.
	    </p>
	  </li>
	  <li>
	    <p>
	      The ``protected payload'' of the capability that was
	      invoked.
	    </p>
	  </li>
	  <li>
	    <p>
	      The length of the string that was sent, it any.
	    </p>
	  </li>
	  <li>
	    <p>
	      A modified copy of the invocation control word, which
	      indicates various information about the incoming
	      message.  In this returned word, the
	      <progident>u</progident>, <progident>RC</progident>, and
	      <progident>SC</progident>, fields are copied from the
	      sender's <em>input</em> invocation control word. The
	      <progident>lsc</progident> field indicates the number of
	      capabilities that have been received. The
	      <progident>ldw</progident> field indicates the number of
	      data words that have been received.
	    </p>
	  </li>
	</ul>
	<p>
	  The protected payload and the endpoint ID can be used to
	  determine the receiver-defined context in which the received
	  message should be interpreted. One common use of these
	  fields is for the endpoint ID to identify the object invoked
	  and the protected payload to identify the permissions on
	  that object.
	</p>
      </sect1>
      <sect1 id="inv_exceptions">
	<title>Invocation-Related Exceptions</title>
	<p>
	  Exceptions may occur during invocation on either the sender
	  or the receiver side of the transmission. All such
	  exceptions logically occur <em>before</em> the
	  invocation. In practice, exceptions are generated as a
	  consequence of payload transfer. If an exception occurs, the
	  implementation is free to resume the transfer at the point
	  of interruption if it is able to do so. However, the
	  receiver of an interrupted transmission logically reverts to
	  the beginning of its receive phase when an exception
	  occurs. In the event that a second sender is attempting to
	  send when a messaging exception is incurred, the second
	  sender's message may prevail.
	</p>
	<p>
	  If the sender specifies non-blocking transmission, the
	  transfer of indirect strings and capabilities is ``best
	  effort.'' If the receiver incurs a page fault during the
	  receipt of an indirect string or a capability argument, that
	  argument will be truncated. In this case the receiver will
	  be notified of truncation, but no receiver-side exception
	  will be generated.
	</p>
	<p>
	  The meaning of a non-blocking send is that the sender is
	  unwilling to be blocked for any cause whose handling is
	  controlled by the receiver. The use-case for this option is
	  a server returning a reply to an untrusted client. For
	  purposes of understanding truncation, a hardware page fault
	  that is successfully resolved by the object paging subsystem
	  is not considered to be an architecturally observable
	  fault. Similarly, an exception that can be satisfied by
	  reconstructing a hardware mapping entry from an already
	  defined GPT hierarchy is not considered an architecturally
	  observable fault.
	</p>
      </sect1>
      <sect1 id="endpoints">
	<title>Endpoints</title>
	<p>
	  A process that wishes to accept capability invocations does
	  so by means of one or more endpoints (Figure&nbsp;<xref
	  ref="endpoint_struct"/>). Endpoints have two capability
	  types: the Endpoint capability, which implements the control
	  interface for the endpoint object, and the Entry capability,
	  which provides the means for extending the object
	  system. When an Entry capability is invoked, the invocation
	  parameters are delivered as a message to the process named
	  by the <progident>recipient</progident> field of the
	  Endpoint.
	</p>
	<figure id="endpoint_struct" latex.placement="h">
	  <img source="endpoint" width="75" srctype="sbox"/>
	  <caption>Endpoint structure</caption>
	</figure>
	<p>
	  The meanings of the endpoint fields are:
	</p>
	<table latex.colspec="lp{5.5in}" latex.long="yes">
	  <thead>
	    <tr>
	      <td><b>Field</b></td>
	      <td><b>Meaning</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td><term>pm</term></td>
	      <td>
		<p>
		  <leadin>Payload Match</leadin> Indicates that the
		  protected payload of the endpoint should be compared
		  to the protected payload of the Entry
		  capability. If they are not equal, the invocation
		  behaves as if the Null capability had been invoked.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>protPayload</term></td>
	      <td>
		<p>
		  <leadin>Protected Payload</leadin> This value will be
		  conditionally used as a matching value if
		  <progident>PM</progident> is set (1).
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>endpointID</term></td>
	      <td>
		<p>
		  A 60-bit field having meaning only to the
		  recipient. The value of this field will be delivered
		  to the recipient during message receive.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><term>recipient</term></td>
	      <td>
		<p>
		  A process capability to the receiving process.
		</p>
	      </td>
	    </tr>
	  </tbody>
	</table>
	<note>
	  <title>Non-Normative Illustration</title>
	  <p>
	    When a server implements a single logical object, it will
	    typically operate with two endpoints. The first is the one
	    used to invoke the service (the ``receive endpoint''). The
	    endpoint ID of this endpoint is not used. The protected
	    payload of the corresponding Entry capability may be used
	    to express distinct permissions or restrictions on the
	    permitted operations. The second endpoint is used to
	    accept replies (the ``reply endpoint''). The endpoint ID
	    of this endpoint is used as a matching value to implement
	    a closed wait so that unrelated messages are not received
	    where a reply is expected. The endpoint's protected
	    payload is used to ensure that no more than one reply will
	    be received (by means of the
	    <progident>IPR0.RC</progident> bit of the invoke
	    capability system call).
	  </p>
	  <p>
	    When a server implements multiple objects, a distinct
	    receive endpoint is typically allocated for each object
	    implemented by the server. In this case, the endpoint ID
	    is used to identify which object or service is being
	    invoked, and the protected payload field of the
	    corresponding Entry capability is used to express distinct
	    permissions or restrictions on the permitted operations on
	    that object.
	  </p>
	</note>
	<note>
	  <title>Non-Normative Note on Reply Endpoints</title>
	  <p>
	    If the <progident>IPR0.RC</progident> bit is set in the
	    invocation control word parameter, the protected payload
	    of the endpoint is pre-incremented before the Entry
	    capability is fabricated. The purpose of the RC bit is to allow
	    a caller to ensure that a call/return sequence receives at
	    most one reply in the normal case. This is accomplished by
	    ensuring that stale reply capabilities are invalidated (by
	    protected payload mismatch) before the next receive on the
	    reply endpoint is performed.
	  </p>
	  <p>
	    Whenever an Entry capability is invoked, the invokee
	    receives the protected payload value of the invoked Entry
	    capability. In the case of a reply endpoint, the PM bit is
	    set, so the received protected payload value matches the
	    value stored in the endpoint.
	  </p>
	  <p>
	    It is the responsibility of the application to notice when
	    the incoming protected payload value approaches
	    UINT32_MAX. In this situation, the pre-increment will
	    overflow the protected payload counter when it is next
	    used. The recommended solution for this is to obtain a new
	    reply endpoint from a space bank when the protected
	    payload reaches UINT32_MAX-1.
	  </p>
	</note>
      </sect1>
      <sect1 id="cap_kernel_sem">
	<title>Semantics of Kernel Capability Invocation</title>
	<p>
	  To ensure consistent invocation behavior, it is necessary to
	  specify the externally observable behavior when a
	  kernel-implemented method is invoked. In particular, the
	  observable effect on process state and the sequencing of
	  operations and events during a kernel invocation must be
	  defined.
	</p>
	<p>
	  When a kernel capability is invoked, the externally
	  observable behavior should be as if the invoker had invoked
	  an endpoint to some application providing the
	  service. Because no kernel operation accepts an indirect
	  string, the invocation of a kernel capability behaves as if
	  this hypothetical provider had performed a receive phase
	  with <progident>IPR0.AS=0</progident> (no strings will be
	  accepted).  This hypothetical provider arrives at the
	  specified answer and accomplishes any effects of the
	  invocation by unspecified means. It then replies as if it
	  had invoked the <progident>InvCap</progident> system call
	  with the control bits of the first input parameter word set
	  as follows: <progident>NB=1</progident> (non-blocking),
	  <progident>RC=0</progident> (no reply capability is
	  generated), <progident>CW=0</progident> (the kernel
	  conceptually enters an open wait state), and
	  <progident>RP=1</progident> (the kernel waits for the next
	  invocation).  In addition, the <progident>SC</progident>
	  (send capabilities) control bit will be set (clear) if
	  capabilities are (are not) returned by the method.  Note
	  that because the kernel reply is non-blocking, and the
	  kernel is deemed to be in the <em>running</em> state until
	  it has replied, the reply from a kernel-implemented
	  capability cannot cause a second kernel-implemented
	  capability to be invoked.
	</p>
	<p>
	  This statement of behavior has (at least) the following
	  implications:
	</p>
	<ul>
	  <li>
	    <p>
	      The effects of a kernel capability invocation occur
	      whether or not the invocation returns successfully,
	      provided any preconditions specified for the method are
	      satisfied.
	    </p>
	  </li>
	  <li>
	    <p>
	      There exist several kernel operations that alter the
	      state of a process. When the process altered is also the
	      process receiving the kernel reply (the ``invokee''),
	      the kernel behavior must be well-defined. There are two
	      such cases:
	    </p>
	    <ol>
	      <li>
		<p>
		  The invokee process is destroyed as an effect of the
		  invoked method. In this case, the reply proceeds as
		  if via an endpoint that contains a Null capability.
		</p>
	      </li>
<!-- 	      <li> -->
<!-- 		<p> -->
<!-- 		  The UPCB of the invokee process is destroyed as an -->
<!-- 		  effect of the invoked method, or the UPCB slot of -->
<!-- 		  the invokee is overwritten with a new capability by -->
<!-- 		  the invoked method. -->
<!-- 		</p> -->
<!-- 		<p> -->
<!-- 		  If, following the effect of the operation, the -->
<!-- 		  process KPCB contains a valid page capability in the -->
<!-- 		  <progident>upcb</progident> slot, the return values -->
<!-- 		  are delivered to the new UPCB page, according to the -->
<!-- 		  receive parameters and buffer registers of the -->
<!-- 		  <em>new</em> UPCB page. Note that both of these -->
<!-- 		  operations, when successful, return only a single -->
<!-- 		  reply status word. In consequence, the modification -->
<!-- 		  of the UPCB does not actually require that the -->
<!-- 		  receive buffers be re-examined in order to correctly -->
<!-- 		  deliver the reply. -->
<!-- 		</p> -->
<!-- 		<p> -->
<!-- 		  Otherwise, the invokee is considered -->
<!-- 		  <term>malformed</term>, and reply delivery proceeds -->
<!-- 		  as if an endpoint naming a malformed process were -->
<!-- 		  being invoked. Any reply payload that would have -->
<!-- 		  been stored in the UPCB, or whose destination -->
<!-- 		  location would have been determined by consulting -->
<!-- 		  the UPCB, is dropped. A -->
<!-- 		  <progident>MalformedProcess</progident> fault code -->
<!-- 		  is set in the invokee's -->
<!-- 		  <progident>faultCode</progident> slot, and the -->
<!-- 		  invokee transitions to the running state. -->
<!-- 		</p> -->
<!-- 	      </li> -->
	    </ol>
	  </li>
	</ul>
	<p>
	  By intention, kernel-implemented operations satisfy two
	  invariants that simplify or eliminate other potentially
	  obscure corner cases:
	</p>
	<ul>
	  <li>
	    <p>
	      No kernel-implemented interface accepts or returns an
	      indirect string.
	    </p>
	  </li>
	  <li>
	    <p>
	      Kernel methods that modify address space mappings or
	      revoke objects return only scalar return values (and
	      therefore behave as if
	      <progident>SC=0</progident>). This ensures that changes
	      in the meaning of the receive capability
	      <progident>capitem_t</progident> values cannot impact
	      the return of these operations.
	    </p>
	  </li>
	</ul>
	<p>
	  <leadin>Undefined Locations</leadin> The content of receive
	  buffers, receive parameters, and receive capability
	  locations is undefined between the start of the IPC receive
	  phase and the completion of the IPC receive phase.  For
	  performance reasons, the kernel is entitled to arbitrarily
	  modify state whose content is undefined during
	  invocation. In particular, the kernel is entitled to modify
	  the receive parameters or the receive string buffers of a
	  waiting process without releasing that process from its wait
	  state. This allows the kernel to more efficiently implement
	  indirect string moves that may induce invoker or invokee
	  page faults during the transfer. This means that
	  <em>all</em> of the receive string buffers of a recipient
	  may be modified during receive, even if the final message
	  received sends only a single indirect byte.  Similarly, any
	  valid receive capability locations may be overwritten even
	  if a smaller number of capabilities was transferred.
	</p>
	<p>
	  <leadin>State Transitions</leadin> The overwhelming majority
	  of kernel capability invocations return to the invoker
	  without generating any exception. In these cases, the kernel
	  may behave as if the operation occurred instantaneously,
	  with the consequence that the invoker may never be observed
	  to leave the <em>running</em> state.
	</p>
	<p>
	  <leadin>Elided Reply Capability</leadin> When a kernel
	  capability is invoked and replies to the invoker without an
	  exception, the kernel implementation is free to elide the
	  fabrication of the reply capability. Elided reply
	  capabilities are observable because the protected payload
	  value of the reply endpoint will not be incremented.
	</p>
      </sect1>
    </chapter>
    <chapter id="syscalls">
      <title>System Calls</title>
      <p>
	Coyotos currently defines three system calls:
      </p>
      <table latex.center="yes" latex.colspec="llp{4.5in}">
	<thead>
	  <tr>
	    <td>Number</td>
	    <td>Name</td>
	    <td>Description</td>
	  </tr>
	</thead>
	<tbody>
	  <tr>
	    <td>0</td>
	    <td><progident>InvokeCap</progident></td>
	    <td>
	      <p>
		Invokes a capability and (optionally) waits for a
		reply on an endpoint.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>1</td>
	    <td><em>reserved</em></td>
	    <td>
	      <p>
		Reserved for future use.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>2</td>
	    <td><progident>CopyCap</progident></td>
	    <td>
	      <p>
		Copy a capability from one location to another.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>3</td>
	    <td><progident>Yield</progident></td>
	    <td>
	      <p>
		Yield the processor, moving the current process to the
		back of its scheduling class.
	      </p>
	    </td>
	  </tr>
	  <tr>
	    <td>4..15</td>
	    <td><em>reserved</em></td>
	    <td>
	      <p>
		Reserved for future use.
	      </p>
	    </td>
	  </tr>
	</tbody>
      </table>
      <sect1 id="param_words">
	<title>Parameters and Parameter Words</title>
	<p>
	  At the system call trap interface, arguments and return
	  values are conveyed by means of a combination of
	  registerized parameter values and (optionally) a system-call
	  specific stack frame. Every architecture-specific annex
	  specifies a subset of hardware registers that are be used to
	  convey system call parameters.  No annex defines fewer than
	  four registers to be available at this interface. Where a
	  specialized stack frame is specified, the
	  architecture-specific annex may specify that some or all of
	  that stack frame is conveyed across the user/supervisor
	  boundary in registers. The corresponding fields of the
	  stack frame will never be accessed by the kernel.
	</p>
	<p>
	  The Coyotos system call specification ensures that all
	  arguments and return values of system calls <em>other
	  than</em> <progident>InvokeCap</progident> can be marshalled
	  in registers. In addition, the majority of
	  kernel-implemented capabilities, including all capabilities
	  likely to be invoked in performance-critical application
	  paths, can be invoked without a string parameter.
	</p>
<!-- 	<p> -->
<!-- 	  On 32-bit platforms, there are 64 parameter -->
<!-- 	  words. On 64-bit platforms, there are 32 parameter words. -->
<!-- 	</p> -->
<!-- 	<p> -->
<!-- 	  All integral scalar types used in the kernel interface, -->
<!-- 	  including those specified as parameters of capability -->
<!-- 	  interfaces and system calls, are naturally aligned -->
<!-- 	  regardless of target platform word size. In particular, 64 -->
<!-- 	  bit integer arguments and fields are aligned at 64 bit -->
<!-- 	  offsets, and structures containing these values (if any) are -->
<!-- 	  required to be aligned at 64 bit boundaries wherever they -->
<!-- 	  are presented at the kernel interface.  Note that on 32-bit -->
<!-- 	  targets this imposes a <em>general</em> alignment constraint -->
<!-- 	  only for <em>nested</em> structures. When an outermost -->
<!-- 	  structure is presented as OUT parameter on a 32-bit -->
<!-- 	  platform, the structure pointer given may be 32-bit aligned. -->
<!-- 	  However, if the same structure is copied to parameter words -->
<!-- 	  during marshalling or demarshalling, the marshalled from -->
<!-- 	  will be naturally aligned within the parameter words. -->
<!-- 	</p> -->
	<p>
	  In the system call specifications that follow, the notation
	  IPR<em>n</em> and OPR<em>n</em> indicate input and output
	  parameter registers, respectively.  Except where required by
	  the architecture-specific system call mechanism, or
	  explicitly noted by the system call, output registers retain
	  their value at the time of system call entry.
	</p>
      </sect1>
      <sect1 id="syscall_exceptions">
	<title>Exceptions</title>
	<p>
	  The following exceptions may be incurred by the caller
	  during system call execution.
	</p>
	<table latex.center="yes" latex.colspec="lp{4in}">
	  <thead>
	    <tr>
	      <td><b>Exception</b></td>
	      <td><b>Cause</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td><progident>MalformedSyscall</progident></td>
	      <td>
		<p>
		  The operand was malformed. This includes field
		  value range errors or reserved type codes.
		</p>
		<p>
		  The <progident>faultInfo</progident> field is
		  zero.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>MisalignedReference</progident></td>
	      <td>
		<p>
		  The operand specified a capability address, but
		  the address described is not aligned to a 16-byte
		  boundary.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>InvalidAddress</progident></td>
	      <td>
		<p>
		  The operand specified an address that is
		  not defined.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>AccessViolation</progident></td>
	      <td>
		<p>
		  A store operation was attempted, but the operand
		  specified an address that does not permit write
		  access.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>DataAccessTypeError</progident></td>
	      <td>
		<p>
		  The address specified by a data load/store operand
		  does not reference a data page.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>CapAccessTypeError</progident></td>
	      <td>
		<p>
		  The address specified by a capability load/store
		  system call does not reference a capability page.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td><progident>MalformedSpace</progident></td>
	      <td>
		<p>
		  The address specified by the operand violated the
		  well-formed address space constraints.
		</p>
		<p>
		  The <progident>faultInfo</progident> field
		  contains the errant address value.
		</p>
	      </td>
	    </tr>
	  </tbody>
	</table>
	<p>
	  Any system call may generate the
	  <progident>MalformedSyscall</progident> exception if bits
	  marked ``reserved'' are non-zero or specified field value
	  bounds are exceeded.  Individual system call descriptions
	  below specify which of the other exceptions may be incurred
	  by that system call.
	</p>
      </sect1>
      <sect1>
	<title>Capability Locations</title>
	<figure id="caploc_t" latex.placement="h">
	  <img source="caploc_t" width="75" srctype="sbox"/>
	  <caption>caploc_t structure</caption>
	</figure>
	<p>
	  A <progident>caploc_t</progident> parameter
	  (Figure&nbsp;<xref ref="param_types"/>) describes a
	  generalized capability location that is either a
	  capability register (ty=0) or a memory
	  address (ty=1).
	</p>
	<p>
	  The encoding of register <progident>caploc_t</progident>
	  values is identical to the encoding used for
	  <progident>capreg_t</progident> values, modulo the wider
	  <progident>location</progident> field. When the
	  <progident>caploc_t</progident> describes a memory
	  address, the <progident>location</progident> field holds
	  the most significant bits of the address. Capability
	  addresses are required to be 16 byte aligned. In
	  consequence, the expression of valid capability addresses
	  is not restricted by the re-use of the least significant
	  bit for this purpose.
	</p>
	<p>
	  The size of a <progident>caploc_t</progident> matches the
	  architecture-defined word size.
	</p>
      </sect1>
      <sect1 id="pseudo_instrs">
	<title>Pseudo-Instructions</title>
	<p>
	  The <progident>Yield</progident> and
	  <progident>CopyCap</progident> system calls are best
	  thought of as pseudo-instructions.
	</p>
	<sect2 id="syscall_Yield">
	  <title>Yield [syscall]</title>
	  <p>
	    The <progident>Yield</progident> system call relinquishes
	    the processor. If the <progident>I</progident> bit is clear
	    (0), the yielding process is placed at the end of the
	    appropriate ready queue.
	  </p>
	  <table latex.center="yes">
	    <thead>
	      <tr>
		<td>Parameter</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPR0</td>
		<td><img source="syscall-yield-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The <progident>Yield</progident> system call does not return
	    any output parameters.
	  </p>
	  <note>
	    <title>Open Issue</title>
	    <p>
	      Should there be a directed yield operation? If so, the
	      yield system call needs to take a second parameter.
	    </p>
	  </note>
	</sect2>
	<sect2 id="syscall_copycap">
	  <title>CopyCap [syscall]</title>
	  <table latex.center="yes">
	    <thead>
	      <tr>
		<td>Parameter</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPR0</td>
		<td><img source="syscall-copycap-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPR1</td>
		<td><img source="syscall-copycap-ipw1" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPR2</td>
		<td><img source="syscall-copycap-ipw2" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The <progident>CopyCap</progident> system call copies a
	    capability from a source location (register or memory address)
	    to a target location (register or memory address).
	    The <progident>CopyCap</progident> system
	    call does not return any output parameters. Exceptions may
	    be generated by the references to the <em>source</em> and 
	    <em>dest</em> parameters.
	  </p>
	  <p>
	    Any of the exceptions listed in Section&nbsp;<xref
	    ref="syscall_exceptions"/> other than
	    <progident>DataAccessTypeError</progident> may be
	    generated by this system call.
	  </p>
	</sect2>
      </sect1>
      <sect1 id="syscall_invcap">
	<title>InvokeCap [syscall]</title>
	<p>
	  The <progident>InvokeCap</progident> system call invokes a
	  capability, passing the supplied parameters to the
	  implementing server. It is both the most complex and the
	  most commonly used system call in the interface. It invokes
	  one capability and optionally blocks for an incoming message
	  on an Endpoint. <progident>InvokeCap</progident> takes a
	  variable number of parameters determined by the invocation
	  control word provided in IPR0 and a system-call specific
	  stack frame.
	</p>
	<p>
	  Any of the exceptions listed in Section&nbsp;<xref
	    ref="syscall_exceptions"/> may be generated by this system
	  call.
	</p>
	<sect2 id="invcap_args">
	  <title>Arguments</title>
	  <p>
	    The arguments to <progident>InvokeCap</progident> are
	    organized in a specialized stack frame. Some elements of
	    the stack frame are then registerized. The canonical stack
	    frame format for <progident>InvokeCap</progident> is shown
	    below:
	  </p>
	  <literallayout>
typedef struct {
  uintptr_t pw[8];
  union {
    caploc_t  invCap;		/* on entry */
    uintptr_t pp;		/* on exit */
  } u;
  caploc_t  sndCap[4];
  caploc_t  rcvCap[4];
  uint32_t  sndLen;		/* FIX: Should be 16 bits */
  uint32_t  rcvBound;		/* FIX: Should be 16 bits */
  void     *sndPtr;
  void     *rcvPtr;
  uint64_t  epID;
} InvParameterBlock_t;</literallayout>
	  <p>
	    All architectures guarantee that the
	    <progident>pw[0]..pw[3]</progident> field are conveyed in
	    registers on both entry and exit. Since the message
	    payload may contain up to 8 data words, the caller should
	    assume that <progident>pw[0]..pw[7]</progident> may be
	    modified on return.
	  </p>
	  <p>
	    The control word parameter to
	    <progident>InvokeCap</progident> is given by:
	  </p>
	  <table latex.center="yes" latex.colspec="llp{5in}">
	    <thead>
	      <tr>
		<td>Argument</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>IPR0</td>
		<td><img source="syscall-invcap-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>IPR1</td>
		<td>Input <progident>pw[1]</progident>, if transmitted.</td>
	      </tr>
	      <tr>
		<td>IPR2</td>
		<td>Input <progident>pw[2]</progident>, if transmitted.</td>
	      </tr>
	      <tr>
		<td>IPR3</td>
		<td>Input <progident>pw[3]</progident>, if transmitted.</td>
	      </tr>
	      <tr>
		<td>OPR0</td>
		<td><img source="syscall-invcap-ipw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPR1</td>
		<td>Output <progident>pw[1]</progident>, if received.</td>
	      </tr>
	      <tr>
		<td>OPR2</td>
		<td>Output <progident>pw[2]</progident>, if received.</td>
	      </tr>
	      <tr>
		<td>OPR3</td>
		<td>Output <progident>pw[3]</progident>, if received.</td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    Other fields and registers are sourced and modified
	    according to the interpretation of the control word and
	    the parameters provided in the stack frame.
	  </p>
	  <p>
	    The fields of the control word have the following meanings:
	  </p>
	  <table latex.colspec="llp{5in}" latex.long="yes">
	    <thead>
	      <tr>
		<td><b>Bit</b></td>
		<td><b>Name</b></td>
		<td><b>Meaning</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>ldw</td>
		<td>Last Data Word</td>
		<td>
		  <p>
		    On entry, the index of the last data word
		    transmitted.  Following a receive phase, this
		    field will contain the values specified in the
		    sender's invocation control word. A receiving
		    process must be prepared to accept 8 direct data
		    words.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>lsc</td>
		<td>Last Sent Capability</td>
		<td>
		  <p>
		    The index of the last sent capability. No
		    capabilities are sent if the
		    <progident>SC</progident> field is clear
		    (0). Following a receive phase, this field will
		    contain the value specified in the sender's
		    invocation control word.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>lrc</td>
		<td>Last Received Capability</td>
		<td>
		  <p>
		    On entry: the index of the last capability slot
		    that will be received. No capabilities are
		    received if the <progident>AC</progident> field is
		    clear (0).
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>sg</td>
		<td>Send Gather</td>
		<td>
		  <p>
		    Send transmitted string(s) using the gather
		    mechanism. This mechanism is not yet specified,
		    and the bit should be clear (0) in all
		    invocations.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>as</td>
		<td>accept scatter</td>
		<td>
		  <p>
		    Accept transmitted string(s) using the scatter
		    mechanism. This mechanism is not yet specified,
		    and the bit should be clear (0) in all
		    invocations.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>nb</td>
		<td>Non-Blocking</td>
		<td>
		  <p>
		    If set (1), send is non-blocking. Any action that
		    would require the sender to be enqueued in such a
		    fashion that re-awakening is controlled by the
		    receiver will result in a dropped message. Any
		    action that would cause a receiver-controlled
		    exception handler to be executed will result in a
		    truncated message.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>cw</td>
		<td>Closed Wait</td>
		<td>
		  <p>
		    If set (1), indicates that the receive phase is
		    performing a closed wait, and only messages from
		    endpoints whose endpoint ID matches the supplied
		    <progident>epID</progident> value will be
		    accepted.
		  </p>
		  <p>
		    If clear (0), no restrictions are imposed on
		    receipt and the <progident>epID</progident>
		    field is ignored.
		  </p>
		</td>
	      </tr>	   
	      <tr>
		<td>sp</td>
		<td>Send Phase</td>
		<td>
		  <p>
		    If set (1), the send phase will be executed.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>rp</td>
		<td>Receive Phase</td>
		<td>
		  <p>
		    If set (1), the receive phase will be executed.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>rc</td>
		<td>Reply Capability</td>
		<td>
		  <p>
		    If set (1), and <progident>sndCap0</progident>
		    names an endpoint capability,
		    <progident>sndCap0</progident> will be replaced
		    with the corresponding Entry capability. The
		    protected payload of the Entry capability will be
		    set to the current protected payload value stored
		    in the endpoint.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>sc</td>
		<td>Send Capabilities</td>
		<td>
		  <p>
		    If set (1), capabilities will be transmitted.
		    Following a receive phase, this field will contain
		    the value specified in the sender's invocation
		    control word.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>ac</td>
		<td>Accept Capabilities</td>
		<td>
		  <p>
		    If set (0), incoming capabilities will be accepted.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>co</td>
		<td>Copy Out</td>
		<td>
		  <p>
		    If set (0), the copy out phase will be
		    executed. Soft register values will be copied back
		    from the kernel to the invocation parameter
		    structure.
		  </p>
		</td>
	      </tr>
	      <tr>
		<td>ex</td>
		<td>exceptional return</td>
		<td>
		  <p>
		    If set (1), indicates that the message payload
		    describes an exception.
		    Following a receive phase, this field will contain
		    the value specified in the sender's invocation
		    control word.
		  </p>
		</td>
	      </tr>
	    </tbody>
	  </table>
	  <p>
	    The parameters of the <progident>InvokeCap</progident>
	    system call are unusual, in that IPR0 determines how the
	    remaining input parameter words are interpreted. Further,
	    some of the bits in the IPR0 word determine how the output
	    parameteres are processed and delivered.
	    <progident>InvokeCap</progident> is <em>also</em> unusual
	    because control flow may not return immediately to the
	    invoker. Finally, it is unusual because an
	    <progident>InvokeCap</progident> system call may cause
	    exceptions to be incurred by the receiver <em>during</em>
	    the system call rather than before it.
	  </p>
	  <sect3>
	    <title>Conventions</title>
	    <p>
	      <progident>InvokeCap</progident> is a reflective system
	      call.  Because the kernel-implemented capabilities use
	      the same request marshalling and demarshalling
	      conventions as application-implemented capabilities,
	      these conventions are effectively mandated.
	    </p>
	    <p>
	      <leadin>Requests</leadin> <progident>IPR1</progident>
	      contains the request code (a method code that is
	      typically assigned by CapIDL). The implementing process
	      uses this request code, in combination with the received
	      endpoint ID and protected payload, to determine what
	      interface has been invoked, what method has been
	      requested, and what permissions the invoker has. By
	      convention, no method should be assigned the method code
	      zero (0).
	    </p>
	    <p>
	      <leadin>Replies</leadin> If
	      <progident>OPR0.ex</progident> is clear (0), then the
	      remaining parameter words contain the specified out
	      parameters according to the interface specification. If
	      <progident>OPR0.ex</progident> is set (0), then the
	      remaining parameter words contain the exception message,
	      which consists of a 64-bit exception code followed by an
	      optional structure containing additional
	      information. The exception code may occupy
	      <progident>OPR1</progident> or
	      <progident>OPR1..OPR2</progident> or
	      <progident>OPR2..OPR3</progident> (notably SPARC)
	      depending on whether the target architecture is 64-bit
	      or 32-bit and the alignment restrictions imposed on
	      64-bit integral values by the underlying architecture.
	    </p>
	  </sect3>
	  <sect3>
	    <title>Kernel Invocation Conventions</title>
	    <p>
	      The following behavioral specification describes the
	      semantics of the <progident>InvokeCap</progident>
	      instruction as if the capability invoked were an Entry
	      capability. If the capability invoked is a
	      kernel-implemented capability, the invocation behaves as
	      if the kernel were a receiving process that had just
	      performed a SendAndWait with IPR0 and IPR1 fields set as
	      follows:
	    </p>
	    <table latex.center="yes" latex.colspec="lp{2in}lp{2in}">
	      <thead>
		<tr>
		  <td><b>Field</b></td>
		  <td><b>Meaning</b></td>
		  <td><b>Field</b></td>
		  <td><b>Meaning</b></td>
		</tr>
	      </thead>
	      <tbody>
		<tr>
		  <td>IPR0.CW=0</td>
		  <td>Perform an open wait.</td>
		  <td>IPR0.NB=0</td>
		  <td>Reply will be non-blocking.</td>
		</tr>
		<tr>
		  <td>IPR0.AS=1</td>
		  <td>Accept string arguments.</td>
		  <td>IPR0.AC=1</td> <td>Accept capability
		  arguments.</td>
		</tr>
		<tr>
		  <td>IPW1</td>
		  <td>(ignored <progident>capitem_t</progident>).</td>
		  <td>IPR0.RP=1</td>
		  <td>Perform a receive operation.</td>
		</tr>
		<tr>
		  <td>IPR0.RC=0</td> 
		  <td>No reply capability.</td> 
		  <td>IPR0.ldw</td>
		  <td>Set according to last operation.</td>
		</tr>
	      </tbody>
	    </table>
	  </sect3>
	</sect2>
	<sect2>
	  <title>Return Values</title>
	  <p>
	    The return values of <progident>InvokeCap</progident> are
	    copies of the sender's argument values with minor
	    alterations:
	  </p>
	  <ul>
	    <li>
	      <p>
		The protected payload of the invoked endpoint
		capability is supplied in place of the invoked
		capability <progident>caploc_t</progident>.
	      </p>
	    </li>
	    <li>
	      <p>
		The sender control bits are replaced by
		<progident>T</progident>, a bit indicating that one or
		more incoming typed items were truncated.
	      </p>
	    </li>
	    <li>
	      <p>
		All addresses supplied in the input typed items are
		zeroed in the output typed items.
	      </p>
	    </li>
	    <li>
	      <p>
		On output, the kernel injects an
		<progident>epiditem_t</progident> as the first output
		typed item.
	      </p>
	    </li>
	  </ul>
	  <table latex.center="yes" latex.colspec="llp{5in}">
	    <thead>
	      <tr>
		<td>Result</td>
		<td>Format</td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>OPR0</td>
		<td><img source="syscall-invcap-opw0" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPR1</td>
		<td><img source="syscall-invcap-rcvPP" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPR2..OPR<em>u</em></td>
		<td><img source="syscall-invcap-word" width="70" srctype="sbox"/></td>
	      </tr>
	      <tr>
		<td>OPR<em>u+1</em>..OPR<em>u+t+1</em></td>
		<td><img source="syscall-invcap-titem" width="70" srctype="sbox"/></td>
	      </tr>
	    </tbody>
	  </table>
	</sect2>
      </sect1>
    </chapter>
    <chapter id="scheduling">
      <title>Schedules</title>
      <sect1>
	<title>Scheduling Model</title>
      </sect1>
    </chapter>
    <chapter>
      <title>Other Kernel Objects</title>
      <p>
	This chapter describes the services provided by the
	miscellaneous kernel capabilities.
      </p>
      <p>
	The <progident>null</progident> capability is used when a
	non-optional capability field must be transmitted but the
	sender does not wish to send a capability in that position.
	Capabilities to destroyed objects become null.
      </p>
      <p>
	The <progident>keybits</progident> capability discloses the
	canonical representation of capabilities. The
	<progident>keybits</progident> capability is considered
	sensitive, and should be closely held. The value of the
	hazard bit <term>HZ</term> is always shown as zero.
      </p>
      <p>
	The <progident>discrim</progident> capability classifies
	capabilities into one of a limited set of
	classifications. The purpose of
	<progident>discrim</progident> is to support the
	implementation of the confinement policy by the
	<progident>constructor</progident>, which is one of the core
	Coyotos applications.
      </p>
      <p>
	The <progident>range</progident> capability conveys the
	authority to fabricate and destroy arbitrary object
	capabilities. The <progident>range</progident> capability is
	highly sensitive, and should be closely held.
      </p>
      <p>
	The <progident>sleep</progident> capability allows its
	holder to receive an event at a scheduled time.
      </p>
      <p>
	The <progident>IrqCtl</progident> capability allows the holder
	to allocate <progident>IrqWait</progident> capabilities. This
	capability is highly sensitive, and should be closely held.
      </p>
      <p>
	The <progident>IrqWait</progident> capability allows the
	holder to wait for a particular interrupt to occur. This
	capability is highly sensitive, and should be closely held.
      </p>
      <p>
	The <progident>schedctl</progident> capability
	allows the holder to alter the kernel-level scheduling
	dispatch table. This capability is highly sensitive, and
	should be closely held.
      </p>
      <p>
	The <progident>checkpoint</progident> capability allows the
	holder to initiate a system-level snapshot operation and
	force the checkpoint age-out logic to run to
	completion. This capability is highly sensitive, and should
	be closely held.
      </p>
      <p>
	The <progident>obstore</progident> capability implements a
	``reverse'' protocol. The object store server uses this
	capability to wait for kernel object fill and flush requests
	and acts on them.
      </p>
    </chapter>
  </part>
  <part>
    <title>Microkernel Interfaces</title>
    <xi:include href="AddressSpace.xmli"/>
    <xi:include href="AppNotice.xmli"/>
    <xi:include href="Cap.xmli"/>
    <xi:include href="CapBits.xmli"/>
    <xi:include href="CapPage.xmli"/>
    <xi:include href="Checkpoint.xmli"/>
    <xi:include href="Discrim.xmli"/>
    <xi:include href="Endpoint.xmli"/>
    <xi:include href="GPT.xmli"/>
    <xi:include href="IrqCtl.xmli"/>
    <xi:include href="IrqWait.xmli"/>
    <xi:include href="LocalWindow.xmli"/>
    <xi:include href="Memory.xmli"/>
    <xi:include href="MemoryHandler.xmli"/>
    <xi:include href="Null.xmli"/>
    <xi:include href="ObStore.xmli"/>
    <xi:include href="Page.xmli"/>
    <xi:include href="Process.xmli"/>
    <xi:include href="ProcessHandler.xmli"/>
    <xi:include href="Range.xmli"/>
    <xi:include href="RcvQueue.xmli"/>
    <xi:include href="SchedCtl.xmli"/>
    <xi:include href="Schedule.xmli"/>
    <xi:include href="Sleep.xmli"/>
    <xi:include href="SysCtl.xmli"/>
    <xi:include href="Window.xmli"/>
  </part>
  <part>
    <title>Architecture Specific Annexes</title>
    <appendix>
      <title>IA-32 Interface</title>
      <p>
	The kernel header file
	<filename>coyotos/i386/UPCB.h</filename> defines the UPCB
	layout for this architecture.
      </p>
      <sect1>
	<title>Execution Models</title>
	<p>
	  The IA-32 implementation supports the ``small spaces''
	  optimization. If a process restricts its address references
	  (ignoring KIP references) to the inclusive range [0,
	  0x10000], the kernel will attempt to run it in a small space
	  region. Control transfers between two applications running
	  in a small address space, or between a large address space
	  and a small address space, are significantly faster than
	  large space control transfer.
	</p>
	<p>
	  By referencing an address outside of the small space bound,
	  a process signals that it wishes to be treated as a large
	  address space process. The user-mode addressable range of a
	  large address space is [0x0,0xC0000000]. Because this
	  transition is transparent to the process, the value returned
	  by 
	  <progident>LSL</progident> (load segment limit) is subject
	  to change between any two instructions. The transition
	  between large and small address space models is otherwise
	  transparent to application code.
	</p>
      </sect1>
      <sect1>
	<title>System Call Trap Interface</title>
	<p>
	  In all cases the register utilization convention follows the
	  requirements of <smallcaps>SYSENTER</smallcaps>:
	</p>
	<floatingtable id="ia32_syscall_conventions" latex.placement="h">
	  <!-- On sysexit, EIP from EDX, ESP from ECX -->
	  <!-- On sysret,  EIP from ECX -->
	  <table latex.center="yes" latex.colspec="lll">
	    <thead>
	      <tr>
		<td><b>Register</b></td> <td><b>Input</b></td>
		<td><b>Output</b></td>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		<td>EAX</td>
		<td><progident>IPR0</progident></td>
		<td><progident>OPR0</progident></td>
	      </tr>
	      <tr>
		<td>EBX</td>
		<td><progident>IPR1</progident></td>
		<td><progident>OPR1</progident></td>
	      </tr>
	      <tr>
		<td>ECX</td>
		<td><em>Post-syscall SP</em></td>
		<td><em>Undefined</em></td>
	      </tr>
	      <tr>
		<td>EDX</td>
		<td><em>Post-syscall return PC</em></td>
		<td><em>Undefined</em></td>
	      </tr>
	      <tr>
		<td>ESI</td>
		<td><progident>IPR2</progident></td>
		<td><progident>OPR2</progident></td>
	      </tr>
	      <tr>
		<td>EDI</td>
		<td><progident>IPR3</progident></td>
		<td><progident>OPR3</progident></td>
	      </tr>
	      <tr>
		<td>EBP</td>
		<td><progident>InvokeCap: invCap</progident></td>
		<td><progident>InvokeCap: rcvPP</progident></td>
	      </tr>
	      <tr>
		<td></td>
		<td><progident>Other: <em>unused</em></progident></td>
		<td><progident>Other: <em>unaltered</em></progident></td>
	      </tr>	
	      <tr>
		<td>ESP</td>
		<td><em>Unavailable</em></td>
		<td><em>input ECX value</em></td>
	      </tr>
	    </tbody>
	  </table>
	  <caption>System call entry and exit conventions.</caption>
	</floatingtable>
	<p>
	  Different generations of IA-32 implementations require
	  different system call implementations for
	  efficiency. Depending on the hardware implementation, either
	  a software interrupt (<progident>int $0x31</progident>) the
	  <smallcaps>sysenter</smallcaps> instruction, or the
	  <smallcaps>syscall</smallcaps> instruction may be used. The
	  software interrupt entry point may be used on all platforms.
	  The preferred entry and exit mechanism is left to the kernel
	  implementation. The kernel publishes the preferred mechanism
	  via the <term>kernel interface page</term>. The system call
	  trap instruction appears at offset zero of this page.
	</p>
	<p>
	  The kernel interface page is mapped into all user address
	  spaces at a well-known <em>far</em> address:
	  <progident>0x32:0</progident>.<footnote>
	    <p>
	      The selector value is provisional.
	    </p>
	  </footnote>
	  The protocol for invoking the preferred system call trap
	  instruction is to marshal all arguments 
	  and perform a
	  <em>far jump</em> to this address. The use of a far address
	  allows the kernel interface page to be accessible to both
	  large and small address spaces within a single compilation
	  and execution model.  This address is a well-known constant
	  that is part of the architecture specification, and will not
	  change in future versions of Coyotos.
	</p>
      </sect1>
      <sect1>
	<title>Virtual Registers</title>
	<p>
	  The architecture defines the following locations for input
	  and output parameters, buffer registers, and capability
	  invocation paramaters. Locations described with an
	  identifier rather than a register name indicate a field in
	  the UPCB structure.
	</p>
	<table latex.center="yes" latex.colspec="llll">
	  <thead>
	    <tr>
	      <td><b>Virtual Register</b></td>
	      <td><b>Location</b></td>
	      <td><b>Virtual Register</b></td>
	      <td><b>Location</b></td>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
	      <td>IPR0</td>
	      <td><progident>%eax</progident></td>
	      <td>OPR0</td>
	      <td><progident>%eax</progident></td>
	    </tr>
	    <tr>
	      <td>IPR1</td>
	      <td><progident>%ebx</progident></td>
	      <td>OPR1</td>
	      <td><progident>%ebx</progident></td>
	    </tr>
	    <tr>
	      <td>IPR2</td>
	      <td><progident>%esi</progident></td>
	      <td>OPR2</td>
	      <td><progident>%esi</progident></td>
	    </tr>
	    <tr>
	      <td>IPR3</td>
	      <td><progident>%edi</progident></td>
	      <td>OPR3</td>
	      <td><progident>%edi</progident></td>
	    </tr>
	    <tr>
	      <td>IPR4..IPR7</td>
	      <td><em>caller stack</em></td>
	      <td>OPR4..OPR7</td>
	      <td><em>receiver stack</em></td>
	    </tr>
	    <tr>
	      <td>invCap</td>
	      <td><em>caller stack</em></td>
	      <td>rcvPP</td>
	      <td><progident>softregs.rcvPP</progident></td>
	    </tr>
	    <tr>
	      <td>rcvEpID</td>
	      <td><progident>softregs.epID</progident></td>
	    </tr>
	  </tbody>
	</table>
	<p>
	  Values in the <progident>softregs</progident> structure are
	  copied out to the receiver stack after the receive phase if
	  IPR0.CO is set (1).
	</p>
      </sect1>
      <sect1>
	<title>Thread Identification</title>
	<p>
	  <em><font color="red">This section is stale</font></em>
	</p>
	<p>
	  The first two words of the UPCB are used by the
	  application-level runtime system to provide support for
	  multi-threading. Word 0 should be used by the
	  multi-threading library to store the pointer to the thread
	  control block. Word 1 should be used to store the virtual
	  address of the UPCB itself, as seen by the
	  application. Neither word is initialized by the kernel.
	  Provided the address range exposed falls within the
	  user-mode addressable range, the value of UPCB word 1 is
	  loaded as the base address of the segment named by %GS, with
	  a limit value of 0x1000.
	</p>
	<p>
	  The critical effect of this is that %GS:0 can be used to
	  load and store the application-level thread control block
	  pointer, which is in turn used to access thread-local
	  storage <cite ref="elf-handling"/>.
	</p>
	<note>
	  <title>Open Issue</title>
	  <p>
	    While storing the UPCB VA in the UPCB is attractive, it is
	    not necessarily efficient. The problem is that the value
	    must be range checked on every kernel exit because it can
	    be modified by user-mode code. It may be better to
	    introduce a system call for this and store it in the Process
	    instead.
	  </p>
	</note>
      </sect1>
    </appendix>
  </part>
  <part>
    <title>Notes on Implementation</title>
    <p>
      The Coyotos specification may be seen as defining an abstract
      machine architecture. In a real-world implementation, this
      abstract machine must be mapped on to a combination of hardware
      and software by the kernel implementation. This mapping must
      satisfy two properties:
    </p>
    <ul>
      <li>
	<p>
	  <b>The permissions of the implementation state must never exceed
	  those of the abstract state.</b> Any instruction whose
	  effect is permitted by the implementation state must be
	  permitted by the abstract machine state. The implementation
	  state is a conservative approximation of the abstract state.
	</p>
      </li>
      <li>
	<p>
	  <b>Ignoring latency, every instruction whose execution is
	  permitted by the abstract machine must ultimately be
	  permitted by the implementation.</b> The implementation
	  state is an approximation of the abstract state that is
	  constructed on demand.
	</p>
	<p>
	  The means by which demand update is triggered are the system
	  call trap and the various protection and permissions
	  violation traps.  This induces several requirements on the
	  underlying hardware:
	</p>
	<ul>
	  <li>
	    <p>
	      The hardware must implement page-granularity protections
	      (or better) in its memory management unit.
	    </p>
	  </li>
	  <li>
	    <p>
	      The hardware must implement precise exceptions &mdash;
	      or precise enough that the software implementation can
	      correct them (e.g. the Pentium family's breakpoint trap
	      incorrectly advances the program counter, but the amount
	      of the advance is known and be corrected in software.
	    </p>
	  </li>
	  <li>
	    <p>
	      Preferred hardware must implement a ``no-execute''
	      permission. This is a recently rediscovered feature in
	      the hardware world, and the specification does not
	      require <progident>NX</progident> permissions to be
	      enforced on hardware that does not provide this feature.
	    </p>
	  </li>
	</ul>
      </li>
    </ul>
    <p>
      Any change to the abstract state that reduces permissions must
      be reflected by an immediate change in the hardware state that
      (conservatively) maintains these invariants. In some cases it is
      not obvious how to do this. This part of the specification
      discusses possible implementation techniques for several key
      parts of the dependency tracking implementation.
    </p>
    <p>
      The entirety of this part is non-normative.
    </p>
    <chapter>
      <title>Implementation of Capabilities</title>
      <p>
	Because so much of any implementation depends on the internal
	representation of capabilities, we begin with a brief
	discussion of capability representation choices.
      </p>
      <p>
	It is convenient for capabilities to have two forms, which we
	call <term>prepared</term> and <term>unprepared</term>. The
	unprepared form is the one described in Section~<xref
	ref="caprep"/>. The <progident>P</progident> bit indicates
	whether the capability is prepared (1) or unprepared (0). The
	representation of a prepared capability is a matter that is
	private to the kernel. When the kernel discloses capability
	representation to application code, it <em>always</em>
	discloses the unprepared format.
      </p>
      <sect1>
	<title>Unprepared Capabilities</title>
	<p>
	  An unprepared capability may be valid or invalid, because it
	  is not known from the capability whether the object it names
	  has been destroyed subsequent to the creation of the
	  capability. This can only be known by comparing the
	  <progident>allocCount</progident> of the capability to the
	  <progident>allocCount</progident> of the object itself.
	</p>
	<p>
	  Assuming the capability is valid, the object designated by an
	  unprepared capability may or may not be in memory. This can
	  only be determined by performing an object lookup to discover
	  whether the object is in memory. In all current implementations
	  of KeyKOS, EROS, and Coyotos, a hash table is maintained that
	  provides a mapping from object id (<progident>OID</progident>)
	  to the actual object for every object that is currently in
	  memory. In systems supporting transparent persistence, there
	  may be <em>two</em> objects for a given
	  <progident>OID</progident>: the current one and the one that
	  was current at the time of the last snapshot.
	</p>
      </sect1>
      <sect1>
	<title>Prepared Capabilities &mdash; Linked Implementation</title>
	<p>
	  In KeyKOS and EROS, a prepared capability designates an
	  object that is known to be in memory. The prepared
	  capability points directly to this object. In addition, the
	  prepared capability resides on a ``key chain'', which is a
	  circularly linked list whose ``head'' is part of the object
	  header. This allows the object to be efficiently found given
	  the capability, and also allows all prepared capabilities to
	  be found given the object.
	</p>
	<figure latex.placement="h">
	  <img source="keychain" width="30" srctype="gif"/>
	  <caption>EROS/KeyKOS key chain</caption>
	</figure>
	<p>
	  There are several advantages to this design:
	</p>
	<ul>
	  <li>
	    <p>
	      Once a capability is determined to be prepared, the
	      object is known to be in memory as a consequence of
	      invariants, and few further checks related to residency
	      or well-formedness are necessary. In addition, the
	      capability is known to be valid, in the sense that its
	      <progident>allocCount</progident> matches that of the
	      target object.
	    </p>
	  </li>
	  <li>
	    <p>
	      When an object is destroyed, it is straightforward to
	      locate the active capabilities to the object and rewrite
	      them as invalid capabilities.
	    </p>
	  </li>
	  <li>
	    <p>
	      When an object is to be removed from memory, it is
	      straightforward to locate all capabilities to the object
	      and restore them to their unprepared form.
	    </p>
	  </li>
	  <li>
	    <p>
	      In either the destruction or pageout case, it is
	      straightforward to identify the <em>locations</em> of
	      all prepared capabilities. KeyKOS and EROS exploit this
	      property very aggressively. They maintain a significant
	      amount of dependency information in hashed structures
	      that are indexed by capability address. For example, the
	      KeyKOS/EROS ``depend table'' is a hash table of
	      (capability address, page table entry address) pairs.
	    </p>
	  </li>
	</ul>
	<p>
	  However, there is a key disadvantage as well:
	</p>
	<ul>
	  <li>
	    <p>
	      Capability copy is a frequent operation. Empirically, we
	      found in EROS that many copied capabilities were
	      prepared, that most overwritten capabilities were
	      prepared, and that updating the key chain when both the
	      source and destination capabilities are prepared entails
	      three cache misses per copy to access the neighbors
	      (Figure&nbsp;<xref ref="keycopy"/>). On
	      modern machines, this cost is a substantial fraction of
	      the total IPC cost.
	    </p>
	  </li>
	  <li>
	    <p>
	      Capability invocation may take time O(<em>n</em>), where
	      <em>n</em> is the size of memory. This is possible
	      because an arbitrary number of resume capabilities may
	      accumulate on the key chain, and the chain needs to be
	      traversed in order to destroy them.
	    </p>
	  </li>
	</ul>
	<figure id="keycopy" latex.placement="h">
	  <img source="keycopy" width="30" srctype="gif"/>
	  <caption>EROS/KeyKOS key copy</caption>
	</figure>
      </sect1>
      <sect1>
	<title>Prepared Capabilities &mdash; Scavenged
	Implementation</title>
	<p>
	  In Coyotos, a prepared capability does <em>not</em>
	  guarantee either that the target object is in memory or that
	  the prepared capability is valid. We are accepting weaker
	  invariants in order to improve capability copy
	  performance. Instead of a linked list, the relationship
	  between a capability and its object is shown in Figure&nbsp;<xref
	  ref="cap-obtable"/>.
	</p>
	<figure id="cap-obtable" latex.placement="h">
	  <img source="cap-obtable" srctype="gif" width="40"/>
	  <caption>Capability/object relationship</caption>
	</figure>
	<p>
	  In this design, the capability points to the object
	  (equivalently: holds an index), but also contains a pointer
	  (equivalently: an index) to an
	  <progident>ObTable</progident> structure. The object pointer
	  is valid only if the capability's
	  <progident>ObTable</progident> reference matches the
	  <progident>ObTable</progident> reference in the object
	  itself. The purpose of the <progident>ObTable</progident>
	  structure is to hold the information needed to deprepare the
	  capability back to its on-disk form. This consists of a copy
	  of the object ID (because that field of the capability is
	  overwritten by the references) and a valid bit.  Under normal circumstances, an object has one
	  <progident>ObTable</progident> entry.<footnote>
	    <p>
	      There may be none if
	      there are no prepared capabilities to this object, but this
	      is a transient case because object page-in is induced only
	      by capability preparation.
	    </p>
	  </footnote>
	</p>
	<p>
	  When an object is paged out, the first step is to change the
	  <progident>ObTable</progident> reference in the object
	  header to Null. This ensures that all outstanding
	  capabilities will be deprepared back to their on-disk
	  format. When an object is destroyed, the valid bit in the
	  current <progident>ObTable</progident> entry is set to
	  ``invalid'' before the <progident>ObTable</progident>
	  reference in the object header is nullified. In this
	  situation, outstanding capabilities will be deprepared to
	  the Null capability.  Capabilities are deprepared through a
	  combination of proactive update when the containing object
	  is written to store and background scavenging.
	</p>
	<sect2>
	  <title>Scavenging</title>
	  <p>
	    This design requires an oversupply of
	    <progident>ObTable</progident> structures.
	    <progident>ObTable</progident> structures are freed by
	    background scavenging. The scavenging proceeds as follows:
	  </p>
	  <ol>
	    <li>
	      <p>
		Make a pass over all 
		<progident>ObTable</progident> structures. Mark the
		ones that are current. Clear the mark on the ones that
		are not current.
	      </p>
	    </li>
	    <li>
	      <p>
		Traverse all in-memory objects that contain
		capabilities. For each capability:
	      </p>
	      <ul>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    current, leave the capability alone.
		  </p>
		</li>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    invalid, deprepare the capability to null.
		  </p>
		</li>
		<li>
		  <p>
		    If the <progident>ObTable</progident> entry is
		    valid but not current, deprepare the capability
		    back to it's on-disk form.
		  </p>
		</li>
	      </ul>
	    </li>
	    <li>
	      <p>
		Make a second pass over all 
		<progident>ObTable</progident> structures, placing the
		unmarked structures onto the free list.
	      </p>
	    </li>
	  </ol>
	  <p>
	    This algorithm can be implemented incrementally by forcing
	    some progress whenever an <progident>ObTable</progident>
	    entry is allocated.
	  </p>
	  <p>
	    Note that the algorithm is <em>not</em> trying to detect
	    unreferenced objects. This is the responsibility of the
	    aging logic, which is handled separately.
	  </p>
	  <p>
	    When the algorithm is executed incrementally, there is the
	    usual race between the mark pass and the mutator that is
	    copying and overwriting references. The unfortunate case
	    is the sequence where:
	  </p>
	  <ol>
	    <li>
	      <p>
		The mark pass has moved past capability slot A, but
		has not yet reached slot B.
	      </p>
	    </li>
	    <li>
	      <p>
		Slot B holds the only outstanding capability to some
		object.
	      </p>
	    </li>
	    <li>
	      <p>
		A copy is made from slot B to slot A.
	      </p>
	    </li>
	    <li>
	      <p>
		Slot B is overwritten before it is reached by the mark
		pass. A now holds the only capability to the
		<progident>ObTable</progident> entry, but it will not
		be seen by the mark pass.
	      </p>
	    </li>
	  </ol>
	  <p>
	    Note that the race condition does not matter if B is a
	    <em>valid</em> capability, because in this case the
	    <progident>ObTable</progident> structure is already
	    marked. The issue arises only when B is an
	    <em>invalid</em> capability. The race is resolved by
	    checking whenever a prepared capability is copied, and
	    updating the newly written capability to the null
	    capability if it is invalid.
	  </p>
	</sect2>
	<sect2>
	  <title>Pros and Cons</title>
	  <p>
	    The primary advantage of this design over the KeyKOS/EROS
	    design is speed of capability copy. There is only one
	    marginal cache miss per copy, which is the probe that
	    checks the capability for validity. If it is feasible to
	    scan all processes in a non-incremental fashion, this
	    probe can be eliminated in the fast IPC path because any
	    copy proceeding <em>from</em> a capability register does
	    not need to be checked for validity. The need for this
	    optimization should be guided by measurement, and our
	    initial implementation will not attempt it.
	  </p>
	  <p>
	    The main disadvantage is that this design requires an
	    incremental scavenging pass whose performance cost is not
	    yet known.
	  </p>
	</sect2>
      </sect1>
    </chapter>
    <chapter>
      <title>Mapping Dependencies</title>
      <p>
	The most challenging set of structures to design in the
	Coyotos implementation is the mechanism for keeping GPT
	structures, objects, and page table entries consistent. There
	are three requirements:
      </p>
      <ol>
	<li>
	  <p>
	    When a page is destroyed or removed from memory,
	    all page table entries that point to that page must be
	    invalidated.
	  </p>
	</li>
	<li>
	  <p>
	    When a GPT is destroyed or removed from memory, all
	    currently valid translations in the page table structures
	    that were constructed by traversing the GPT must be
	    invalidated.
	  </p>
	</li>
	<li>
	  <p>
	    When a capability slot within a GPT is overwritten, all
	    currently valid translations in the page table structures
	    that were constructed by traversing that slot of the GPT
	    must be invalidated. This may viewed as a sub-case of (2).
	  </p>
	</li>
      </ol>
      <sect1>
	<title>Page Removal</title>
	<p>
	  In KeyKOS and EROS, the key chain meant that any
	  implementation of requirement (3) also satisfied requirement
	  (1). When a page is removed from memory, its key chain can be
	  traversed to locate all of the capability slots that reference
	  the page. These can then be used to invalidate the necessary
	  page table entries.
	</p>
	<p>
	  In the Coyotos implementation, which does not have a key
	  chain, we maintain a reverse page table structure known as
	  <progident>PTE<sup>-1</sup></progident>. For every valid
	  page table entry in the hardware page table, we maintain a
	  reverse entry that provides a mapping from the physical
	  object address to the kernel virtual address of its
	  referencing page table entry.
	</p>
	<p>
	  In systems having hierarchical page tables, we maintain this
	  inverse page table structure at all levels of the
	  translation hierarchy. This allows mapping tables to be aged
	  and reclaimed.
	</p>
      </sect1>
      <sect1>
	<title>GPT Dependencies</title>
	<p>
	  The statement of requirements in (2, 3) is a bit subtle. The
	  straightforward implementation of these requirements is to
	  record a pairwise relationship between capability slot
	  addresses and page table entry addresses, and use this to
	  invalidate all page table entries when a slot is overwritten
	  or a GPT is removed. This was, in essence, the implementation
	  used by KeyKOS and EROS, and it is fairly straightforward to
	  see why it satisfies the requirement that ``the permissions of
	  the implementation state must never exceed those of the
	  abstract state.'' However, this implementation is both
	  unnecessarily aggressive and unnecessarily expensive.
	</p>
	<p>
	  Because we do not rely on key rings for page removal,
	  Coyotos has slightly different properties than KeyKOS or
	  EROS. Whenever we consider changing the value of a slot, we
	  always have the address of its containing GPT in
	  hand.<footnote>
	    <p>
	      In EROS, we knew the location of the vector of Nodes
	      (the precursor to GPTs), and we could use this knowledge
	      to infer the containing Node address from any given Node
	      slot address. This inference is not memory safe, and we
	      wanted to avoid it in Coyotos in anticipation of later
	      verification efforts.
	    </p>
	  </footnote>. Coyotos therefore maintains a dependency table
	  that maps from GPT addresses to page table entry
	  addresses. There may be multiple entries in this table for a
	  given GPT. This can happen for two reasons:
	</p>
	<ol>
	  <li>
	    <p>
	      A GPT may produce multiple page tables because it spans
	      multiple entries in a page directory (Figure&nbsp;<xref
	      ref="gpt-pt-span"/>). This arises only in hardware
	      system having hierarchical translation systems, but it
	      can arise at any ``layer'' of the translation system. In
	      fact, a single GPT can span three or more layers if it
	      describes the only valid path across multiple levels of
	      the hardware tables.
	    </p>
	  </li>
	  <li>
	    <p>
	      Because of page table reuse, a GPT may produce both
	      read-only and read-write variants of the same page table.
	    </p>
	  </li>
	</ol>
	<figure id="gpt-pt-span" latex.placement="h">
	  <img source="gpt-pt-span" srctype="gif" width="60"/>
	  <caption>Capability/object relationship</caption>
	</figure>
	<p>
	  The hierarchical case is complicated by the desire for page
	  table sharing. In KeyKOS and EROS, we recorded dependency
	  information at all implicated levels of the hardware
	  translation hierarchy. In Coyotos we do not. Instead, we
	  record dependencies only when the GPT wholly or partially
	  dominates the hardware table. This is sufficient to let is
	  invalidate all <em>paths</em> through the hardware tree that
	  are implicated by changes to a GPT. It does <em>not</em>
	  allow us to invalidate all of the page table entries, but we
	  assert this is not actually necessary to satisfy the
	  requirements.
	</p>
	<p>
	  This assertion is <em>not</em> obvious and will need to be
	  confirmed by demonstration as we develop a statement of
	  invariants maintained by the translation logic in this
	  case. The substance of it, however, is that valid entries
	  higher in the hardware structures do not matter if all of
	  the lower entries they span are correctly invalidated. If
	  the GPT is being destroyed, the lower tables will in due
	  course be reclaimed and the higher-level page table entries
	  will then be invalidated. If the GPT is being overwritten,
	  the higher-level page table entries would get rebuilt in any
	  case, and the permissions of the lower-level page table
	  entries are sufficient to ensure a conservative mapping of
	  the abstract machine's permission state.
	</p>
      </sect1>
      <sect1>
	<title>Optimizations</title>
	<p>
	  Ironically, the new structure should be more compact than
	  the old structure.
	</p>
	<p>
	  <leadin>Inverse Page Table</leadin> The
	  <progident>PTE<sup>-1</sup></progident> table requires only
	  a single word per entry, because the pointer to the PTE can
	  be used to read the physical page address in order to detect
	  hash collisions and stale dependency table entries.
	</p>
	<p>
	  Observe further that the majority of pages and page tables
	  have only one or two simultaneous page table entries. A
	  possible storage optimization is to dedicate two
	  <progident>PTE<sup>-1</sup></progident> entries in the frame
	  management structures for each of these, leaving the general
	  <progident>PTE<sup>-1</sup></progident> table to handle only
	  those pages that are widely shared. Whether this is
	  worthwhile depends on whether a sufficiently good hash
	  function can be discovered to keep hash chains short in the
	  usual case.
	</p>
	<p>
	  <leadin>GPT Dependencies</leadin> Because we use GPT object
	  pointers rather than GPT slot pointers in the GPT dependency
	  table, our GPT dependency table will have a factor of 16
	  (well, given underutilization probably a factor of 5 to 8)
	  reduction in space requirements compared to the old
	  dependency tracking scheme.
	</p>
	<p>
	  Observe that while a GPT may produce entries in multiple
	  page tables, it always produces 2<sup><em>k</em></sup>
	  entries at a natural alignment boundary within those
	  tables. This statement is also true of GPT <em>slots</em>,
	  and offered a basis for run length compression of the GPT
	  dependency table in some implementations. We note that this
	  option remains available in the new implementation.
	</p>
      </sect1>
    </chapter>
  </part>
  <bibliography>
    <bibentry label="elphinstone99vm64">
      Kevin John Elphinstone. <doctitle>Virtual Memory in a 64-Bit
	Microkernel</doctitle>. Ph.D. Dissertation. University of New
      South Wales, School of Computer Science, August 31, 1999.
    </bibentry>
    <bibentry label="hardy1985keykos">
      Norman Hardy. ``The KeyKOS Architecture.'' <doctitle>Operating
        Systems Review</doctitle>, <b>19</b>(4),  October 1985,
        pp. 8&ndash;25.
    </bibentry>
<!--     <bibentry label="landau2005capros"> -->
<!--       Charles Landau. ``CapROS: The Capability-based Reliable -->
<!--         Operating System.'' <tt>http://www.capros.org</tt>. -->
<!--     </bibentry> -->
    <bibentry label="liedtke1995gpt4600">
      Jochen Liedtke and Kevin Elphinstone. <doctitle>Guarded Page Tables on
      the MIPS R4600, or, An Exercise in Architecture-Dependent Micro
      Optimization.</doctitle> Technical Report UNSWCSE-TR-9503,
      University of New South Wales, School of Computer Science, 1995.
    </bibentry>
    <bibentry label="shap1999fastcapsystem">
      J. S. Shapiro, J. M. Smith, and D. J. Farber. ``EROS, A Fast
      Capability System'' <doctitle>Proc. 17th ACM Symposium on Operating
      Systems Principles</doctitle>. Dec 1999. pp. 170&ndash;185. Kiawah
      Island Resort, SC, USA.
    </bibentry>
    <bibentry label="shap2002store">
      J. S. Shapiro, J. Adams. ``Design Evolution of the EROS
      Single-Level Store'' <doctitle>Proc. 2002 USENIX Annual
      Technical Conference</doctitle>. 2002. pp. 59&ndash;72.
    </bibentry>
<!--     <bibentry label="shap2003vulnerabilities"> -->
<!--       J. S. Shapiro. ``Vulnerabilities in Synchronous IPC Design'' -->
<!--       <doctitle>Proc. 2003 IEEE Symposium on Security and -->
<!--       Privacy</doctitle>. 2003.Oakland, CA, USA. -->
<!--     </bibentry> -->
    <bibentry label="shap2004towards">
      J. Shapiro, M. Doerrie, S. Sridhar, M. Miller. ``Towards a
      Verified, General-Purpose Operating System Kernel''
      <doctitle>Proc. NICTA OS Verification Workshop 2004</doctitle>. 
      October, 2004. Sydney, New South Wales, Australia.
    </bibentry>
    <bibentry label="shap00verifying">
      J. S. Shapiro and S. Weber. ``Verifying the EROS Confinement
	Mechanism.'' <doctitle>Proc. 2000 IEEE Symposium on Security and
	Privacy</doctitle>. May 2000. pp. 166&ndash;176. Oakland, CA, USA
    </bibentry>
    <bibentry label="shap04ews">
      J. Shapiro, J. Vanderburgh, E. Northup, and
	D. Chizmadia. ``Design of the EROS Trusted Window System''
	<doctitle>Proc. 13th USENIX Security
	Symposium</doctitle>. 2004
    </bibentry>
    <bibentry label="sag04l4refman">
      &mdash;: L4 <em>eXperimental</em> Kernel Reference Manual. 
      System Architecture Group, Dept. of Computer Science,
      Universit&auml;t Karlsruhe. 2004
    </bibentry>
    <bibentry label="sinha04network">
      A. Sinha, S. Sarat, and J. S. Shapiro. ``Network Subsystems
      Reloaded'' <doctitle>Proc. 2004 USENIX Annual Technical
      Conference</doctitle>. Dec. 2004
    </bibentry>
    <bibentry label="dennis1966semantics">
      J. B. Dennis and E. C. van Horn.
      ``Programming Semantics for Multiprogrammed Computations''
      <doctitle>Communications of the ACM</doctitle>. <b>9</b>(3),
      March 1966.
      pp. 143&ndash;154.
    </bibentry>
    <bibentry label="l3:ipc">
      J. Liedtke. ``Improving IPC by Kernel Design''
      <doctitle>Proc. 14th ACM Symposium on Operating System
      Principles</doctitle>. ACM. pp. 175&ndash;188. 1993
    </bibentry>
    <bibentry label="EROS:IPC">
      J. S. Shapiro, D. J. Farber, and J. M. Smith. ``The Measured
      Performance of a Fast Local IPC'' <doctitle>Proc. 5th
      International Workshop on Object Orientation in Operating
      Systems</doctitle>. Seattle, WA, USA. Nov
      1996. pp. 89&ndash;94. IEEE.
    </bibentry>
    <bibentry label="mach4evolving">
      B. Ford and J. Lepreau. ``Evolving Mach 3.0 to a Migrating
      Threads Model'' <doctitle>Proc. 1994 Winter USENIX
      Conference</doctitle>. Jan 1994. pp. 97&ndash;114.
    </bibentry>
<!--     <bibentry label="thomas90scheduler"> -->
<!--       T. E. Anderson and B. N. Bershad and E. D. Lazowska and -->
<!--       H. M. Levy. -->
<!--       ``Scheduler Activations: Effective Kernel Support for the -->
<!--       User-Level Management of Parallelism'' <doctitle>Proc. 13th ACM -->
<!--       Symposium on Operating Systems Principles</doctitle>. Pacific -->
<!--       Grove, CA, USA. pp. 95&ndash;109. 1991. -->
<!--     </bibentry> -->
<!--     <bibentry label="marsh91firstclass"> -->
<!--       B. D. Marsh and M. L. Scott and T. J. LeBlank and -->
<!--       E. P. Markatos, -->
<!--       ``First-Class User-Level Threads'' <doctitle>Proc 13th ACM -->
<!--       Symposium on Operating Systems Principles</doctitle>. -->
<!--       Pacific Grove, CA, USA. -->
<!--       pp. 110&ndash;121. 1991. -->
<!--     </bibentry> -->
    <bibentry label="roscoe1995thesis">
      T. Roscoe.
      <doctitle>The Structure of a Multi-Service Operating
      System</doctitle>.
      Ph.D. Dissertation, University of Cambridge Computer Laboratory
      Technical Report UCAM-CL-TR376. August 1995.
    </bibentry>
    <bibentry label="wulf1974hydra">
      W. A. Wulf, E. S. Cohen, W. M. Corwin, A. K. Jones, R. Levin,
      C. Pierson and Fred J. Pollack. ``HYDRA: The Kernel of a
      Multiprocessor Operating System'' <doctitle>Communications of
      the ACM</doctitle>. <b>17</b>(6), pp. 337&ndash;345. 1974.
    </bibentry>
    <bibentry label="Redell:Thesis">
      D. D. Redell. <doctitle>Naming and Protection in Extensible
      Operating Systems</doctitle>. Ph.D. Dissertation. Department of
      Computer Science, University of California at Berkeley. Nov
      1974.
    </bibentry>
    <bibentry label="KeyKOS:KeySafe">
      S. A. Rajunas. <doctitle>The KeyKOS/KeySAFE System
      Design.</doctitle>
      Key Logic Technical Report SEC009-01. March 1989. Key Logic, Inc.
    </bibentry>
    <bibentry label="kauer2005thesis">
      B. Kauer. <doctitle>L4.sec Implementation &mdash; Kernel Memory
      Management</doctitle> Diploma Thesis, Chair for Operating
      Systems, Technical University of Dresden. Supervisor: Marcus
      Volp. 2005
    </bibentry>
    <bibentry label="mc68851">
      Motorola, Inc. <doctitle>MC68851 Paged Memory Management Unit
	User's Manual</doctitle>.  Prentice Hall, Inc., Englewood
	Cliffs, New Jersey, USA, 1986.
    </bibentry>
    <bibentry label="elf-handling">
      Ulrich Drepper, <doctitle>ELF Handling for Thread-Local
      Storage</doctitle>, Version 0.20. Red Hat Inc., December 21
      2005.
    </bibentry>
  </bibliography>
</book>
