#ifndef __KERNINC_DEPEND_H__
#define __KERNINC_DEPEND_H__
/*
 * Copyright (C) 2006, The EROS Group, LLC.
 *
 * This file is part of the Coyotos Operating System.
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2,
 * or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
 */

/** @file 
 * @brief Definition of Wrapper structure. */

#include <obstore/GPT.h>
#include <kerninc/ccs.h>
#include <kerninc/capability.h>
#include <kerninc/ObjectHeader.h>
#include <hal/config.h>
#include <hal/vm.h>

/** @page DependTheory Depend Table Theory of Operation
 *
 * Coyotos has two dependency tracking data structures: the reverse
 * map and the depend table. The reverse map is simply an inverse page
 * table: for every valid PTE, it contains a back pointer from the
 * object to its PTE. The discussion here focuses on the depend table.
 *
 * @section HierarchicalDepends Behavior with Hierarchical Tables
 *
 * Conceptually, the relationship between GPT slots and page table
 * slots is straightforward: each GPT slot produces nPTE page table
 * entries, where nPTE is some power of two. The page table entries
 * produced may start in the middle of the page table somewhere (at a
 * power of two index). Conversely, a GPT may produce multiple page
 * tables, with the effect that GPT slots 1 and 2 produce entries on
 * one page table, GPT slots 3 and 4 produce entries in a second page
 * table, and so forth.
 *
 * There are many possible ways to encode this information. We are
 * concerned here to find one that maximizes our ability to merge
 * DependEntry structures as new PTEs are created.
 *
 * In the current encoding, @p l2slotSpan is log2(nPTE), where nPTE is
 * the number of page table entries produced by each GPT slot
 * encoded. The @p basePTE index names the first PTE that has
 * actually been produced from this GPT. If the only GPT slot that has
 * been traversed is slot 3, then @p basePTE names to the first PTE
 * that was generated by traversing slot 3. The @p slotMask tells us
 * which slots have been visited for translation. The @p slotBias
 * field indicates the least numbered slot that has been traversed for
 * translation. If the slot was subsequently invalidated, there may
 * not be any actual entries associated with it. The @p slotBias field
 * therefore also tells us the least bit that may validly be set in @p
 * slotMask.
 *
 * The @p basePTE and @p slotBias fields move in lockstep. The reason
 * for this encoding decision is that simple arithmetic does not
 * suffice here. If we are describing a table that is entirely
 * produced by GPT slots 3 and 4, and @p basePTE were not pre-biased
 * in this fashion, then @p basePTE might need to point someplace
 * entirely outside the page table. That encoding could be made to
 * work, but this one seems a bit more conservative from a sanity
 * checking perspective.
 *
 * With all this in mind, the rule is:
 *
 * If bit N of @p slotMask is set, then the 2^l2slotSpan PTEs at:
 * @verbatim
    @p basePTE + (N - @p slotBias) @<@< l2slotSpan
@endverbatim
 *
 * Are implicated by this depend entry. That is: each slot in this
 * GPT potentially defines 2^l2slotSpan PTEs.
 *
 * @section SoftDepends Behavior with Soft Translation
 *
 * If MAPPING_INDEX_BITS is zero, then the target
 * architecture is using soft translation, and is relying on the GPT
 * walker to re-fill the TLB directly. This is a dubious design choice
 * from a performance perspective, but it does provide a fast way to
 * bring up a new target on such architectures. Implementations of
 * that sort tend to graduate into some form of clustering strategy
 * for page table entries later, at which point they look like
 * hierarchical page table systems.
 *
 * In the pure soft-translated case, the only reason for a depend
 * entry is to record the relationship between the top-level GPT and
 * the corresponding logical Mapping structure.
 */

/** @brief The depend structure.
 *
 * The Depend structure tracks the relationship from GPT structures to
 * the hardware page table entries that are produced from them. This
 * provides the information that we need to correctly invalidate the
 * hardware entries when a slot in a GPT is overwritten.  A single
 * DependEntry structure describes entries that fall within a single
 * page table.
 *
 * This data structure appears in the depend table, and is indexed by
 * the MemHeader address.
 *
 * A detailed discussion may be found at: @ref DependTheory
 */

struct DependEntry {
  /** @brief The key for the hash;  the GPT effected.  
   *
   * In free DependEntrys, this is NULL.
   */
  struct GPT *gpt;
  struct Mapping *map;

#if MAPPING_INDEX_BITS
  /** @brief slots which may have entries.
   *
   * If bit N is set, then the 2^l2slotSpan PTEs at:
   *
   *   @p basePTE + (N - @p slotBias) @<@< l2slotSpan
   *
   * Are implicated by this depend entry. That is: each slot in this
   * GPT potentially defines 2^l2slotSpan PTEs.
   */
  uint32_t   slotMask : NUM_GPT_SLOTS; /* which slots have been traversed */
  /** @brief Index of the least bit that has been
   * set in slotMask to date.
   *
   * Note that the bit may subsequently have been cleared due to
   * depend invalidation.  When a new depend entry is created, it may
   * be merged in depend_merge(), in which case @p slotBias and @p
   * basePTE will be reduced in lockstep at the time of the merge. */
  uint32_t   slotBias : GPT_SLOT_INDEX_BITS;

  /** @brief Number of PTEs generated from each GPT slot. */
  uint32_t   l2slotSpan : L2_MAPPING_INDEX_BITS;
  uint32_t   basePTE : MAPPING_INDEX_BITS;
#else
  /**
   * If HIEARCHICAL_MAP_INDEX_BITS is zero, we have a soft-translated
   * architecture and we are not implementing conventional page tables
   * at all.
   *
   */
#endif
};
typedef struct DependEntry DependEntry;

enum { ENTRIES_PER_DEPEND = 15 };

struct Depend {
  struct Depend *next;	/**< @brief Next depend entry in chain */
  size_t	nvalid; /**< @brief number of valid entries */
  DependEntry	ents[ENTRIES_PER_DEPEND]; /**< @brief entries */
};
typedef struct Depend Depend;

/**
 * @brief Install a requested depend entry in the depend table, merging it
 * with other entries if possible.
 *
 * Preconditions: The GPT referenced in @p toInstall must be locked.
 *
 * Postcondition: The requested depend entry is in the depend table.
 */
void depend_install(DependEntry toInstall);

/**
 * @brief Invalidate all depend entries associated with the GPT @p gpt.
 */
void depend_invalidate(struct GPT *gpt);

/**
 * @brief Invalidate all depend entries associated with slot @p slot in 
 * the GPT @p gpt.
 */
void depend_invalidate_slot(struct GPT *gpt, size_t slot);

#define DEPEND_INVALIDATE_ALL -1
/**
 * @brief HAL function to invalidate all Mapping entries associated with
 * a particular @p slot in a DependEntry.
 *
 * If @p slot is DEPEND_INVALIDATE_ALL, all slots are invalidated.
 */
__hal void depend_entry_invalidate(const DependEntry *entry, int slot);

#endif /* __KERNINC_DEPEND_H__ */
